[{"title":"Conditional Quantile Estimation for Uncertain Watch Time in Short-Video Recommendation","abstract":"Within the domain of short video recommendation, predicting users' watch time\nis a critical but challenging task. Prevailing deterministic solutions obtain\naccurate debiased statistical models, yet they neglect the intrinsic\nuncertainty inherent in user environments. In our observation, we found that\nthis uncertainty could potentially limit these methods' accuracy in watch-time\nprediction on our online platform, despite that we have employed numerous\nfeatures and complex network architectures. Consequently, we believe that a\nbetter solution is to model the conditional distribution of this uncertain\nwatch time.\n  In this paper, we introduce a novel estimation technique -- Conditional\nQuantile Estimation (CQE), which utilizes quantile regression to capture the\nnuanced distribution of watch time. The learned distribution accounts for the\nstochastic nature of users, thereby it provides a more accurate and robust\nestimation. In addition, we also design several strategies to enhance the\nquantile prediction including conditional expectation, conservative estimation,\nand dynamic quantile combination. We verify the effectiveness of our method\nthrough extensive offline evaluations using public datasets as well as\ndeployment in a real-world video application with over 300 million daily active\nusers.","authors":["Chengzhi Lin","Shuchang Liu","Chuyuan Wang","Yongqi Liu"],"pdf_link":"http://arxiv.org/pdf/2407.12223v1","category":["Datasets","Reinforcement Learning"]},{"title":"Laugh Now Cry Later: Controlling Time-Varying Emotional States of Flow-Matching-Based Zero-Shot Text-to-Speech","abstract":"People change their tones of voice, often accompanied by nonverbal\nvocalizations (NVs) such as laughter and cries, to convey rich emotions.\nHowever, most text-to-speech (TTS) systems lack the capability to generate\nspeech with rich emotions, including NVs. This paper introduces EmoCtrl-TTS, an\nemotion-controllable zero-shot TTS that can generate highly emotional speech\nwith NVs for any speaker. EmoCtrl-TTS leverages arousal and valence values, as\nwell as laughter embeddings, to condition the flow-matching-based zero-shot\nTTS. To achieve high-quality emotional speech generation, EmoCtrl-TTS is\ntrained using more than 27,000 hours of expressive data curated based on\npseudo-labeling. Comprehensive evaluations demonstrate that EmoCtrl-TTS excels\nin mimicking the emotions of audio prompts in speech-to-speech translation\nscenarios. We also show that EmoCtrl-TTS can capture emotion changes, express\nstrong emotions, and generate various NVs in zero-shot TTS. See\nhttps://aka.ms/emoctrl-tts for demo samples.","authors":["Haibin Wu","Xiaofei Wang","Sefik Emre Eskimez","Manthan Thakker","Daniel Tompkins","Chung-Hsien Tsai","Canrun Li","Zhen Xiao","Sheng Zhao","Jinyu Li","Naoyuki Kanda"],"pdf_link":"http://arxiv.org/pdf/2407.12229v1","category":["Speech Synthesis","Speech Recognition"]},{"title":"Turning Generative Models Degenerate: The Power of Data Poisoning Attacks","abstract":"The increasing use of large language models (LLMs) trained by third parties\nraises significant security concerns. In particular, malicious actors can\nintroduce backdoors through poisoning attacks to generate undesirable outputs.\nWhile such attacks have been extensively studied in image domains and\nclassification tasks, they remain underexplored for natural language generation\n(NLG) tasks. To address this gap, we conduct an investigation of various\npoisoning techniques targeting the LLM's fine-tuning phase via prefix-tuning, a\nParameter Efficient Fine-Tuning (PEFT) method. We assess their effectiveness\nacross two generative tasks: text summarization and text completion; and we\nalso introduce new metrics to quantify the success and stealthiness of such NLG\npoisoning attacks. Through our experiments, we find that the prefix-tuning\nhyperparameters and trigger designs are the most crucial factors to influence\nattack success and stealthiness. Moreover, we demonstrate that existing popular\ndefenses are ineffective against our poisoning attacks. Our study presents the\nfirst systematic approach to understanding poisoning attacks targeting NLG\ntasks during fine-tuning via PEFT across a wide range of triggers and attack\nsettings. We hope our findings will aid the AI security community in developing\neffective defenses against such threats.","authors":["Shuli Jiang","Swanand Ravindra Kadhe","Yi Zhou","Farhan Ahmed","Ling Cai","Nathalie Baracaldo"],"pdf_link":"http://arxiv.org/pdf/2407.12281v2","category":["Speech Synthesis","LLMs"]},{"title":"Chip Placement with Diffusion","abstract":"Macro placement is a vital step in digital circuit design that defines the\nphysical location of large collections of components, known as macros, on a\n2-dimensional chip. The physical layout obtained during placement determines\nkey performance metrics of the chip, such as power consumption, area, and\nperformance. Existing learning-based methods typically fall short because of\ntheir reliance on reinforcement learning, which is slow and limits the\nflexibility of the agent by casting placement as a sequential process. Instead,\nwe use a powerful diffusion model to place all components simultaneously. To\nenable such models to train at scale, we propose a novel architecture for the\ndenoising model, as well as an algorithm to generate large synthetic datasets\nfor pre-training. We empirically show that our model can tackle the placement\ntask, and achieve competitive performance on placement benchmarks compared to\nstate-of-the-art methods.","authors":["Vint Lee","Chun Deng","Leena Elzeiny","Pieter Abbeel","John Wawrzynek"],"pdf_link":"http://arxiv.org/pdf/2407.12282v1","category":["Reinforcement Learning","Explainable AI"]},{"title":"Information-Theoretic Foundations for Machine Learning","abstract":"The staggering progress of machine learning in the past decade has been a\nsight to behold. In retrospect, it is both remarkable and unsettling that these\nmilestones were achievable with little to no rigorous theory to guide\nexperimentation. Despite this fact, practitioners have been able to guide their\nfuture experimentation via observations from previous large-scale empirical\ninvestigations. However, alluding to Plato's Allegory of the cave, it is likely\nthat the observations which form the field's notion of reality are but shadows\nrepresenting fragments of that reality. In this work, we propose a theoretical\nframework which attempts to answer what exists outside of the cave. To the\ntheorist, we provide a framework which is mathematically rigorous and leaves\nopen many interesting ideas for future exploration. To the practitioner, we\nprovide a framework whose results are very intuitive, general, and which will\nhelp form principles to guide future investigations. Concretely, we provide a\ntheoretical framework rooted in Bayesian statistics and Shannon's information\ntheory which is general enough to unify the analysis of many phenomena in\nmachine learning. Our framework characterizes the performance of an optimal\nBayesian learner, which considers the fundamental limits of information.\nThroughout this work, we derive very general theoretical results and apply them\nto derive insights specific to settings ranging from data which is\nindependently and identically distributed under an unknown distribution, to\ndata which is sequential, to data which exhibits hierarchical structure\namenable to meta-learning. We conclude with a section dedicated to\ncharacterizing the performance of misspecified algorithms. These results are\nexciting and particularly relevant as we strive to overcome increasingly\ndifficult machine learning challenges in this endlessly complex world.","authors":["Hong Jun Jeon","Benjamin Van Roy"],"pdf_link":"http://arxiv.org/pdf/2407.12288v2","category":["Explainable AI","Datasets"]},{"title":"Spectra: A Comprehensive Study of Ternary, Quantized, and FP16 Language Models","abstract":"Post-training quantization is the leading method for addressing\nmemory-related bottlenecks in LLM inference, but unfortunately, it suffers from\nsignificant performance degradation below 4-bit precision. An alternative\napproach involves training compressed models directly at a low bitwidth (e.g.,\nbinary or ternary models). However, the performance, training dynamics, and\nscaling trends of such models are not yet well understood. To address this\nissue, we train and openly release the Spectra LLM suite consisting of 54\nlanguage models ranging from 99M to 3.9B parameters, trained on 300B tokens.\nSpectra includes FloatLMs, post-training quantized QuantLMs (3, 4, 6, and 8\nbits), and ternary LLMs (TriLMs) - our improved architecture for ternary\nlanguage modeling, which significantly outperforms previously proposed ternary\nmodels of a given size (in bits), matching half-precision models at scale. For\nexample, TriLM 3.9B is (bit-wise) smaller than the half-precision FloatLM 830M,\nbut matches half-precision FloatLM 3.9B in commonsense reasoning and knowledge\nbenchmarks. However, TriLM 3.9B is also as toxic and stereotyping as FloatLM\n3.9B, a model six times larger in size. Additionally, TriLM 3.9B lags behind\nFloatLM in perplexity on validation splits and web-based corpora but performs\nbetter on less noisy datasets like Lambada and PennTreeBank.\n  To enhance understanding of low-bitwidth models, we are releasing 500+\nintermediate checkpoints of the Spectra suite at\n\\href{https://github.com/NolanoOrg/SpectraSuite}{https://github.com/NolanoOrg/SpectraSuite}.","authors":["Ayush Kaushal","Tejas Pandey","Tejas Vaidhya","Aaryan Bhagat","Irina Rish"],"pdf_link":"http://arxiv.org/pdf/2407.12327v1","category":["LLMs","Speech Synthesis"]},{"title":"Uncertainty Calibration with Energy Based Instance-wise Scaling in the Wild Dataset","abstract":"With the rapid advancement in the performance of deep neural networks (DNNs),\nthere has been significant interest in deploying and incorporating artificial\nintelligence (AI) systems into real-world scenarios. However, many DNNs lack\nthe ability to represent uncertainty, often exhibiting excessive confidence\neven when making incorrect predictions. To ensure the reliability of AI\nsystems, particularly in safety-critical cases, DNNs should transparently\nreflect the uncertainty in their predictions. In this paper, we investigate\nrobust post-hoc uncertainty calibration methods for DNNs within the context of\nmulti-class classification tasks. While previous studies have made notable\nprogress, they still face challenges in achieving robust calibration,\nparticularly in scenarios involving out-of-distribution (OOD). We identify that\nprevious methods lack adaptability to individual input data and struggle to\naccurately estimate uncertainty when processing inputs drawn from the wild\ndataset. To address this issue, we introduce a novel instance-wise calibration\nmethod based on an energy model. Our method incorporates energy scores instead\nof softmax confidence scores, allowing for adaptive consideration of DNN\nuncertainty for each prediction within a logit space. In experiments, we show\nthat the proposed method consistently maintains robust performance across the\nspectrum, spanning from in-distribution to OOD scenarios, when compared to\nother state-of-the-art methods.","authors":["Mijoo Kim","Junseok Kwon"],"pdf_link":"http://arxiv.org/pdf/2407.12330v1","category":["Explainable AI","Reinforcement Learning"]},{"title":"GUME: Graphs and User Modalities Enhancement for Long-Tail Multimodal Recommendation","abstract":"Multimodal recommendation systems (MMRS) have received considerable attention\nfrom the research community due to their ability to jointly utilize information\nfrom user behavior and product images and text. Previous research has two main\nissues. First, many long-tail items in recommendation systems have limited\ninteraction data, making it difficult to learn comprehensive and informative\nrepresentations. However, past MMRS studies have overlooked this issue.\nSecondly, users' modality preferences are crucial to their behavior. However,\nprevious research has primarily focused on learning item modality\nrepresentations, while user modality representations have remained relatively\nsimplistic.To address these challenges, we propose a novel Graphs and User\nModalities Enhancement (GUME) for long-tail multimodal recommendation.\nSpecifically, we first enhance the user-item graph using multimodal similarity\nbetween items. This improves the connectivity of long-tail items and helps them\nlearn high-quality representations through graph propagation. Then, we\nconstruct two types of user modalities: explicit interaction features and\nextended interest features. By using the user modality enhancement strategy to\nmaximize mutual information between these two features, we improve the\ngeneralization ability of user modality representations. Additionally, we\ndesign an alignment strategy for modality data to remove noise from both\ninternal and external perspectives. Extensive experiments on four publicly\navailable datasets demonstrate the effectiveness of our approach.","authors":["Guojiao Lin","Zhen Meng","Dongjie Wang","Qingqing Long","Yuanchun Zhou","Meng Xiao"],"pdf_link":"http://arxiv.org/pdf/2407.12338v1","category":["Multimodal Learning","Datasets"]},{"title":"SENTAUR: Security EnhaNced Trojan Assessment Using LLMs Against Undesirable Revisions","abstract":"A globally distributed IC supply chain brings risks due to untrusted third\nparties. The risks span inadvertent use of hardware Trojan (HT), inserted\nIntellectual Property (3P-IP) or Electronic Design Automation (EDA) flows. HT\ncan introduce stealthy HT behavior, prevent an IC work as intended, or leak\nsensitive data via side channels. To counter HTs, rapidly examining HT\nscenarios is a key requirement. While Trust-Hub benchmarks are a good starting\npoint to assess defenses, they encompass a small subset of manually created HTs\nwithin the expanse of HT designs. Further, the HTs may disappear during\nsynthesis. We propose a large language model (LLM) framework SENTAUR to\ngenerate a suite of legitimate HTs for a Register Transfer Level (RTL) design\nby learning its specifications, descriptions, and natural language descriptions\nof HT effects. Existing tools and benchmarks are limited; they need a learning\nperiod to construct an ML model to mimic the threat model and are difficult to\nreproduce. SENTAUR can swiftly produce HT instances by leveraging LLMs without\nany learning period and sanitizing the HTs facilitating their rapid assessment.\nEvaluation of SENTAUR involved generating effective, synthesizable, and\npractical HTs from TrustHub and elsewhere, investigating impacts of\npayloads/triggers at the RTL. While our evaluation focused on HT insertion,\nSENTAUR can generalize to automatically transform an RTL code to have defined\nfunctional modifications.","authors":["Jitendra Bhandari","Rajat Sadhukhan","Prashanth Krishnamurthy","Farshad Khorrami","Ramesh Karri"],"pdf_link":"http://arxiv.org/pdf/2407.12352v1","category":["Explainable AI","LLMs"]},{"title":"Evaluating graph-based explanations for AI-based recommender systems","abstract":"Recent years have witnessed a rapid growth of recommender systems, providing\nsuggestions in numerous applications with potentially high social impact, such\nas health or justice. Meanwhile, in Europe, the upcoming AI Act mentions\n\\emph{transparency} as a requirement for critical AI systems in order to\n``mitigate the risks to fundamental rights''. Post-hoc explanations seamlessly\nalign with this goal and extensive literature on the subject produced several\nforms of such objects, graphs being one of them. Early studies in visualization\ndemonstrated the graphs' ability to improve user understanding, positioning\nthem as potentially ideal explanations. However, it remains unclear how\ngraph-based explanations compare to other explanation designs. In this work, we\naim to determine the effectiveness of graph-based explanations in improving\nusers' perception of AI-based recommendations using a mixed-methods approach.\nWe first conduct a qualitative study to collect users' requirements for graph\nexplanations. We then run a larger quantitative study in which we evaluate the\ninfluence of various explanation designs, including enhanced graph-based ones,\non aspects such as understanding, usability and curiosity toward the AI system.\nWe find that users perceive graph-based explanations as more usable than\ndesigns involving feature importance. However, we also reveal that textual\nexplanations lead to higher objective understanding than graph-based designs.\nMost importantly, we highlight the strong contrast between participants'\nexpressed preferences for graph design and their actual ratings using it, which\nare lower compared to textual design. These findings imply that meeting\nstakeholders' expressed preferences might not alone guarantee ``good''\nexplanations. Therefore, crafting hybrid designs successfully balancing social\nexpectations with downstream performance emerges as a significant challenge.","authors":["Simon Delarue","Astrid Bertrand","Tiphaine Viard"],"pdf_link":"http://arxiv.org/pdf/2407.12357v1","category":["Explainable AI","AI in Healthcare"]},{"title":"Improving the classification of extreme classes by means of loss regularisation and generalised beta distributions","abstract":"An ordinal classification problem is one in which the target variable takes\nvalues on an ordinal scale. Nowadays, there are many of these problems\nassociated with real-world tasks where it is crucial to accurately classify the\nextreme classes of the ordinal structure. In this work, we propose a unimodal\nregularisation approach that can be applied to any loss function to improve the\nclassification performance of the first and last classes while maintaining good\nperformance for the remainder. The proposed methodology is tested on six\ndatasets with different numbers of classes, and compared with other unimodal\nregularisation methods in the literature. In addition, performance in the\nextreme classes is compared using a new metric that takes into account their\nsensitivities. Experimental results and statistical analysis show that the\nproposed methodology obtains a superior average performance considering\ndifferent metrics. The results for the proposed metric show that the\ngeneralised beta distribution generally improves classification performance in\nthe extreme classes. At the same time, the other five nominal and ordinal\nmetrics considered show that the overall performance is aligned with the\nperformance of previous alternatives.","authors":["V\u00edctor Manuel Vargas","Pedro Antonio Guti\u00e9rrez","Javier Barbero-G\u00f3mez","C\u00e9sar Herv\u00e1s-Mart\u00ednez"],"pdf_link":"http://arxiv.org/pdf/2407.12417v1","category":["AI in Healthcare","Reinforcement Learning"]},{"title":"StuGPTViz: A Visual Analytics Approach to Understand Student-ChatGPT Interactions","abstract":"The integration of Large Language Models (LLMs), especially ChatGPT, into\neducation is poised to revolutionize students' learning experiences by\nintroducing innovative conversational learning methodologies. To empower\nstudents to fully leverage the capabilities of ChatGPT in educational\nscenarios, understanding students' interaction patterns with ChatGPT is crucial\nfor instructors. However, this endeavor is challenging due to the absence of\ndatasets focused on student-ChatGPT conversations and the complexities in\nidentifying and analyzing the evolutional interaction patterns within\nconversations. To address these challenges, we collected conversational data\nfrom 48 students interacting with ChatGPT in a master's level data\nvisualization course over one semester. We then developed a coding scheme,\ngrounded in the literature on cognitive levels and thematic analysis, to\ncategorize students' interaction patterns with ChatGPT. Furthermore, we present\na visual analytics system, StuGPTViz, that tracks and compares temporal\npatterns in student prompts and the quality of ChatGPT's responses at multiple\nscales, revealing significant pedagogical insights for instructors. We\nvalidated the system's effectiveness through expert interviews with six data\nvisualization instructors and three case studies. The results confirmed\nStuGPTViz's capacity to enhance educators' insights into the pedagogical value\nof ChatGPT. We also discussed the potential research opportunities of applying\nvisual analytics in education and developing AI-driven personalized learning\nsolutions.","authors":["Zixin Chen","Jiachen Wang","Meng Xia","Kento Shigyo","Dingdong Liu","Rong Zhang","Huamin Qu"],"pdf_link":"http://arxiv.org/pdf/2407.12423v1","category":["Speech Synthesis","Explainable AI"]},{"title":"Search Engines, LLMs or Both? Evaluating Information Seeking Strategies for Answering Health Questions","abstract":"Search engines have traditionally served as primary tools for information\nseeking. However, the new Large Language Models (LLMs) have recently\ndemonstrated remarkable capabilities in multiple tasks and, specifically, their\nadoption as question answering systems is becoming increasingly prevalent. It\nis expected that LLM-based conversational systems and traditional web engines\nwill continue to coexist in the future, supporting end users in various ways.\nBut there is a need for more scientific research on the effectiveness of both\ntypes of systems in facilitating accurate information seeking. In this study,\nwe focus on their merits in answering health questions. We conducted an\nextensive study comparing different web search engines, LLMs and\nretrieval-augmented (RAG) approaches. Our research reveals intriguing\nconclusions. For example, we observed that the quality of webpages potentially\nresponding to a health question does not decline as we navigate further down\nthe ranked lists. However, according to our evaluation, web engines are less\naccurate than LLMs in finding correct answers to health questions. On the other\nhand, LLMs are quite sensitive to the input prompts, and we also found out that\nRAG leads to highly effective information seeking methods.","authors":["Marcos Fern\u00e1ndez-Pichel","Juan C. Pichel","David E. Losada"],"pdf_link":"http://arxiv.org/pdf/2407.12468v2","category":["AI in Healthcare","LLMs"]},{"title":"A Methodology Establishing Linear Convergence of Adaptive Gradient Methods under PL Inequality","abstract":"Adaptive gradient-descent optimizers are the standard choice for training\nneural network models. Despite their faster convergence than gradient-descent\nand remarkable performance in practice, the adaptive optimizers are not as well\nunderstood as vanilla gradient-descent. A reason is that the dynamic update of\nthe learning rate that helps in faster convergence of these methods also makes\ntheir analysis intricate. Particularly, the simple gradient-descent method\nconverges at a linear rate for a class of optimization problems, whereas the\npractically faster adaptive gradient methods lack such a theoretical guarantee.\nThe Polyak-{\\L}ojasiewicz (PL) inequality is the weakest known class, for which\nlinear convergence of gradient-descent and its momentum variants has been\nproved. Therefore, in this paper, we prove that AdaGrad and Adam, two\nwell-known adaptive gradient methods, converge linearly when the cost function\nis smooth and satisfies the PL inequality. Our theoretical framework follows a\nsimple and unified approach, applicable to both batch and stochastic gradients,\nwhich can potentially be utilized in analyzing linear convergence of other\nvariants of Adam.","authors":["Kushal Chakrabarti","Mayank Baranwal"],"pdf_link":"http://arxiv.org/pdf/2407.12629v1","category":["Reinforcement Learning","Speech Recognition"]},{"title":"GraphMuse: A Library for Symbolic Music Graph Processing","abstract":"Graph Neural Networks (GNNs) have recently gained traction in symbolic music\ntasks, yet a lack of a unified framework impedes progress. Addressing this gap,\nwe present GraphMuse, a graph processing framework and library that facilitates\nefficient music graph processing and GNN training for symbolic music tasks.\nCentral to our contribution is a new neighbor sampling technique specifically\ntargeted toward meaningful behavior in musical scores. Additionally, GraphMuse\nintegrates hierarchical modeling elements that augment the expressivity and\ncapabilities of graph networks for musical tasks. Experiments with two specific\nmusical prediction tasks -- pitch spelling and cadence detection -- demonstrate\nsignificant performance improvement over previous methods. Our hope is that\nGraphMuse will lead to a boost in, and standardization of, symbolic music\nprocessing based on graph representations. The library is available at\nhttps://github.com/manoskary/graphmuse","authors":["Emmanouil Karystinaios","Gerhard Widmer"],"pdf_link":"http://arxiv.org/pdf/2407.12671v1","category":["Speech Recognition","Speech Synthesis"]},{"title":"A Unifying Post-Processing Framework for Multi-Objective Learn-to-Defer Problems","abstract":"Learn-to-Defer is a paradigm that enables learning algorithms to work not in\nisolation but as a team with human experts. In this paradigm, we permit the\nsystem to defer a subset of its tasks to the expert. Although there are\ncurrently systems that follow this paradigm and are designed to optimize the\naccuracy of the final human-AI team, the general methodology for developing\nsuch systems under a set of constraints (e.g., algorithmic fairness, expert\nintervention budget, defer of anomaly, etc.) remains largely unexplored. In\nthis paper, using a $d$-dimensional generalization to the fundamental lemma of\nNeyman and Pearson (d-GNP), we obtain the Bayes optimal solution for\nlearn-to-defer systems under various constraints. Furthermore, we design a\ngeneralizable algorithm to estimate that solution and apply this algorithm to\nthe COMPAS and ACSIncome datasets. Our algorithm shows improvements in terms of\nconstraint violation over a set of baselines.","authors":["Mohammad-Amin Charusaie","Samira Samadi"],"pdf_link":"http://arxiv.org/pdf/2407.12710v1","category":["Reinforcement Learning","Explainable AI"]}]