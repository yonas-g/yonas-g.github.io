[{"title":"Hide and Seek: Fingerprinting Large Language Models with Evolutionary Learning","abstract":"As content generated by Large Language Model (LLM) has grown exponentially,\nthe ability to accurately identify and fingerprint such text has become\nincreasingly crucial. In this work, we introduce a novel black-box approach for\nfingerprinting LLMs, achieving an impressive 72% accuracy in identifying the\ncorrect family of models (Such as Llama, Mistral, Gemma, etc) among a lineup of\nLLMs. We present an evolutionary strategy that leverages the capabilities of\none LLM to discover the most salient features for identifying other LLMs. Our\nmethod employs a unique \"Hide and Seek\" algorithm, where an Auditor LLM\ngenerates discriminative prompts, and a Detective LLM analyzes the responses to\nfingerprint the target models. This approach not only demonstrates the\nfeasibility of LLM-driven model identification but also reveals insights into\nthe semantic manifolds of different LLM families. By iteratively refining\nprompts through in-context learning, our system uncovers subtle distinctions\nbetween model outputs, providing a powerful tool for LLM analysis and\nverification. This research opens new avenues for understanding LLM behavior\nand has significant implications for model attribution, security, and the\nbroader field of AI transparency.","authors":["Dmitri Iourovitski","Sanat Sharma","Rakshak Talwar"],"pdf_link":"http://arxiv.org/pdf/2408.02871v1","category":["LLMs","Explainable AI"]},{"title":"A Taxonomy of Architecture Options for Foundation Model-based Agents: Analysis and Decision Model","abstract":"The rapid advancement of AI technology has led to widespread applications of\nagent systems across various domains. However, the need for detailed\narchitecture design poses significant challenges in designing and operating\nthese systems. This paper introduces a taxonomy focused on the architectures of\nfoundation-model-based agents, addressing critical aspects such as functional\ncapabilities and non-functional qualities. We also discuss the operations\ninvolved in both design-time and run-time phases, providing a comprehensive\nview of architectural design and operational characteristics. By unifying and\ndetailing these classifications, our taxonomy aims to improve the design of\nfoundation-model-based agents. Additionally, the paper establishes a decision\nmodel that guides critical design and runtime decisions, offering a structured\napproach to enhance the development of foundation-model-based agents. Our\ncontributions include providing a structured architecture design option and\nguiding the development process of foundation-model-based agents, thereby\naddressing current fragmentation in the field.","authors":["Jingwen Zhou","Qinghua Lu","Jieshan Chen","Liming Zhu","Xiwei Xu","Zhenchang Xing","Stefan Harrer"],"pdf_link":"http://arxiv.org/pdf/2408.02920v1","category":["Explainable AI","Reinforcement Learning"]},{"title":"The Need for a Big World Simulator: A Scientific Challenge for Continual Learning","abstract":"The \"small agent, big world\" frame offers a conceptual view that motivates\nthe need for continual learning. The idea is that a small agent operating in a\nmuch bigger world cannot store all information that the world has to offer. To\nperform well, the agent must be carefully designed to ingest, retain, and eject\nthe right information. To enable the development of performant continual\nlearning agents, a number of synthetic environments have been proposed.\nHowever, these benchmarks suffer from limitations, including unnatural\ndistribution shifts and a lack of fidelity to the \"small agent, big world\"\nframing. This paper aims to formalize two desiderata for the design of future\nsimulated environments. These two criteria aim to reflect the objectives and\ncomplexity of continual learning in practical settings while enabling rapid\nprototyping of algorithms on a smaller scale.","authors":["Saurabh Kumar","Hong Jun Jeon","Alex Lewandowski","Benjamin Van Roy"],"pdf_link":"http://arxiv.org/pdf/2408.02930v1","category":["Reinforcement Learning","Explainable AI"]},{"title":"LLM-Empowered Resource Allocation in Wireless Communications Systems","abstract":"The recent success of large language models (LLMs) has spurred their\napplication in various fields. In particular, there have been efforts to\nintegrate LLMs into various aspects of wireless communication systems. The use\nof LLMs in wireless communication systems has the potential to realize\nartificial general intelligence (AGI)-enabled wireless networks. In this paper,\nwe investigate an LLM-based resource allocation scheme for wireless\ncommunication systems. Specifically, we formulate a simple resource allocation\nproblem involving two transmit pairs and develop an LLM-based resource\nallocation approach that aims to maximize either energy efficiency or spectral\nefficiency. Additionally, we consider the joint use of low-complexity resource\nallocation techniques to compensate for the reliability shortcomings of the\nLLM-based scheme. After confirming the applicability and feasibility of\nLLM-based resource allocation, we address several key technical challenges that\nremain in applying LLMs in practice.","authors":["Woongsup Lee","Jeonghun Park"],"pdf_link":"http://arxiv.org/pdf/2408.02944v1","category":["Speech Recognition","LLMs"]},{"title":"Scaling Laws for Data Poisoning in LLMs","abstract":"Recent work shows that LLMs are vulnerable to data poisoning, in which they\nare trained on partially corrupted or harmful data. Poisoned data is hard to\ndetect, breaks guardrails, and leads to undesirable and harmful behavior. Given\nthe intense efforts by leading labs to train and deploy increasingly larger and\nmore capable LLMs, it is critical to ask if the risk of data poisoning will be\nnaturally mitigated by scale, or if it is an increasing threat. We consider\nthree threat models by which data poisoning can occur: malicious fine-tuning,\nimperfect data curation, and intentional data contamination. Our experiments\nevaluate the effects of data poisoning on 23 frontier LLMs ranging from 1.5-72\nbillion parameters on three datasets which speak to each of our threat models.\nWe find that larger LLMs are increasingly vulnerable, learning harmful behavior\n-- including sleeper agent behavior -- significantly more quickly than smaller\nLLMs with even minimal data poisoning. These results underscore the need for\nrobust safeguards against data poisoning in larger LLMs.","authors":["Dillon Bowen","Brendan Murphy","Will Cai","David Khachaturov","Adam Gleave","Kellin Pelrine"],"pdf_link":"http://arxiv.org/pdf/2408.02946v1","category":["Datasets","Explainable AI"]},{"title":"Anytime Multi-Agent Path Finding with an Adaptive Delay-Based Heuristic","abstract":"Anytime multi-agent path finding (MAPF) is a promising approach to scalable\npath optimization in multi-agent systems. MAPF-LNS, based on Large Neighborhood\nSearch (LNS), is the current state-of-the-art approach where a fast initial\nsolution is iteratively optimized by destroying and repairing selected paths of\nthe solution. Current MAPF-LNS variants commonly use an adaptive selection\nmechanism to choose among multiple destroy heuristics. However, to determine\npromising destroy heuristics, MAPF-LNS requires a considerable amount of\nexploration time. As common destroy heuristics are non-adaptive, any\nperformance bottleneck caused by these heuristics cannot be overcome via\nadaptive heuristic selection alone, thus limiting the overall effectiveness of\nMAPF-LNS in terms of solution cost. In this paper, we propose Adaptive\nDelay-based Destroy-and-Repair Enhanced with Success-based Self-Learning\n(ADDRESS) as a single-destroy-heuristic variant of MAPF-LNS. ADDRESS applies\nrestricted Thompson Sampling to the top-K set of the most delayed agents to\nselect a seed agent for adaptive LNS neighborhood generation. We evaluate\nADDRESS in multiple maps from the MAPF benchmark set and demonstrate cost\nimprovements by at least 50% in large-scale scenarios with up to a thousand\nagents, compared with the original MAPF-LNS and other state-of-the-art methods.","authors":["Thomy Phan","Benran Zhang","Shao-Hung Chan","Sven Koenig"],"pdf_link":"http://arxiv.org/pdf/2408.02960v1","category":["Reinforcement Learning","Explainable AI"]},{"title":"LLMs as Probabilistic Minimally Adequate Teachers for DFA Learning","abstract":"The emergence of intelligence in large language models (LLMs) has inspired\ninvestigations into their integration into automata learning. This paper\nintroduces the probabilistic Minimally Adequate Teacher (pMAT) formulation,\nwhich leverages a probabilistic oracle that could give persistent errors\nrandomly during answering the membership queries for deterministic finite\nautomata (DFA) learning. Given the tendency of LLMs to produce hallucinatory\ncontent, we have developed techniques to improve answer accuracy and ensure the\ncorrectness of the learned automata. We propose the $\\mathtt{Discrimination}$\nprompt as well as the $\\mathtt{Verification}$ prompt and explore their\nadvantages over common prompts. Additionally, we compare DFA learning\nperformance between the TTT algorithm and common active learning algorithms. To\naddress the exponential number of persistent errors, we implement a dynamic\nquery cache refinement algorithm that identifies and corrects conflicting\nqueries by combining the active and passive learning algorithms. The empirical\nresults demonstrate the robustness and efficiency of our approach, providing a\ntheoretical foundation for automata learning with LLMs in the loop.","authors":["Lekai Chen","Ashutosh Trivedi","Alvaro Velasquez"],"pdf_link":"http://arxiv.org/pdf/2408.02999v1","category":["LLMs","Speech Recognition"]},{"title":"Cross-cultural analysis of pedestrian group behaviour influence on crossing decisions in interactions with autonomous vehicles","abstract":"Understanding cultural backgrounds is crucial for the seamless integration of\nautonomous driving into daily life as it ensures that systems are attuned to\ndiverse societal norms and behaviours, enhancing acceptance and safety in\nvaried cultural contexts. In this work, we investigate the impact of co-located\npedestrians on crossing behaviour, considering cultural and situational\nfactors. To accomplish this, a full-scale virtual reality (VR) environment was\ncreated in the CARLA simulator, enabling the identical experiment to be\nreplicated in both Spain and Australia. Participants (N=30) attempted to cross\nthe road at an urban crosswalk alongside other pedestrians exhibiting\nconservative to more daring behaviours, while an autonomous vehicle (AV)\napproached with different driving styles. For the analysis of interactions, we\nutilized questionnaires and direct measures of the moment when participants\nentered the lane.\n  Our findings indicate that pedestrians tend to cross the same traffic gap\ntogether, even though reckless behaviour by the group reduces confidence and\nmakes the situation perceived as more complex. Australian participants were\nwilling to take fewer risks than Spanish participants, adopting more cautious\nbehaviour when it was uncertain whether the AV would yield.","authors":["Sergio Mart\u00edn Serrano","\u00d3scar M\u00e9ndez Blanco","Stewart Worrall","Miguel \u00c1ngel Sotelo","David Fern\u00e1ndez-Llorca"],"pdf_link":"http://arxiv.org/pdf/2408.03003v1","category":["Explainable AI","Multimodal Learning"]},{"title":"NeurDB: On the Design and Implementation of an AI-powered Autonomous Database","abstract":"Databases are increasingly embracing AI to provide autonomous system\noptimization and intelligent in-database analytics, aiming to relieve end-user\nburdens across various industry sectors. Nonetheless, most existing approaches\nfail to account for the dynamic nature of databases, which renders them\nineffective for real-world applications characterized by evolving data and\nworkloads. This paper introduces NeurDB, an AI-powered autonomous database that\ndeepens the fusion of AI and databases with adaptability to data and workload\ndrift. NeurDB establishes a new in-database AI ecosystem that seamlessly\nintegrates AI workflows within the database. This integration enables efficient\nand effective in-database AI analytics and fast-adaptive learned system\ncomponents. Empirical evaluations demonstrate that NeurDB substantially\noutperforms existing solutions in managing AI analytics tasks, with the\nproposed learned components more effectively handling environmental dynamism\nthan state-of-the-art approaches.","authors":["Zhanhao Zhao","Shaofeng Cai","Haotian Gao","Hexiang Pan","Siqi Xiang","Naili Xing","Gang Chen","Beng Chin Ooi","Yanyan Shen","Yuncheng Wu","Meihui Zhang"],"pdf_link":"http://arxiv.org/pdf/2408.03013v1","category":["Datasets","AI in Healthcare"]},{"title":"Highly Efficient Self-Adaptive Reward Shaping for Reinforcement Learning","abstract":"Reward shaping addresses the challenge of sparse rewards in reinforcement\nlearning by constructing denser and more informative reward signals. To achieve\nself-adaptive and highly efficient reward shaping, we propose a novel method\nthat incorporates success rates derived from historical experiences into shaped\nrewards. Our approach utilizes success rates sampled from Beta distributions,\nwhich dynamically evolve from uncertain to reliable values as more data is\ncollected. Initially, the self-adaptive success rates exhibit more randomness\nto encourage exploration. Over time, they become more certain to enhance\nexploitation, thus achieving a better balance between exploration and\nexploitation. We employ Kernel Density Estimation (KDE) combined with Random\nFourier Features (RFF) to derive the Beta distributions, resulting in a\ncomputationally efficient implementation in high-dimensional continuous state\nspaces. This method provides a non-parametric and learning-free approach. The\nproposed method is evaluated on a wide range of continuous control tasks with\nsparse and delayed rewards, demonstrating significant improvements in sample\nefficiency and convergence stability compared to relevant baselines.","authors":["Haozhe Ma","Zhengding Luo","Thanh Vinh Vo","Kuankuan Sima","Tze-Yun Leong"],"pdf_link":"http://arxiv.org/pdf/2408.03029v2","category":["Reinforcement Learning","Multimodal Learning"]},{"title":"Learning Provably Robust Policies in Uncertain Parametric Environments","abstract":"We present a data-driven approach for learning MDP policies that are robust\nacross stochastic environments whose transition probabilities are defined by\nparameters with an unknown distribution. We produce probably approximately\ncorrect (PAC) guarantees for the performance of these learned policies in a\nnew, unseen environment over the unknown distribution. Our approach is based on\nfinite samples of the MDP environments, for each of which we build an\napproximation of the model as an interval MDP, by exploring a set of generated\ntrajectories. We use the built approximations to synthesise a single policy\nthat performs well (meets given requirements) across the sampled environments,\nand furthermore bound its risk (of not meeting the given requirements) when\ndeployed in an unseen environment. Our procedure offers a trade-off between the\nguaranteed performance of the learned policy and the risk of not meeting the\nguarantee in an unseen environment. Our approach exploits knowledge of the\nenvironment's state space and graph structure, and we show how additional\nknowledge of its parametric structure can be leveraged to optimize learning and\nto obtain tighter guarantees from less samples. We evaluate our approach on a\ndiverse range of established benchmarks, demonstrating that we can generate\nhighly performing and robust policies, along with guarantees that tightly\nquantify their performance and the associated risk.","authors":["Yannik Schnitzer","Alessandro Abate","David Parker"],"pdf_link":"http://arxiv.org/pdf/2408.03093v1","category":["Reinforcement Learning","Explainable AI"]},{"title":"MLC-GCN: Multi-Level Generated Connectome Based GCN for AD Analysis","abstract":"Alzheimer's Disease (AD) is a currently incurable neurodegeneartive disease.\nAccurately detecting AD, especially in the early stage, represents a high\nresearch priority. AD is characterized by progressive cognitive impairments\nthat are related to alterations in brain functional connectivity (FC). Based on\nthis association, many studies have been published over the decades using FC\nand machine learning to differentiate AD from healthy aging. The most recent\ndevelopment in this detection method highlights the use of graph neural network\n(GNN) as the brain functionality analysis. In this paper, we proposed a stack\nof spatio-temporal feature extraction and graph generation based AD\nclassification model using resting state fMRI. The proposed multi-level\ngenerated connectome (MLC) based graph convolutional network (GCN) (MLC-GCN)\ncontains a multi-graph generation block and a GCN prediction block. The\nmulti-graph generation block consists of a hierarchy of spatio-temporal feature\nextraction layers for extracting spatio-temporal rsfMRI features at different\ndepths and building the corresponding connectomes. The GCN prediction block\ntakes the learned multi-level connectomes to build and optimize GCNs at each\nlevel and concatenates the learned graphical features as the final predicting\nfeatures for AD classification. Through independent cohort validations, MLC-GCN\nshows better performance for differentiating MCI, AD, and normal aging than\nstate-of-art GCN and rsfMRI based AD classifiers. The proposed MLC-GCN also\nshowed high explainability in terms of learning clinically reasonable\nconnectome node and connectivity features from two independent datasets. While\nwe only tested MLC-GCN on AD, the basic rsfMRI-based multi-level learned GCN\nbased outcome prediction strategy is valid for other diseases or clinical\noutcomes.","authors":["Wenqi Zhu","Yinghua Fu","Ze Wang"],"pdf_link":"http://arxiv.org/pdf/2408.03358v1","category":["AI in Healthcare","Explainable AI"]},{"title":"Compress and Compare: Interactively Evaluating Efficiency and Behavior Across ML Model Compression Experiments","abstract":"To deploy machine learning models on-device, practitioners use compression\nalgorithms to shrink and speed up models while maintaining their high-quality\noutput. A critical aspect of compression in practice is model comparison,\nincluding tracking many compression experiments, identifying subtle changes in\nmodel behavior, and negotiating complex accuracy-efficiency trade-offs.\nHowever, existing compression tools poorly support comparison, leading to\ntedious and, sometimes, incomplete analyses spread across disjoint tools. To\nsupport real-world comparative workflows, we develop an interactive visual\nsystem called Compress and Compare. Within a single interface, Compress and\nCompare surfaces promising compression strategies by visualizing provenance\nrelationships between compressed models and reveals compression-induced\nbehavior changes by comparing models' predictions, weights, and activations. We\ndemonstrate how Compress and Compare supports common compression analysis tasks\nthrough two case studies, debugging failed compression on generative language\nmodels and identifying compression artifacts in image classification models. We\nfurther evaluate Compress and Compare in a user study with eight compression\nexperts, illustrating its potential to provide structure to compression\nworkflows, help practitioners build intuition about compression, and encourage\nthorough analysis of compression's effect on model behavior. Through these\nevaluations, we identify compression-specific challenges that future visual\nanalytics tools should consider and Compress and Compare visualizations that\nmay generalize to broader model comparison tasks.","authors":["Angie Boggust","Venkatesh Sivaraman","Yannick Assogba","Donghao Ren","Dominik Moritz","Fred Hohman"],"pdf_link":"http://arxiv.org/pdf/2408.03274v1","category":["Explainable AI","Benchmarking"]},{"title":"Prioritize Alignment in Dataset Distillation","abstract":"Dataset Distillation aims to compress a large dataset into a significantly\nmore compact, synthetic one without compromising the performance of the trained\nmodels. To achieve this, existing methods use the agent model to extract\ninformation from the target dataset and embed it into the distilled dataset.\nConsequently, the quality of extracted and embedded information determines the\nquality of the distilled dataset. In this work, we find that existing methods\nintroduce misaligned information in both information extraction and embedding\nstages. To alleviate this, we propose Prioritize Alignment in Dataset\nDistillation (PAD), which aligns information from the following two\nperspectives. 1) We prune the target dataset according to the compressing ratio\nto filter the information that can be extracted by the agent model. 2) We use\nonly deep layers of the agent model to perform the distillation to avoid\nexcessively introducing low-level information. This simple strategy effectively\nfilters out misaligned information and brings non-trivial improvement for\nmainstream matching-based distillation algorithms. Furthermore, built on\ntrajectory matching, \\textbf{PAD} achieves remarkable improvements on various\nbenchmarks, achieving state-of-the-art performance.","authors":["Zekai Li","Ziyao Guo","Wangbo Zhao","Tianle Zhang","Zhi-Qi Cheng","Samir Khaki","Kaipeng Zhang","Ahmad Sajed","Konstantinos N Plataniotis","Kai Wang","Yang You"],"pdf_link":"http://arxiv.org/pdf/2408.03360v1","category":["Datasets","Explainable AI"]},{"title":"RHiOTS: A Framework for Evaluating Hierarchical Time Series Forecasting Algorithms","abstract":"We introduce the Robustness of Hierarchically Organized Time Series (RHiOTS)\nframework, designed to assess the robustness of hierarchical time series\nforecasting models and algorithms on real-world datasets. Hierarchical time\nseries, where lower-level forecasts must sum to upper-level ones, are prevalent\nin various contexts, such as retail sales across countries. Current empirical\nevaluations of forecasting methods are often limited to a small set of\nbenchmark datasets, offering a narrow view of algorithm behavior. RHiOTS\naddresses this gap by systematically altering existing datasets and modifying\nthe characteristics of individual series and their interrelations. It uses a\nset of parameterizable transformations to simulate those changes in the data\ndistribution. Additionally, RHiOTS incorporates an innovative visualization\ncomponent, turning complex, multidimensional robustness evaluation results into\nintuitive, easily interpretable visuals. This approach allows an in-depth\nanalysis of algorithm and model behavior under diverse conditions. We\nillustrate the use of RHiOTS by analyzing the predictive performance of several\nalgorithms. Our findings show that traditional statistical methods are more\nrobust than state-of-the-art deep learning algorithms, except when the\ntransformation effect is highly disruptive. Furthermore, we found no\nsignificant differences in the robustness of the algorithms when applying\nspecific reconciliation methods, such as MinT. RHiOTS provides researchers with\na comprehensive tool for understanding the nuanced behavior of forecasting\nalgorithms, offering a more reliable basis for selecting the most appropriate\nmethod for a given problem.","authors":["Luis Roque","Carlos Soares","Lu\u00eds Torgo"],"pdf_link":"http://arxiv.org/pdf/2408.03399v1","category":["Explainable AI","Datasets"]},{"title":"Attacks and Defenses for Generative Diffusion Models: A Comprehensive Survey","abstract":"Diffusion models (DMs) have achieved state-of-the-art performance on various\ngenerative tasks such as image synthesis, text-to-image, and text-guided\nimage-to-image generation. However, the more powerful the DMs, the more harmful\nthey potentially are. Recent studies have shown that DMs are prone to a wide\nrange of attacks, including adversarial attacks, membership inference, backdoor\ninjection, and various multi-modal threats. Since numerous pre-trained DMs are\npublished widely on the Internet, potential threats from these attacks are\nespecially detrimental to the society, making DM-related security a worth\ninvestigating topic. Therefore, in this paper, we conduct a comprehensive\nsurvey on the security aspect of DMs, focusing on various attack and defense\nmethods for DMs. First, we present crucial knowledge of DMs with five main\ntypes of DMs, including denoising diffusion probabilistic models, denoising\ndiffusion implicit models, noise conditioned score networks, stochastic\ndifferential equations, and multi-modal conditional DMs. We further survey a\nvariety of recent studies investigating different types of attacks that exploit\nthe vulnerabilities of DMs. Then, we thoroughly review potential\ncountermeasures to mitigate each of the presented threats. Finally, we discuss\nopen challenges of DM-related security and envision certain research directions\nfor this topic.","authors":["Vu Tuan Truong","Luan Ba Dang","Long Bao Le"],"pdf_link":"http://arxiv.org/pdf/2408.03400v1","category":["Multimodal Learning","Explainable AI"]},{"title":"Combining Diverse Information for Coordinated Action: Stochastic Bandit Algorithms for Heterogeneous Agents","abstract":"Stochastic multi-agent multi-armed bandits typically assume that the rewards\nfrom each arm follow a fixed distribution, regardless of which agent pulls the\narm. However, in many real-world settings, rewards can depend on the\nsensitivity of each agent to their environment. In medical screening, disease\ndetection rates can vary by test type; in preference matching, rewards can\ndepend on user preferences; and in environmental sensing, observation quality\ncan vary across sensors. Since past work does not specify how to allocate\nagents of heterogeneous but known sensitivity of these types in a stochastic\nbandit setting, we introduce a UCB-style algorithm, Min-Width, which aggregates\ninformation from diverse agents. In doing so, we address the joint challenges\nof (i) aggregating the rewards, which follow different distributions for each\nagent-arm pair, and (ii) coordinating the assignments of agents to arms.\nMin-Width facilitates efficient collaboration among heterogeneous agents,\nexploiting the known structure in the agents' reward functions to weight their\nrewards accordingly. We analyze the regret of Min-Width and conduct\npseudo-synthetic and fully synthetic experiments to study the performance of\ndifferent levels of information sharing. Our results confirm that the gains to\nmodeling agent heterogeneity tend to be greater when the sensitivities are more\nvaried across agents, while combining more information does not always improve\nperformance.","authors":["Lucia Gordon","Esther Rolf","Milind Tambe"],"pdf_link":"http://arxiv.org/pdf/2408.03405v1","category":["Reinforcement Learning","Explainable AI"]},{"title":"Identifying treatment response subgroups in observational time-to-event data","abstract":"Identifying patient subgroups with different treatment responses is an\nimportant task to inform medical recommendations, guidelines, and the design of\nfuture clinical trials. Existing approaches for subgroup analysis primarily\nfocus on Randomised Controlled Trials (RCTs), in which treatment assignment is\nrandomised. Furthermore, the patient cohort of an RCT is often constrained by\ncost, and is not representative of the heterogeneity of patients likely to\nreceive treatment in real-world clinical practice. Therefore, when applied to\nobservational studies, such approaches suffer from significant statistical\nbiases because of the non-randomisation of treatment. Our work introduces a\nnovel, outcome-guided method for identifying treatment response subgroups in\nobservational studies. Our approach assigns each patient to a subgroup\nassociated with two time-to-event distributions: one under treatment and one\nunder control regime. It hence positions itself in between individualised and\naverage treatment effect estimation. The assumptions of our model result in a\nsimple correction of the statistical bias from treatment non-randomisation\nthrough inverse propensity weighting. In experiments, our approach\nsignificantly outperforms the current state-of-the-art method for\noutcome-guided subgroup analysis in both randomised and observational treatment\nregimes.","authors":["Vincent Jeanselme","Chang Ho Yoon","Fabian Falck","Brian Tom","Jessica Barrett"],"pdf_link":"http://arxiv.org/pdf/2408.03463v1","category":["Datasets","AI in Healthcare"]},{"title":"Can LLMs Serve As Time Series Anomaly Detectors?","abstract":"An emerging topic in large language models (LLMs) is their application to\ntime series forecasting, characterizing mainstream and patternable\ncharacteristics of time series. A relevant but rarely explored and more\nchallenging question is whether LLMs can detect and explain time series\nanomalies, a critical task across various real-world applications. In this\npaper, we investigate the capabilities of LLMs, specifically GPT-4 and LLaMA3,\nin detecting and explaining anomalies in time series. Our studies reveal that:\n1) LLMs cannot be directly used for time series anomaly detection. 2) By\ndesigning prompt strategies such as in-context learning and chain-of-thought\nprompting, GPT-4 can detect time series anomalies with results competitive to\nbaseline methods. 3) We propose a synthesized dataset to automatically generate\ntime series anomalies with corresponding explanations. By applying instruction\nfine-tuning on this dataset, LLaMA3 demonstrates improved performance in time\nseries anomaly detection tasks. In summary, our exploration shows the promising\npotential of LLMs as time series anomaly detectors.","authors":["Manqing Dong","Hao Huang","Longbing Cao"],"pdf_link":"http://arxiv.org/pdf/2408.03475v1","category":["LLMs","Explainable AI"]},{"title":"Harnessing the Power of LLMs in Source Code Vulnerability Detection","abstract":"Software vulnerabilities, caused by unintentional flaws in source code, are a\nprimary root cause of cyberattacks. Static analysis of source code has been\nwidely used to detect these unintentional defects introduced by software\ndevelopers. Large Language Models (LLMs) have demonstrated human-like\nconversational abilities due to their capacity to capture complex patterns in\nsequential data, such as natural languages. In this paper, we harness LLMs'\ncapabilities to analyze source code and detect known vulnerabilities. To ensure\nthe proposed vulnerability detection method is universal across multiple\nprogramming languages, we convert source code to LLVM IR and train LLMs on\nthese intermediate representations. We conduct extensive experiments on various\nLLM architectures and compare their accuracy. Our comprehensive experiments on\nreal-world and synthetic codes from NVD and SARD demonstrate high accuracy in\nidentifying source code vulnerabilities.","authors":["Andrew A Mahyari"],"pdf_link":"http://arxiv.org/pdf/2408.03489v1","category":["Speech Recognition","LLMs"]},{"title":"Advanced User Credit Risk Prediction Model using LightGBM, XGBoost and Tabnet with SMOTEENN","abstract":"Bank credit risk is a significant challenge in modern financial transactions,\nand the ability to identify qualified credit card holders among a large number\nof applicants is crucial for the profitability of a bank'sbank's credit card\nbusiness. In the past, screening applicants'applicants' conditions often\nrequired a significant amount of manual labor, which was time-consuming and\nlabor-intensive. Although the accuracy and reliability of previously used ML\nmodels have been continuously improving, the pursuit of more reliable and\npowerful AI intelligent models is undoubtedly the unremitting pursuit by major\nbanks in the financial industry. In this study, we used a dataset of over\n40,000 records provided by a commercial bank as the research object. We\ncompared various dimensionality reduction techniques such as PCA and T-SNE for\npreprocessing high-dimensional datasets and performed in-depth adaptation and\ntuning of distributed models such as LightGBM and XGBoost, as well as deep\nmodels like Tabnet. After a series of research and processing, we obtained\nexcellent research results by combining SMOTEENN with these techniques. The\nexperiments demonstrated that LightGBM combined with PCA and SMOTEENN\ntechniques can assist banks in accurately predicting potential high-quality\ncustomers, showing relatively outstanding performance compared to other models.","authors":["Chang Yu","Yixin Jin","Qianwen Xing","Ye Zhang","Shaobo Guo","Shuchen Meng"],"pdf_link":"http://arxiv.org/pdf/2408.03497v1","category":["Datasets","AI in Healthcare"]},{"title":"RepoMasterEval: Evaluating Code Completion via Real-World Repositories","abstract":"With the growing reliance on automated code completion tools in software\ndevelopment, the need for robust evaluation benchmarks has become critical.\nHowever, existing benchmarks focus more on code generation tasks in function\nand class level and provide rich text description to prompt the model. By\ncontrast, such descriptive prompt is commonly unavailable in real development\nand code completion can occur in wider range of situations such as in the\nmiddle of a function or a code block. These limitations makes the evaluation\npoorly align with the practical scenarios of code completion tools. In this\npaper, we propose RepoMasterEval, a novel benchmark for evaluating code\ncompletion models constructed from real-world Python and TypeScript\nrepositories. Each benchmark datum is generated by masking a code snippet\n(ground truth) from one source code file with existing test suites. To improve\ntest accuracy of model generated code, we employ mutation testing to measure\nthe effectiveness of the test cases and we manually crafted new test cases for\nthose test suites with low mutation score. Our empirical evaluation on 6\nstate-of-the-art models shows that test argumentation is critical in improving\nthe accuracy of the benchmark and RepoMasterEval is able to report difference\nin model performance in real-world scenarios. The deployment of RepoMasterEval\nin a collaborated company for one month also revealed that the benchmark is\nuseful to give accurate feedback during model training and the score is in high\ncorrelation with the model's performance in practice. Based on our findings, we\ncall for the software engineering community to build more LLM benchmarks\ntailored for code generation tools taking the practical and complex development\nenvironment into consideration.","authors":["Qinyun Wu","Chao Peng","Pengfei Gao","Ruida Hu","Haoyu Gan","Bo Jiang","Jinhe Tang","Zhiwen Deng","Zhanming Guan","Cuiyun Gao","Xia Liu","Ping Yang"],"pdf_link":"http://arxiv.org/pdf/2408.03519v1","category":["Benchmarking","LLMs"]},{"title":"Exploring the extent of similarities in software failures across industries using LLMs","abstract":"The rapid evolution of software development necessitates enhanced safety\nmeasures. Extracting information about software failures from companies is\nbecoming increasingly more available through news articles.\n  This research utilizes the Failure Analysis Investigation with LLMs (FAIL)\nmodel to extract industry-specific information. Although the FAIL model's\ndatabase is rich in information, it could benefit from further categorization\nand industry-specific insights to further assist software engineers.\n  In previous work news articles were collected from reputable sources and\ncategorized by incidents inside a database. Prompt engineering and Large\nLanguage Models (LLMs) were then applied to extract relevant information\nregarding the software failure. This research extends these methods by\ncategorizing articles into specific domains and types of software failures. The\nresults are visually represented through graphs.\n  The analysis shows that throughout the database some software failures occur\nsignificantly more often in specific industries. This categorization provides a\nvaluable resource for software engineers and companies to identify and address\ncommon failures.\n  This research highlights the synergy between software engineering and Large\nLanguage Models (LLMs) to automate and enhance the analysis of software\nfailures. By transforming data from the database into an industry specific\nmodel, we provide a valuable resource that can be used to identify common\nvulnerabilities, predict potential risks, and implement proactive measures for\npreventing software failures. Leveraging the power of the current FAIL database\nand data visualization, we aim to provide an avenue for safer and more secure\nsoftware in the future.","authors":["Martin Detloff"],"pdf_link":"http://arxiv.org/pdf/2408.03528v2","category":["Datasets","AI in Healthcare"]},{"title":"Lifelong Personalized Low-Rank Adaptation of Large Language Models for Recommendation","abstract":"We primarily focus on the field of large language models (LLMs) for\nrecommendation, which has been actively explored recently and poses a\nsignificant challenge in effectively enhancing recommender systems with logical\nreasoning abilities and open-world knowledge. Current mainstream efforts mainly\ncenter around injecting personalized information from recommendation models\ninto LLMs by customizing input templates or aligning representations between\nsemantic and recommendation spaces at the prediction layer. However, they face\nthree significant limitations: (1) LoRA is mostly used as a core component in\nexisting works, but personalization is not well established in LoRA parameters\nas the LoRA matrix shared by every user may not cater to different users'\ncharacteristics, leading to suboptimal performance. (2) Although lifelong\npersonalized behavior sequences are ideal for personalization, their use raises\neffectiveness and efficiency issues since LLMs require escalating training and\ninference time to extend text lengths. (3) Existing approaches aren't scalable\nfor large datasets due to training efficiency constraints. Thus, LLMs only see\na small fraction of the datasets (e.g., less than 10%) instead of the whole\ndatasets, limiting their exposure to the full training space. To address these\nproblems, we propose RecLoRA. This model incorporates a Personalized LoRA\nmodule that maintains independent LoRAs for different users and a Long-Short\nModality Retriever that retrieves different history lengths for different\nmodalities, significantly improving performance while adding minimal time cost.\nFurthermore, we design a Few2Many Learning Strategy, using a conventional\nrecommendation model as a lens to magnify small training spaces to full spaces.\nExtensive experiments on public datasets demonstrate the efficacy of our\nRecLoRA compared to existing baseline models.","authors":["Jiachen Zhu","Jianghao Lin","Xinyi Dai","Bo Chen","Rong Shan","Jieming Zhu","Ruiming Tang","Yong Yu","Weinan Zhang"],"pdf_link":"http://arxiv.org/pdf/2408.03533v1","category":["LLMs","Speech Recognition"]},{"title":"2D-OOB: Attributing Data Contribution through Joint Valuation Framework","abstract":"Data valuation has emerged as a powerful framework to quantify the\ncontribution of each datum to the training of a particular machine learning\nmodel. However, it is crucial to recognize that the quality of various cells\nwithin a single data point can vary greatly in practice. For example, even in\nthe case of an abnormal data point, not all cells are necessarily noisy. The\nsingle scalar valuation assigned by existing methods blurs the distinction\nbetween noisy and clean cells of a data point, thereby compromising the\ninterpretability of the valuation. In this paper, we propose 2D-OOB, an\nout-of-bag estimation framework for jointly determining helpful (or\ndetrimental) samples, as well as the particular cells that drive them. Our\ncomprehensive experiments demonstrate that 2D-OOB achieves state-of-the-art\nperformance across multiple use cases, while being exponentially faster. 2D-OOB\nexcels in detecting and rectifying fine-grained outliers at the cell level, as\nwell as localizing backdoor triggers in data poisoning attacks.","authors":["Yifan Sun","Jingyan Shen","Yongchan Kwon"],"pdf_link":"http://arxiv.org/pdf/2408.03572v1","category":["Datasets","Explainable AI"]},{"title":"Hierarchical Neural Constructive Solver for Real-world TSP Scenarios","abstract":"Existing neural constructive solvers for routing problems have predominantly\nemployed transformer architectures, conceptualizing the route construction as a\nset-to-sequence learning task. However, their efficacy has primarily been\ndemonstrated on entirely random problem instances that inadequately capture\nreal-world scenarios. In this paper, we introduce realistic Traveling Salesman\nProblem (TSP) scenarios relevant to industrial settings and derive the\nfollowing insights: (1) The optimal next node (or city) to visit often lies\nwithin proximity to the current node, suggesting the potential benefits of\nbiasing choices based on current locations. (2) Effectively solving the TSP\nrequires robust tracking of unvisited nodes and warrants succinct grouping\nstrategies. Building upon these insights, we propose integrating a learnable\nchoice layer inspired by Hypernetworks to prioritize choices based on the\ncurrent location, and a learnable approximate clustering algorithm inspired by\nthe Expectation-Maximization algorithm to facilitate grouping the unvisited\ncities. Together, these two contributions form a hierarchical approach towards\nsolving the realistic TSP by considering both immediate local neighbourhoods\nand learning an intermediate set of node representations. Our hierarchical\napproach yields superior performance compared to both classical and recent\ntransformer models, showcasing the efficacy of the key designs.","authors":["Yong Liang Goh","Zhiguang Cao","Yining Ma","Yanfei Dong","Mohammed Haroon Dupty","Wee Sun Lee"],"pdf_link":"http://arxiv.org/pdf/2408.03585v1","category":["Reinforcement Learning","Explainable AI"]},{"title":"Facing the Music: Tackling Singing Voice Separation in Cinematic Audio Source Separation","abstract":"Cinematic audio source separation (CASS) is a fairly new subtask of audio\nsource separation. A typical setup of CASS is a three-stem problem, with the\naim of separating the mixture into the dialogue stem (DX), music stem (MX), and\neffects stem (FX). In practice, however, several edge cases exist as some sound\nsources do not fit neatly in either of these three stems, necessitating the use\nof additional auxiliary stems in production. One very common edge case is the\nsinging voice in film audio, which may belong in either the DX or MX, depending\nheavily on the cinematic context. In this work, we demonstrate a very\nstraightforward extension of the dedicated-decoder Bandit and query-based\nsingle-decoder Banquet models to a four-stem problem, treating non-musical\ndialogue, instrumental music, singing voice, and effects as separate stems.\nInterestingly, the query-based Banquet model outperformed the dedicated-decoder\nBandit model. We hypothesized that this is due to a better feature alignment at\nthe bottleneck as enforced by the band-agnostic FiLM layer. Dataset and model\nimplementation will be made available at\nhttps://github.com/kwatcharasupat/source-separation-landing.","authors":["Karn N. Watcharasupat","Chih-Wei Wu","Iroro Orife"],"pdf_link":"http://arxiv.org/pdf/2408.03588v1","category":["Speech Recognition","Speech Synthesis"]},{"title":"HiQuE: Hierarchical Question Embedding Network for Multimodal Depression Detection","abstract":"The utilization of automated depression detection significantly enhances\nearly intervention for individuals experiencing depression. Despite numerous\nproposals on automated depression detection using recorded clinical interview\nvideos, limited attention has been paid to considering the hierarchical\nstructure of the interview questions. In clinical interviews for diagnosing\ndepression, clinicians use a structured questionnaire that includes routine\nbaseline questions and follow-up questions to assess the interviewee's\ncondition. This paper introduces HiQuE (Hierarchical Question Embedding\nnetwork), a novel depression detection framework that leverages the\nhierarchical relationship between primary and follow-up questions in clinical\ninterviews. HiQuE can effectively capture the importance of each question in\ndiagnosing depression by learning mutual information across multiple\nmodalities. We conduct extensive experiments on the widely-used clinical\ninterview data, DAIC-WOZ, where our model outperforms other state-of-the-art\nmultimodal depression detection models and emotion recognition models,\nshowcasing its clinical utility in depression detection.","authors":["Juho Jung","Chaewon Kang","Jeewoo Yoon","Seungbae Kim","Jinyoung Han"],"pdf_link":"http://arxiv.org/pdf/2408.03648v1","category":["AI in Healthcare","Multimodal Learning"]},{"title":"Generative Design of Periodic Orbits in the Restricted Three-Body Problem","abstract":"The Three-Body Problem has fascinated scientists for centuries and it has\nbeen crucial in the design of modern space missions. Recent developments in\nGenerative Artificial Intelligence hold transformative promise for addressing\nthis longstanding problem. This work investigates the use of Variational\nAutoencoder (VAE) and its internal representation to generate periodic orbits.\nWe utilize a comprehensive dataset of periodic orbits in the Circular\nRestricted Three-Body Problem (CR3BP) to train deep-learning architectures that\ncapture key orbital characteristics, and we set up physical evaluation metrics\nfor the generated trajectories. Through this investigation, we seek to enhance\nthe understanding of how Generative AI can improve space mission planning and\nastrodynamics research, leading to novel, data-driven approaches in the field.","authors":["Alvaro Francisco Gil","Walther Litteri","Victor Rodriguez-Fernandez","David Camacho","Massimiliano Vasile"],"pdf_link":"http://arxiv.org/pdf/2408.03691v1","category":["Explainable AI","Reinforcement Learning"]},{"title":"Online Model-based Anomaly Detection in Multivariate Time Series: Taxonomy, Survey, Research Challenges and Future Directions","abstract":"Time-series anomaly detection plays an important role in engineering\nprocesses, like development, manufacturing and other operations involving\ndynamic systems. These processes can greatly benefit from advances in the\nfield, as state-of-the-art approaches may aid in cases involving, for example,\nhighly dimensional data. To provide the reader with understanding of the\nterminology, this survey introduces a novel taxonomy where a distinction\nbetween online and offline, and training and inference is made. Additionally,\nit presents the most popular data sets and evaluation metrics used in the\nliterature, as well as a detailed analysis. Furthermore, this survey provides\nan extensive overview of the state-of-the-art model-based online semi- and\nunsupervised anomaly detection approaches for multivariate time-series data,\ncategorising them into different model families and other properties. The\nbiggest research challenge revolves around benchmarking, as currently there is\nno reliable way to compare different approaches against one another. This\nproblem is two-fold: on the one hand, public data sets suffers from at least\none fundamental flaw, while on the other hand, there is a lack of intuitive and\nrepresentative evaluation metrics in the field. Moreover, the way most\npublications choose a detection threshold disregards real-world conditions,\nwhich hinders the application in the real world. To allow for tangible advances\nin the field, these issues must be addressed in future work.","authors":["Lucas Correia","Jan-Christoph Goos","Philipp Klein","Thomas B\u00e4ck","Anna V. Kononova"],"pdf_link":"http://arxiv.org/pdf/2408.03747v1","category":["Datasets","Explainable AI"]},{"title":"Relevance meets Diversity: A User-Centric Framework for Knowledge Exploration through Recommendations","abstract":"Providing recommendations that are both relevant and diverse is a key\nconsideration of modern recommender systems. Optimizing both of these measures\npresents a fundamental trade-off, as higher diversity typically comes at the\ncost of relevance, resulting in lower user engagement. Existing recommendation\nalgorithms try to resolve this trade-off by combining the two measures,\nrelevance and diversity, into one aim and then seeking recommendations that\noptimize the combined objective, for a given number of items to recommend.\nTraditional approaches, however, do not consider the user interaction with the\nrecommended items.\n  In this paper, we put the user at the central stage, and build on the\ninterplay between relevance, diversity, and user behavior. In contrast to\napplications where the goal is solely to maximize engagement, we focus on\nscenarios aiming at maximizing the total amount of knowledge encountered by the\nuser. We use diversity as a surrogate of the amount of knowledge obtained by\nthe user while interacting with the system, and we seek to maximize diversity.\nWe propose a probabilistic user-behavior model in which users keep interacting\nwith the recommender system as long as they receive relevant recommendations,\nbut they may stop if the relevance of the recommended items drops. Thus, for a\nrecommender system to achieve a high-diversity measure, it will need to produce\nrecommendations that are both relevant and diverse.\n  Finally, we propose a novel recommendation strategy that combines relevance\nand diversity by a copula function. We conduct an extensive evaluation of the\nproposed methodology over multiple datasets, and we show that our strategy\noutperforms several state-of-the-art competitors. Our implementation is\npublicly available at https://github.com/EricaCoppolillo/EXPLORE.","authors":["Erica Coppolillo","Giuseppe Manco","Aristides Gionis"],"pdf_link":"http://arxiv.org/pdf/2408.03772v1","category":["Reinforcement Learning","Multimodal Learning"]},{"title":"Frank's triangular norms in Piaget's logical proportions","abstract":"Starting from the Boolean notion of logical proportion in Piaget's sense,\nwhich turns out to be equivalent to analogical proportion, this note proposes a\ndefinition of analogical proportion between numerical values based on\ntriangular norms (and dual co-norms). Frank's family of triangular norms is\nparticularly interesting from this perspective. The article concludes with a\ncomparative discussion with another very recent proposal for defining\nanalogical proportions between numerical values based on the family of\ngeneralized means.","authors":["Henri Prade","Gilles Richard"],"pdf_link":"http://arxiv.org/pdf/2408.03795v1","category":["Multimodal Learning","Benchmarking"]},{"title":"Automated Code Fix Suggestions for Accessibility Issues in Mobile Apps","abstract":"Accessibility is crucial for inclusive app usability, yet developers often\nstruggle to identify and fix app accessibility issues due to a lack of\nawareness, expertise, and inadequate tools. Current accessibility testing tools\ncan identify accessibility issues but may not always provide guidance on how to\naddress them. We introduce FixAlly, an automated tool designed to suggest\nsource code fixes for accessibility issues detected by automated accessibility\nscanners. FixAlly employs a multi-agent LLM architecture to generate fix\nstrategies, localize issues within the source code, and propose code\nmodification suggestions to fix the accessibility issue. Our empirical study\ndemonstrates FixAlly's capability in suggesting fixes that resolve issues found\nby accessibility scanners -- with an effectiveness of 77% in generating\nplausible fix suggestions -- and our survey of 12 iOS developers finds they\nwould be willing to accept 69.4% of evaluated fix suggestions.","authors":["Forough Mehralian","Titus Barik","Jeff Nichols","Amanda Swearngin"],"pdf_link":"http://arxiv.org/pdf/2408.03827v1","category":["Speech Recognition","AI in Healthcare"]},{"title":"MaxMind: A Memory Loop Network to Enhance Software Productivity based on Large Language Models","abstract":"The application of large language models to facilitate automated software\noperations and tool generation (SOTG), thus augmenting software productivity,\nmirrors the early stages of human evolution when the ability to create and use\ntools accelerated the progress of civilization. These complex tasks require AI\nto continuously summarize and improve. Current research often overlooks the\nimportance of converting real-time task experiences into system memory and\ndifferentiating the value of existing knowledge for future reference. This\npaper addresses these issues by evolving external memory models into\nMemory-Loop Networks for timely memorization and experience referencing. We\nalso enhance a RAG mechanism with knowledge precision segmentation to utilize\nmemory based on value differentiation, and design the MaxMind model for SOTG\naccordingly.To demonstrate our approach, we developed MaxMind4Sheet, an\nelectronic spreadsheet processing system aligned with the MaxMind philosophy.\nComparative experiments with SheetCopilot have demonstrated that the\naccumulation and recycling of task memories lead to a steady enhancement in\ntask success rate, with an improvement rate of approximately 3%-6% per round in\nthis implementation example. Note that as the memories continue to grow, this\ncumulative improvement may be substantial. The inclusion of memory recycling\ncan also boost the system's task execution efficiency by up to 25%, and it can\naddress the retraining issue faced by LLMs when handling specialized tasks\nthrough memories transfer.These suggest that MaxMind has significant potential\nto enhance the capabilities and productivity of LLM systems in SOTG.","authors":["Yuchen Dong","XiaoXiang Fang","Yuchen Hu","Renshuang Jiang","Zhe Jiang"],"pdf_link":"http://arxiv.org/pdf/2408.03841v1","category":["Speech Recognition","Speech Synthesis"]},{"title":"Inter-Series Transformer: Attending to Products in Time Series Forecasting","abstract":"Time series forecasting is an important task in many fields ranging from\nsupply chain management to weather forecasting. Recently, Transformer neural\nnetwork architectures have shown promising results in forecasting on common\ntime series benchmark datasets. However, application to supply chain demand\nforecasting, which can have challenging characteristics such as sparsity and\ncross-series effects, has been limited.\n  In this work, we explore the application of Transformer-based models to\nsupply chain demand forecasting. In particular, we develop a new\nTransformer-based forecasting approach using a shared, multi-task per-time\nseries network with an initial component applying attention across time series,\nto capture interactions and help address sparsity. We provide a case study\napplying our approach to successfully improve demand prediction for a medical\ndevice manufacturing company. To further validate our approach, we also apply\nit to public demand forecasting datasets as well and demonstrate competitive to\nsuperior performance compared to a variety of baseline and state-of-the-art\nforecast methods across the private and public datasets.","authors":["Rares Cristian","Pavithra Harsha","Clemente Ocejo","Georgia Perakis","Brian Quanz","Ioannis Spantidakis","Hamza Zerhouni"],"pdf_link":"http://arxiv.org/pdf/2408.03872v1","category":["Reinforcement Learning","Datasets"]},{"title":"Knowledge Probing for Graph Representation Learning","abstract":"Graph learning methods have been extensively applied in diverse application\nareas. However, what kind of inherent graph properties e.g. graph proximity,\ngraph structural information has been encoded into graph representation\nlearning for downstream tasks is still under-explored. In this paper, we\npropose a novel graph probing framework (GraphProbe) to investigate and\ninterpret whether the family of graph learning methods has encoded different\nlevels of knowledge in graph representation learning. Based on the intrinsic\nproperties of graphs, we design three probes to systematically investigate the\ngraph representation learning process from different perspectives, respectively\nthe node-wise level, the path-wise level, and the structural level. We\nconstruct a thorough evaluation benchmark with nine representative graph\nlearning methods from random walk based approaches, basic graph neural networks\nand self-supervised graph methods, and probe them on six benchmark datasets for\nnode classification, link prediction and graph classification. The experimental\nevaluation verify that GraphProbe can estimate the capability of graph\nrepresentation learning. Remaking results have been concluded: GCN and\nWeightedGCN methods are relatively versatile methods achieving better results\nwith respect to different tasks.","authors":["Mingyu Zhao","Xingyu Huang","Ziyu Lyu","Yanlin Wang","Lixin Cui","Lu Bai"],"pdf_link":"http://arxiv.org/pdf/2408.03877v1","category":["Datasets","Explainable AI"]}]