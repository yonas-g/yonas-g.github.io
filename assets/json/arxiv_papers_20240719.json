[
  {
    "title": "On Causally Disentangled State Representation Learning for Reinforcement Learning based Recommender Systems",
    "abstract": "In Reinforcement Learning-based Recommender Systems (RLRS), the complexity\nand dynamism of user interactions often result in high-dimensional and noisy\nstate spaces, making it challenging to discern which aspects of the state are\ntruly influential in driving the decision-making process. This issue is\nexacerbated by the evolving nature of user preferences and behaviors, requiring\nthe recommender system to adaptively focus on the most relevant information for\ndecision-making while preserving generaliability. To tackle this problem, we\nintroduce an innovative causal approach for decomposing the state and\nextracting \\textbf{C}ausal-\\textbf{I}n\\textbf{D}ispensable \\textbf{S}tate\nRepresentations (CIDS) in RLRS. Our method concentrates on identifying the\n\\textbf{D}irectly \\textbf{A}ction-\\textbf{I}nfluenced \\textbf{S}tate Variables\n(DAIS) and \\textbf{A}ction-\\textbf{I}nfluence \\textbf{A}ncestors (AIA), which\nare essential for making effective recommendations. By leveraging conditional\nmutual information, we develop a framework that not only discerns the causal\nrelationships within the generative process but also isolates critical state\nvariables from the typically dense and high-dimensional state representations.\nWe provide theoretical evidence for the identifiability of these variables.\nThen, by making use of the identified causal relationship, we construct\ncausal-indispensable state representations, enabling the training of policies\nover a more advantageous subset of the agent's state space. We demonstrate the\nefficacy of our approach through extensive experiments, showcasing our method\noutperforms state-of-the-art methods.",
    "authors": [
      "Siyu Wang",
      "Xiaocong Chen",
      "Lina Yao"
    ],
    "pdf_link": "http://arxiv.org/pdf/2407.13091v1",
    "category": [
      "Explainable AI",
      "Reinforcement Learning"
    ]
  },
  {
    "title": "Multiobjective Vehicle Routing Optimization with Time Windows: A Hybrid Approach Using Deep Reinforcement Learning and NSGA-II",
    "abstract": "This paper proposes a weight-aware deep reinforcement learning (WADRL)\napproach designed to address the multiobjective vehicle routing problem with\ntime windows (MOVRPTW), aiming to use a single deep reinforcement learning\n(DRL) model to solve the entire multiobjective optimization problem. The\nNon-dominated sorting genetic algorithm-II (NSGA-II) method is then employed to\noptimize the outcomes produced by the WADRL, thereby mitigating the limitations\nof both approaches. Firstly, we design an MOVRPTW model to balance the\nminimization of travel cost and the maximization of customer satisfaction.\nSubsequently, we present a novel DRL framework that incorporates a\ntransformer-based policy network. This network is composed of an encoder\nmodule, a weight embedding module where the weights of the objective functions\nare incorporated, and a decoder module. NSGA-II is then utilized to optimize\nthe solutions generated by WADRL. Finally, extensive experimental results\ndemonstrate that our method outperforms the existing and traditional methods.\nDue to the numerous constraints in VRPTW, generating initial solutions of the\nNSGA-II algorithm can be time-consuming. However, using solutions generated by\nthe WADRL as initial solutions for NSGA-II significantly reduces the time\nrequired for generating initial solutions. Meanwhile, the NSGA-II algorithm can\nenhance the quality of solutions generated by WADRL, resulting in solutions\nwith better scalability. Notably, the weight-aware strategy significantly\nreduces the training time of DRL while achieving better results, enabling a\nsingle DRL model to solve the entire multiobjective optimization problem.",
    "authors": [
      "Rixin Wu",
      "Ran Wang",
      "Jie Hao",
      "Qiang Wu",
      "Ping Wang",
      "Dusit Niyato"
    ],
    "pdf_link": "http://arxiv.org/pdf/2407.13113v1",
    "category": [
      "Reinforcement Learning",
      "Explainable AI"
    ]
  },
  {
    "title": "PG-Rainbow: Using Distributional Reinforcement Learning in Policy Gradient Methods",
    "abstract": "This paper introduces PG-Rainbow, a novel algorithm that incorporates a\ndistributional reinforcement learning framework with a policy gradient\nalgorithm. Existing policy gradient methods are sample inefficient and rely on\nthe mean of returns when calculating the state-action value function,\nneglecting the distributional nature of returns in reinforcement learning\ntasks. To address this issue, we use an Implicit Quantile Network that provides\nthe quantile information of the distribution of rewards to the critic network\nof the Proximal Policy Optimization algorithm. We show empirical results that\nthrough the integration of reward distribution information into the policy\nnetwork, the policy agent acquires enhanced capabilities to comprehensively\nevaluate the consequences of potential actions in a given state, facilitating\nmore sophisticated and informed decision-making processes. We evaluate the\nperformance of the proposed algorithm in the Atari-2600 game suite, simulated\nvia the Arcade Learning Environment (ALE).",
    "authors": [
      "WooJae Jeon",
      "KanJun Lee",
      "Jeewoo Lee"
    ],
    "pdf_link": "http://arxiv.org/pdf/2407.13146v1",
    "category": [
      "Reinforcement Learning",
      "Explainable AI"
    ]
  },
  {
    "title": "ROLeR: Effective Reward Shaping in Offline Reinforcement Learning for Recommender Systems",
    "abstract": "Offline reinforcement learning (RL) is an effective tool for real-world\nrecommender systems with its capacity to model the dynamic interest of users\nand its interactive nature. Most existing offline RL recommender systems focus\non model-based RL through learning a world model from offline data and building\nthe recommendation policy by interacting with this model. Although these\nmethods have made progress in the recommendation performance, the effectiveness\nof model-based offline RL methods is often constrained by the accuracy of the\nestimation of the reward model and the model uncertainties, primarily due to\nthe extreme discrepancy between offline logged data and real-world data in user\ninteractions with online platforms. To fill this gap, a more accurate reward\nmodel and uncertainty estimation are needed for the model-based RL methods. In\nthis paper, a novel model-based Reward Shaping in Offline Reinforcement\nLearning for Recommender Systems, ROLeR, is proposed for reward and uncertainty\nestimation in recommendation systems. Specifically, a non-parametric reward\nshaping method is designed to refine the reward model. In addition, a flexible\nand more representative uncertainty penalty is designed to fit the needs of\nrecommendation systems. Extensive experiments conducted on four benchmark\ndatasets showcase that ROLeR achieves state-of-the-art performance compared\nwith existing baselines. The source code can be downloaded at\nhttps://github.com/ArronDZhang/ROLeR.",
    "authors": [
      "Yi Zhang",
      "Ruihong Qiu",
      "Jiajun Liu",
      "Sen Wang"
    ],
    "pdf_link": "http://arxiv.org/pdf/2407.13163v1",
    "category": [
      "Reinforcement Learning",
      "Explainable AI"
    ]
  },
  {
    "title": "SpaDiT: Diffusion Transformer for Spatial Gene Expression Prediction using scRNA-seq",
    "abstract": "The rapid development of spatial transcriptomics (ST) technologies is\nrevolutionizing our understanding of the spatial organization of biological\ntissues. Current ST methods, categorized into next-generation sequencing-based\n(seq-based) and fluorescence in situ hybridization-based (image-based) methods,\noffer innovative insights into the functional dynamics of biological tissues.\nHowever, these methods are limited by their cellular resolution and the\nquantity of genes they can detect. To address these limitations, we propose\nSpaDiT, a deep learning method that utilizes a diffusion generative model to\nintegrate scRNA-seq and ST data for the prediction of undetected genes. By\nemploying a Transformer-based diffusion model, SpaDiT not only accurately\npredicts unknown genes but also effectively generates the spatial structure of\nST genes. We have demonstrated the effectiveness of SpaDiT through extensive\nexperiments on both seq-based and image-based ST data. SpaDiT significantly\ncontributes to ST gene prediction methods with its innovative approach.\nCompared to eight leading baseline methods, SpaDiT achieved state-of-the-art\nperformance across multiple metrics, highlighting its substantial\nbioinformatics contribution.",
    "authors": [
      "Xiaoyu Li",
      "Fangfang Zhu",
      "Wenwen Min"
    ],
    "pdf_link": "http://arxiv.org/pdf/2407.13182v1",
    "category": [
      "AI in Healthcare",
      "Multimodal Learning"
    ]
  },
  {
    "title": "Robust Multivariate Time Series Forecasting against Intra- and Inter-Series Transitional Shift",
    "abstract": "The non-stationary nature of real-world Multivariate Time Series (MTS) data\npresents forecasting models with a formidable challenge of the time-variant\ndistribution of time series, referred to as distribution shift. Existing\nstudies on the distribution shift mostly adhere to adaptive normalization\ntechniques for alleviating temporal mean and covariance shifts or time-variant\nmodeling for capturing temporal shifts. Despite improving model generalization,\nthese normalization-based methods often assume a time-invariant transition\nbetween outputs and inputs but disregard specific intra-/inter-series\ncorrelations, while time-variant models overlook the intrinsic causes of the\ndistribution shift. This limits model expressiveness and interpretability of\ntackling the distribution shift for MTS forecasting. To mitigate such a\ndilemma, we present a unified Probabilistic Graphical Model to Jointly\ncapturing intra-/inter-series correlations and modeling the time-variant\ntransitional distribution, and instantiate a neural framework called JointPGM\nfor non-stationary MTS forecasting. Specifically, JointPGM first employs\nmultiple Fourier basis functions to learn dynamic time factors and designs two\ndistinct learners: intra-series and inter-series learners. The intra-series\nlearner effectively captures temporal dynamics by utilizing temporal gates,\nwhile the inter-series learner explicitly models spatial dynamics through\nmulti-hop propagation, incorporating Gumbel-softmax sampling. These two types\nof series dynamics are subsequently fused into a latent variable, which is\ninversely employed to infer time factors, generate final prediction, and\nperform reconstruction. We validate the effectiveness and efficiency of\nJointPGM through extensive experiments on six highly non-stationary MTS\ndatasets, achieving state-of-the-art forecasting performance of MTS\nforecasting.",
    "authors": [
      "Hui He",
      "Qi Zhang",
      "Kun Yi",
      "Xiaojun Xue",
      "Shoujin Wang",
      "Liang Hu",
      "Longbing Cao"
    ],
    "pdf_link": "http://arxiv.org/pdf/2407.13194v1",
    "category": [
      "Multimodal Learning",
      "Reinforcement Learning"
    ]
  },
  {
    "title": "LiNR: Model Based Neural Retrieval on GPUs at LinkedIn",
    "abstract": "This paper introduces LiNR, LinkedIn's large-scale, GPU-based retrieval\nsystem. LiNR supports a billion-sized index on GPU models. We discuss our\nexperiences and challenges in creating scalable, differentiable search indexes\nusing TensorFlow and PyTorch at production scale. In LiNR, both items and model\nweights are integrated into the model binary. Viewing index construction as a\nform of model training, we describe scaling our system for large indexes,\nincorporating full scans and efficient filtering. A key focus is on enabling\nattribute-based pre-filtering for exhaustive GPU searches, addressing the\ncommon challenge of post-filtering in KNN searches that often reduces system\nquality. We further provide multi-embedding retrieval algorithms and strategies\nfor tackling cold start issues in retrieval. Our advancements in supporting\nlarger indexes through quantization are also discussed. We believe LiNR\nrepresents one of the industry's first Live-updated model-based retrieval\nindexes. Applied to out-of-network post recommendations on LinkedIn Feed, LiNR\nhas contributed to a 3% relative increase in professional daily active users.\nWe envisage LiNR as a step towards integrating retrieval and ranking into a\nsingle GPU model, simplifying complex infrastructures and enabling end-to-end\noptimization of the entire differentiable infrastructure through gradient\ndescent.",
    "authors": [
      "Fedor Borisyuk",
      "Qingquan Song",
      "Mingzhou Zhou",
      "Ganesh Parameswaran",
      "Madhu Arun",
      "Siva Popuri",
      "Tugrul Bingol",
      "Zhuotao Pei",
      "Kuang-Hsuan Lee",
      "Lu Zheng",
      "Qizhan Shao",
      "Ali Naqvi",
      "Sen Zhou",
      "Aman Gupta"
    ],
    "pdf_link": "http://arxiv.org/pdf/2407.13218v1",
    "category": [
      "LLMs",
      "Datasets"
    ]
  },
  {
    "title": "Underwater Acoustic Signal Denoising Algorithms: A Survey of the State-of-the-art",
    "abstract": "This paper comprehensively reviews recent advances in underwater acoustic\nsignal denoising, an area critical for improving the reliability and clarity of\nunderwater communication and monitoring systems. Despite significant progress\nin the field, the complex nature of underwater environments poses unique\nchallenges that complicate the denoising process. We begin by outlining the\nfundamental challenges associated with underwater acoustic signal processing,\nincluding signal attenuation, noise variability, and the impact of\nenvironmental factors. The review then systematically categorizes and discusses\nvarious denoising algorithms, such as conventional, decomposition-based, and\nlearning-based techniques, highlighting their applications, advantages, and\nlimitations. Evaluation metrics and experimental datasets are also reviewed.\nThe paper concludes with a list of open questions and recommendations for\nfuture research directions, emphasizing the need for developing more robust\ndenoising techniques that can adapt to the dynamic underwater acoustic\nenvironment.",
    "authors": [
      "Ruobin Gao",
      "Maohan Liang",
      "Heng Dong",
      "Xuewen Luo",
      "P. N. Suganthan"
    ],
    "pdf_link": "http://arxiv.org/pdf/2407.13264v1",
    "category": [
      "Speech Recognition",
      "Speech Synthesis"
    ]
  },
  {
    "title": "Mixture of Experts based Multi-task Supervise Learning from Crowds",
    "abstract": "Existing truth inference methods in crowdsourcing aim to map redundant labels\nand items to the ground truth. They treat the ground truth as hidden variables\nand use statistical or deep learning-based worker behavior models to infer the\nground truth. However, worker behavior models that rely on ground truth hidden\nvariables overlook workers' behavior at the item feature level, leading to\nimprecise characterizations and negatively impacting the quality of truth\ninference. This paper proposes a new paradigm of multi-task supervised learning\nfrom crowds, which eliminates the need for modeling of items's ground truth in\nworker behavior models. Within this paradigm, we propose a worker behavior\nmodel at the item feature level called Mixture of Experts based Multi-task\nSupervised Learning from Crowds (MMLC). Two truth inference strategies are\nproposed within MMLC. The first strategy, named MMLC-owf, utilizes clustering\nmethods in the worker spectral space to identify the projection vector of the\noracle worker. Subsequently, the labels generated based on this vector are\nconsidered as the inferred truth. The second strategy, called MMLC-df, employs\nthe MMLC model to fill the crowdsourced data, which can enhance the\neffectiveness of existing truth inference methods. Experimental results\ndemonstrate that MMLC-owf outperforms state-of-the-art methods and MMLC-df\nenhances the quality of existing truth inference methods.",
    "authors": [
      "Tao Han",
      "Huaixuan Shi",
      "Xinyi Ding",
      "Xiao Ma",
      "Huamao Gu",
      "Yili Fang"
    ],
    "pdf_link": "http://arxiv.org/pdf/2407.13268v1",
    "category": [
      "Datasets",
      "Multimodal Learning"
    ]
  },
  {
    "title": "Sortability of Time Series Data",
    "abstract": "Evaluating the performance of causal discovery algorithms that aim to find\ncausal relationships between time-dependent processes remains a challenging\ntopic. In this paper, we show that certain characteristics of datasets, such as\nvarsortability (Reisach et al. 2021) and $R^2$-sortability (Reisach et al.\n2023), also occur in datasets for autocorrelated stationary time series. We\nillustrate this empirically using four types of data: simulated data based on\nSVAR models and Erd\\H{o}s-R\\'enyi graphs, the data used in the 2019\ncausality-for-climate challenge (Runge et al. 2019), real-world river stream\ndatasets, and real-world data generated by the Causal Chamber of (Gamella et\nal. 2024). To do this, we adapt var- and $R^2$-sortability to time series data.\nWe also investigate the extent to which the performance of score-based causal\ndiscovery methods goes hand in hand with high sortability. Arguably, our most\nsurprising finding is that the investigated real-world datasets exhibit high\nvarsortability and low $R^2$-sortability indicating that scales may carry a\nsignificant amount of causal information.",
    "authors": [
      "Christopher Lohse",
      "Jonas Wahl"
    ],
    "pdf_link": "http://arxiv.org/pdf/2407.13313v1",
    "category": [
      "Datasets",
      "Explainable AI"
    ]
  },
  {
    "title": "Improving Out-of-Distribution Generalization of Trajectory Prediction for Autonomous Driving via Polynomial Representations",
    "abstract": "Robustness against Out-of-Distribution (OoD) samples is a key performance\nindicator of a trajectory prediction model. However, the development and\nranking of state-of-the-art (SotA) models are driven by their In-Distribution\n(ID) performance on individual competition datasets. We present an OoD testing\nprotocol that homogenizes datasets and prediction tasks across two large-scale\nmotion datasets. We introduce a novel prediction algorithm based on polynomial\nrepresentations for agent trajectory and road geometry on both the input and\noutput sides of the model. With a much smaller model size, training effort, and\ninference time, we reach near SotA performance for ID testing and significantly\nimprove robustness in OoD testing. Within our OoD testing protocol, we further\nstudy two augmentation strategies of SotA models and their effects on model\ngeneralization. Highlighting the contrast between ID and OoD performance, we\nsuggest adding OoD testing to the evaluation criteria of trajectory prediction\nmodels.",
    "authors": [
      "Yue Yao",
      "Shengchao Yan",
      "Daniel Goehring",
      "Wolfram Burgard",
      "Joerg Reichardt"
    ],
    "pdf_link": "http://arxiv.org/pdf/2407.13431v1",
    "category": [
      "Benchmarking",
      "Explainable AI"
    ]
  },
  {
    "title": "Reducing Barriers to the Use of Marginalised Music Genres in AI",
    "abstract": "AI systems for high quality music generation typically rely on extremely\nlarge musical datasets to train the AI models. This creates barriers to\ngenerating music beyond the genres represented in dominant datasets such as\nWestern Classical music or pop music. We undertook a 4 month international\nresearch project summarised in this paper to explore the eXplainable AI (XAI)\nchallenges and opportunities associated with reducing barriers to using\nmarginalised genres of music with AI models. XAI opportunities identified\nincluded topics of improving transparency and control of AI models, explaining\nthe ethics and bias of AI models, fine tuning large models with small datasets\nto reduce bias, and explaining style-transfer opportunities with AI models.\nParticipants in the research emphasised that whilst it is hard to work with\nsmall datasets such as marginalised music and AI, such approaches strengthen\ncultural representation of underrepresented cultures and contribute to\naddressing issues of bias of deep learning models. We are now building on this\nproject to bring together a global International Responsible AI Music community\nand invite people to join our network.",
    "authors": [
      "Nick Bryan-Kinns",
      "Zijin Li"
    ],
    "pdf_link": "http://arxiv.org/pdf/2407.13439v1",
    "category": [
      "Explainable AI",
      "Datasets"
    ]
  },
  {
    "title": "Differential Privacy Mechanisms in Neural Tangent Kernel Regression",
    "abstract": "Training data privacy is a fundamental problem in modern Artificial\nIntelligence (AI) applications, such as face recognition, recommendation\nsystems, language generation, and many others, as it may contain sensitive user\ninformation related to legal issues. To fundamentally understand how privacy\nmechanisms work in AI applications, we study differential privacy (DP) in the\nNeural Tangent Kernel (NTK) regression setting, where DP is one of the most\npowerful tools for measuring privacy under statistical learning, and NTK is one\nof the most popular analysis frameworks for studying the learning mechanisms of\ndeep neural networks. In our work, we can show provable guarantees for both\ndifferential privacy and test accuracy of our NTK regression. Furthermore, we\nconduct experiments on the basic image classification dataset CIFAR10 to\ndemonstrate that NTK regression can preserve good accuracy under a modest\nprivacy budget, supporting the validity of our analysis. To our knowledge, this\nis the first work to provide a DP guarantee for NTK regression.",
    "authors": [
      "Jiuxiang Gu",
      "Yingyu Liang",
      "Zhizhou Sha",
      "Zhenmei Shi",
      "Zhao Song"
    ],
    "pdf_link": "http://arxiv.org/pdf/2407.13621v1",
    "category": [
      "Datasets",
      "Explainable AI"
    ]
  },
  {
    "title": "Misspecified $Q$-Learning with Sparse Linear Function Approximation: Tight Bounds on Approximation Error",
    "abstract": "The recent work by Dong & Yang (2023) showed for misspecified sparse linear\nbandits, one can obtain an $O\\left(\\epsilon\\right)$-optimal policy using a\npolynomial number of samples when the sparsity is a constant, where $\\epsilon$\nis the misspecification error. This result is in sharp contrast to misspecified\nlinear bandits without sparsity, which require an exponential number of samples\nto get the same guarantee. In order to study whether the analog result is\npossible in the reinforcement learning setting, we consider the following\nproblem: assuming the optimal $Q$-function is a $d$-dimensional linear function\nwith sparsity $k$ and misspecification error $\\epsilon$, whether we can obtain\nan $O\\left(\\epsilon\\right)$-optimal policy using number of samples polynomially\nin the feature dimension $d$. We first demonstrate why the standard approach\nbased on Bellman backup or the existing optimistic value function elimination\napproach such as OLIVE (Jiang et al., 2017) achieves suboptimal guarantees for\nthis problem. We then design a novel elimination-based algorithm to show one\ncan obtain an $O\\left(H\\epsilon\\right)$-optimal policy with sample complexity\npolynomially in the feature dimension $d$ and planning horizon $H$. Lastly, we\ncomplement our upper bound with an $\\widetilde{\\Omega}\\left(H\\epsilon\\right)$\nsuboptimality lower bound, giving a complete picture of this problem.",
    "authors": [
      "Ally Yalei Du",
      "Lin F. Yang",
      "Ruosong Wang"
    ],
    "pdf_link": "http://arxiv.org/pdf/2407.13622v1",
    "category": [
      "Reinforcement Learning",
      "Explainable AI"
    ]
  },
  {
    "title": "A Comprehensive Review of Recommender Systems: Transitioning from Theory to Practice",
    "abstract": "Recommender Systems (RS) play an integral role in enhancing user experiences\nby providing personalized item suggestions. This survey reviews the progress in\nRS inclusively from 2017 to 2024, effectively connecting theoretical advances\nwith practical applications. We explore the development from traditional RS\ntechniques like content-based and collaborative filtering to advanced methods\ninvolving deep learning, graph-based models, reinforcement learning, and large\nlanguage models. We also discuss specialized systems such as context-aware,\nreview-based, and fairness-aware RS. The primary goal of this survey is to\nbridge theory with practice. It addresses challenges across various sectors,\nincluding e-commerce, healthcare, and finance, emphasizing the need for\nscalable, real-time, and trustworthy solutions. Through this survey, we promote\nstronger partnerships between academic research and industry practices. The\ninsights offered by this survey aim to guide industry professionals in\noptimizing RS deployment and to inspire future research directions, especially\nin addressing emerging technological and societal trends",
    "authors": [
      "Shaina Raza",
      "Mizanur Rahman",
      "Safiullah Kamawal",
      "Armin Toroghi",
      "Ananya Raval",
      "Farshad Navah",
      "Amirmohammad Kazemeini"
    ],
    "pdf_link": "http://arxiv.org/pdf/2407.13699v1",
    "category": [
      "Reinforcement Learning",
      "AI in Healthcare"
    ]
  },
  {
    "title": "CoDefeater: Using LLMs To Find Defeaters in Assurance Cases",
    "abstract": "Constructing assurance cases is a widely used, and sometimes required,\nprocess toward demonstrating that safety-critical systems will operate safely\nin their planned environment. To mitigate the risk of errors and missing edge\ncases, the concept of defeaters - arguments or evidence that challenge claims\nin an assurance case - has been introduced. Defeaters can provide timely\ndetection of weaknesses in the arguments, prompting further investigation and\ntimely mitigations. However, capturing defeaters relies on expert judgment,\nexperience, and creativity and must be done iteratively due to evolving\nrequirements and regulations. This paper proposes CoDefeater, an automated\nprocess to leverage large language models (LLMs) for finding defeaters. Initial\nresults on two systems show that LLMs can efficiently find known and unforeseen\nfeasible defeaters to support safety analysts in enhancing the completeness and\nconfidence of assurance cases.",
    "authors": [
      "Usman Gohar",
      "Michael C. Hunter",
      "Robyn R. Lutz",
      "Myra B. Cohen"
    ],
    "pdf_link": "http://arxiv.org/pdf/2407.13717v1",
    "category": [
      "Explainable AI",
      "Benchmarking"
    ]
  },
  {
    "title": "Understanding Reinforcement Learning-Based Fine-Tuning of Diffusion Models: A Tutorial and Review",
    "abstract": "This tutorial provides a comprehensive survey of methods for fine-tuning\ndiffusion models to optimize downstream reward functions. While diffusion\nmodels are widely known to provide excellent generative modeling capability,\npractical applications in domains such as biology require generating samples\nthat maximize some desired metric (e.g., translation efficiency in RNA, docking\nscore in molecules, stability in protein). In these cases, the diffusion model\ncan be optimized not only to generate realistic samples but also to explicitly\nmaximize the measure of interest. Such methods are based on concepts from\nreinforcement learning (RL). We explain the application of various RL\nalgorithms, including PPO, differentiable optimization, reward-weighted MLE,\nvalue-weighted sampling, and path consistency learning, tailored specifically\nfor fine-tuning diffusion models. We aim to explore fundamental aspects such as\nthe strengths and limitations of different RL-based fine-tuning algorithms\nacross various scenarios, the benefits of RL-based fine-tuning compared to\nnon-RL-based approaches, and the formal objectives of RL-based fine-tuning\n(target distributions). Additionally, we aim to examine their connections with\nrelated topics such as classifier guidance, Gflownets, flow-based diffusion\nmodels, path integral control theory, and sampling from unnormalized\ndistributions such as MCMC. The code of this tutorial is available at\nhttps://github.com/masa-ue/RLfinetuning_Diffusion_Bioseq",
    "authors": [
      "Masatoshi Uehara",
      "Yulai Zhao",
      "Tommaso Biancalani",
      "Sergey Levine"
    ],
    "pdf_link": "http://arxiv.org/pdf/2407.13734v1",
    "category": [
      "Reinforcement Learning",
      "Explainable AI"
    ]
  },
  {
    "title": "CellularLint: A Systematic Approach to Identify Inconsistent Behavior in Cellular Network Specifications",
    "abstract": "In recent years, there has been a growing focus on scrutinizing the security\nof cellular networks, often attributing security vulnerabilities to issues in\nthe underlying protocol design descriptions. These protocol design\nspecifications, typically extensive documents that are thousands of pages long,\ncan harbor inaccuracies, underspecifications, implicit assumptions, and\ninternal inconsistencies. In light of the evolving landscape, we introduce\nCellularLint--a semi-automatic framework for inconsistency detection within the\nstandards of 4G and 5G, capitalizing on a suite of natural language processing\ntechniques. Our proposed method uses a revamped few-shot learning mechanism on\ndomain-adapted large language models. Pre-trained on a vast corpus of cellular\nnetwork protocols, this method enables CellularLint to simultaneously detect\ninconsistencies at various levels of semantics and practical use cases. In\ndoing so, CellularLint significantly advances the automated analysis of\nprotocol specifications in a scalable fashion. In our investigation, we focused\non the Non-Access Stratum (NAS) and the security specifications of 4G and 5G\nnetworks, ultimately uncovering 157 inconsistencies with 82.67% accuracy. After\nverification of these inconsistencies on open-source implementations and 17\ncommercial devices, we confirm that they indeed have a substantial impact on\ndesign decisions, potentially leading to concerns related to privacy,\nintegrity, availability, and interoperability.",
    "authors": [
      "Mirza Masfiqur Rahman",
      "Imtiaz Karim",
      "Elisa Bertino"
    ],
    "pdf_link": "http://arxiv.org/pdf/2407.13742v1",
    "category": [
      "Datasets",
      "LLMs"
    ]
  },
  {
    "title": "Neural Network Tire Force Modeling for Automated Drifting",
    "abstract": "Automated drifting presents a challenge problem for vehicle control,\nrequiring models and control algorithms that can precisely handle nonlinear,\ncoupled tire forces at the friction limits. We present a neural network\narchitecture for predicting front tire lateral force as a drop-in replacement\nfor physics-based approaches. With a full-scale automated vehicle purpose-built\nfor the drifting application, we deploy these models in a nonlinear model\npredictive controller tuned for tracking a reference drifting trajectory, for\ndirect comparisons of model performance. The neural network tire model exhibits\nsignificantly improved path tracking performance over the brush tire model in\ncases where front-axle braking force is applied, suggesting the neural\nnetwork's ability to express previously unmodeled, latent dynamics in the\ndrifting condition.",
    "authors": [
      "Nicholas Drake Broadbent",
      "Trey Weber",
      "Daiki Mori",
      "J. Christian Gerdes"
    ],
    "pdf_link": "http://arxiv.org/pdf/2407.13760v1",
    "category": [
      "Reinforcement Learning",
      "Explainable AI"
    ]
  }
]