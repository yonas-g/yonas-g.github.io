{
  "summary": "Today's research papers are about:\n1. \"Vibravox\": a dataset of French speech captured with body-conduction audio sensors, used for various speech-related tasks with state-of-the-art models.\n2. \"DeepGate3\": an enhanced architecture integrating Transformer modules for scalable circuit representation learning, showing improved scalability and generalizability.\n3. \"SMTAFormer\": a novel static and multivariate-temporal attentive fusion transformer for short-term ICU patient readmission prediction, outperforming advanced methods.\n4. \"CodeV\": a series of instruction-tuned Verilog generation LLMs using multi-level summarization, showing significant improvements over previous models.\n5. \"GraphPrint\": extracting features from 3D protein structure for drug target affinity prediction, providing a mean squared error of 0.1378 and a concordance index of 0.8929.\n6. \"BandControlNet\": a parallel Transformers-based music generation model for popular music, outperforming other models in fidelity and inference speed.\n7. \"GROOT\": generating robust watermarks for diffusion-model-based audio synthesis, showcasing exceptional robustness against different attacks.\n8. \"Three Dogmas of Reinforcement Learning\": reflecting on the environment spotlight, learning task solutions, and the reward hypothesis in reinforcement learning paradigms to shape the field's scientific paradigm.\n9. \"XEQ Scale\": introducing a comprehensive framework for evaluating user-centered XAI experiences with a focus on learning, utility, fulfillment, and engagement dimensions.\n10. \"Classification of Heart Sounds using Multi-Branch Deep Convolutional Network and LSTM-CNN\": presenting a fast and cost-effective method for diagnosing cardiac abnormalities with high accuracy using low-cost systems.\n11. \"SEMINAR\": a unified lifelong multi-modal sequence model for personalized search ranking and CTR prediction, demonstrating enhanced task performance.\n12. \"Repurformer\": transformers for repurposing-aware molecule generation, showing improved diversity in generated molecules.\n13. \"A Unified Differentiable Boolean Operator with Fuzzy Logic\": proposing a continuous Boolean operator for constructive solid geometry optimization tasks, enabling gradient descent-based optimization.\n14. \"BECAUSE\": a bilinear causal representation model for offline model-based reinforcement learning, addressing confounder influences and achieving robust performance.\n15. \"Pacer and Runner\": a cooperative learning framework between Single- and Cross-Domain Sequential Recommendation, enhancing recommendation performance.\n16. \"Exploration in Knowledge Transfer Utilizing Reinforcement Learning\": comparing different exploration methods within a deep transfer learning algorithm for the virtual drone problem.\n17. \"Offline Reinforcement Learning with Imputed Rewards\": proposing a reward model that can estimate rewards from limited samples, enabling offline reinforcement learning in data-scarce scenarios.\n18. \"Deep Causal Learning to Explain and Quantify The Geo-Tension's Impact on Natural Gas Market\": exploring the impact of shock events on the natural gas market using deep causal learning.\n19. \"Hey, That's My Model!\": introducing Chain & Hash, a fingerprinting method for large language models to prevent misuse and theft.\n20. \"A Unified Differentiable Boolean Operator with Fuzzy Logic\": presenting a continuous Boolean operator to optimize Constructive Solid Geometry tasks effectively."
}