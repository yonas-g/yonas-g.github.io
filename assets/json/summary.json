{"summary":"Here is a concise summary of each paper:\n\n1. Vibravox: A dataset of French speech captured using body-conduction audio sensors, containing 38 hours of speech samples, and physiological sounds. The dataset is designed for speech recognition, speech enhancement, and speaker verification tasks.\n\n2. DeepGate3: A new architecture that integrates Transformer modules with Graph Neural Networks for circuit representation learning, enhancing scalability and generalizability.\n\n3. Static and multivariate-temporal attentive fusion transformer for readmission risk prediction: A model that combines static and temporal features for predicting short-term readmission risk in ICU patients.\n\n4. CodeV: A series of instruction-tuned Verilog generation LLMs that use multi-level summarization to generate code, outperforming previous methods.\n\n5. GraphPrint: A framework for incorporating 3D protein structure features for drug target affinity prediction, using amino acid residue location coordinates and graph representations.\n\n6. BandControlNet: A conditional model based on parallel Transformers for generating high-quality music samples that are conditioned on given spatiotemporal control features.\n\n7. GROOT: A generative robust audio watermarking method that embeds a watermark in audio signals and can retrieve it using a lightweight decoder.\n\n8. Three Dogmas of Reinforcement Learning: An examination of three dogmas in reinforcement learning, highlighting their limitations and proposing a nuanced approach.\n\n9. XEQ Scale: A framework for evaluating the quality of XAI experiences, quantifying the quality of experiences across four evaluation dimensions.\n\n10. Classification of Heart Sounds Using Multi-Branch Deep Convolutional Network and LSTM-CNN: A method for classifying heart sounds using a multi-branch deep convolutional network and LSTM-CNN.\n\n11. SEMINAR: A search-enhanced multi-modal interest network and approximate retrieval method for lifelong sequential recommendation.\n\n12. Exploring the Potentials and Challenges of Deep Generative Models in Product Design Conception: A study on the potential applications of deep generative models in product design conception.\n\n13. Impacts of Data Preprocessing and Hyperparameter Optimization on the Performance of Machine Learning Models Applied to Intrusion Detection Systems: An evaluation of the impact of data preprocessing and hyperparameter optimization on intrusion detection systems.\n\n14. MSegRNN: An enhanced SegRNN model with Mamba for long-term time series forecasting.\n\n15. AdapTable: A test-time adaptation method for tabular data using a shift-aware uncertainty calibrator and label distribution handler.\n\n16. Towards Enhanced Classification of Abnormal Lung sound in Multi-breath: A lightweight multi-label and multi-head attention classification method.\n\n17. Exploration in Knowledge Transfer Utilizing Reinforcement Learning: A study on the exploration of knowledge transfer in reinforcement learning.\n\n18. Offline Reinforcement Learning with Imputed Rewards: A method for imputing rewards in offline reinforcement learning using a reward model.\n\n19. Deep Causal Learning to Explain and Quantify The Geo-Tension's Impact on Natural Gas Market: A method for explaining and quantifying the impact of shocks on natural gas markets using deep causal learning.\n\n20. Hey, That's My Model! Introducing Chain & Hash, An LLM Fingerprinting Technique: A fingerprinting technique for large language models to identify ownership.\n\n21. BECAUSE: Bilinear Causal Representation for Generalizable Offline Model-based Reinforcement Learning: A method for using bilinear causal representation to improve offline model-based reinforcement learning.\n\n22. Pacer and Runner: Cooperative Learning Framework between Single- and Cross-Domain Sequential Recommendation: A cooperative learning framework for sequential recommendation that combines single and cross-domain approaches.\n\n23. Disentangling Representations in RNNs through Multi-task Learning: A study on the emergence of disentangled representations in RNNs through multi-task learning.\n\nHere are the summaries of the research papers:\n\n1. CLAMS: A System for Zero-Shot Model Selection for Clustering\nThe paper proposes a system called CLAMS that enables model selection for clustering problems using optimal transport-based dataset similarity. The system outperforms traditional clustering methods and can be used to select the most suitable algorithms for clustering tasks.\n\n2. COMET: \"Cone of Experience\" enhanced large multimodal model for mathematical problem generation\nThe paper proposes a new model called COMET that can generate mathematical problems with desired properties by leveraging bi-directional pretraining with Fast Fourier Transform (FFT) and low-pass filtering (LPF). The model is evaluated on a Chinese multimodal mathematical problem dataset and achieves better results than other state-of-the-art models.\n\n3. Feature Inference Attack on Shapley Values\nThe paper investigates the privacy risks of Shapley value-based model interpretability methods and proposes two adversaries that can reconstruct private model inputs based on their Shapley value explanations. The experiments demonstrate the vulnerability of leading MLaaS platforms to these attacks.\n\n4. Thorns and Algorithms: Navigating Generative AI Challenges Inspired by Giraffes and Acacias\nThe paper explores the challenges of navigating Gig-Regimes (Gr) and makes a case for responsible AI adoption by framing the conversation around giraffe-like adaptability and acacia-like flexibility.\n\n5. Generally-Occurring Model Change for Robust Counterfactual Explanations\nThe paper proposes a new framework for studying the robustness of counterfactual explanation generation algorithms to model changes and provides a set of properties for evaluating the imperceptibility of adversarial attacks on tabular data.\n\n6. Repurformer: Transformers for Repurposing-Aware Molecule Generation\nThe paper proposes a new model called Repurformer that can generate diverse molecules with desired properties by leveraging multi-hop relationships among proteins and compounds. The model is evaluated on a binding database dataset and achieves better results than other state-of-the-art models.\n\n7. Graceful task adaptation with a bi-hemispheric RL agent\nThe paper proposes a new RL agent that can adapt to new tasks by exploiting generalist knowledge from the right hemisphere and specializes in routine tasks from the left hemisphere. The agent achieves better results than other state-of-the-art agents in a simulated environment.\n\n8. Investigating Imperceptibility of Adversarial Attacks on Tabular Data: An Empirical Analysis\nThe paper proposes a comprehensive evaluation benchmark for imperceptibility of adversarial attacks on tabular data and provides a set of properties for evaluating the resilience of datasets to attacks.\n\n9. A Meta-Learning Approach for Multi-Objective Reinforcement Learning in Sustainable Home Environments\nThe paper proposes a new meta-learning approach for multi-objective reinforcement learning in sustainable home environments using Transformers and 2D convolutional neural networks.\n\n10. LRQ: Optimizing Post-Training Quantization for Large Language Models by Learning Low-Rank Weight-Scaling Matrices\nThe paper proposes a new method called LRQ that optimizes post-training quantization for large language models by learning low-rank weight-scaling matrices.\n\n11. Improving Engagement and Efficacy of mHealth Micro-Interventions for Stress Coping: an In-The-Wild Study\nThe paper proposes a new algorithm for selecting micro-interventions for stress coping based on the context-aware needs of users and evaluates its effectiveness in a real-world study.\n\n12. Graph Dimension Attention Networks for Enterprise Credit Assessment\nThe paper proposes a new model called Graph Dimension Attention Network (GDAN) that integrates dimension-level attention mechanisms to capture fine-grained risk-related characteristics in enterprise credit assessment.\n\n13. Universal Sound Separation with Self-Supervised Audio Masked Autoencoder\nThe paper proposes a new model called Audio Masked Autoencoder (A-MAE) that can separate mixtures of arbitrary sound sources using self-supervised learning.\n\n14. Characterizing and Understanding HGNN Training on GPUs\nThe paper provides an in-depth analysis of the execution semantics and patterns within the training process of Heterogeneous Graph Neural Networks (HGNNs) on GPUs.\n\n15. Schema Matching with Large Language Models: an Experimental Study\nThe paper investigates the use of large language models for schema matching and proposes different task scopes for prompting the model to identify semantic correspondences between elements of two relational schemas.\n\n16. Tackling Oversmoothing in GNN via Graph Sparsification: A Truss-based Approach\nThe paper proposes a novel truss-based graph sparsification model that prunes edges from dense regions of the graph to prevent oversmoothing in Graph Neural Networks (GNNs).\n\n17. Schema Matching with Knowledge Graph Embeddings\nThe paper investigates the use of knowledge graph embeddings for schema matching and proposes different task scopes for prompting the model to identify semantic correspondences between elements of two relational schemas.\n\n18. AIGC for Industrial Time Series: From Deep Generative Models to Large Generative Models\nThe paper proposes a comprehensive overview of generative models for industrial time series and presents a novel large generative model for industrial data generation.\n\n19. Multi-Channel Masked Autoencoder and Comprehensive Evaluations for Reconstructing 12-Lead ECG from Arbitrary Single-Lead ECG\nThe paper proposes a new multi-channel masked autoencoder for reconstructing 12-lead ECG from arbitrary single-lead ECG and evaluates its performance on a comprehensive evaluation benchmark.\n\n20. Diff-MTS: Temporal-Augmented Conditional Diffusion-based AIGC for Industrial Time Series Towards the Large Model Era\nThe paper proposes a novel diffusion-based generative model called Diff-MTS that can generate industrial time series data with complex temporal dependencies and evaluates its performance on a comprehensive evaluation benchmark.\n\n21. The Future of Data Science Education\nThe paper discusses the definition and scope of Data Science and proposes a new model for teaching data science education.\n\n22. Variational Randomized Smoothing for Sample-Wise Adversarial Robustness\nThe paper proposes a novel variational framework for randomized smoothing that uses a per-sample noise level to enhance sample-wise adversarial robustness.\n\n23. Universal Sound Separation with Self-Supervised Audio Masked Autoencoder\nThe paper proposes a new model called Audio Masked Autoencoder (A-MAE) that can separate mixtures of arbitrary sound sources using self-supervised learning.\n\n24. Approximating Probabilistic Inference in Statistical EL with Knowledge Graph Embeddings\nThe paper proposes a new method for approximating probabilistic inference in Statistical EL using knowledge graph embeddings.\n\n25. Schema Matching with Large Language Models: an Experimental Study\nThe paper investigates the use of large language models for schema matching and proposes different task scopes for prompting the model to identify semantic correspondences between elements of two relational schemas.\n\nThese summaries provide a brief overview of each"}