[
  {
    "title": "VoxBlink2: A 100K+ Speaker Recognition Corpus and the Open-Set Speaker-Identification Benchmark",
    "abstract": "In this paper, we provide a large audio-visual speaker recognition dataset,\nVoxBlink2, which includes approximately 10M utterances with videos from 110K+\nspeakers in the wild. This dataset represents a significant expansion over the\nVoxBlink dataset, encompassing a broader diversity of speakers and scenarios by\nthe grace of an optimized data collection pipeline. Afterward, we explore the\nimpact of training strategies, data scale, and model complexity on speaker\nverification and finally establish a new single-model state-of-the-art EER at\n0.170% and minDCF at 0.006% on the VoxCeleb1-O test set. Such remarkable\nresults motivate us to explore speaker recognition from a new challenging\nperspective. We raise the Open-Set Speaker-Identification task, which is\ndesigned to either match a probe utterance with a known gallery speaker or\ncategorize it as an unknown query. Associated with this task, we design\nconcrete benchmark and evaluation protocols. The data and model resources can\nbe found in http://voxblink2.github.io.",
    "authors": [
      "Yuke Lin",
      "Ming Cheng",
      "Fulin Zhang",
      "Yingying Gao",
      "Shilei Zhang",
      "Ming Li"
    ],
    "pdf_link": "http://arxiv.org/pdf/2407.11510v1",
    "category": [
      "Speech Recognition",
      "Multimodal Learning"
    ]
  },
  {
    "title": "The VoicePrivacy 2022 Challenge: Progress and Perspectives in Voice Anonymisation",
    "abstract": "The VoicePrivacy Challenge promotes the development of voice anonymisation\nsolutions for speech technology. In this paper we present a systematic overview\nand analysis of the second edition held in 2022. We describe the voice\nanonymisation task and datasets used for system development and evaluation,\npresent the different attack models used for evaluation, and the associated\nobjective and subjective metrics. We describe three anonymisation baselines,\nprovide a summary description of the anonymisation systems developed by\nchallenge participants, and report objective and subjective evaluation results\nfor all. In addition, we describe post-evaluation analyses and a summary of\nrelated work reported in the open literature. Results show that solutions based\non voice conversion better preserve utility, that an alternative which combines\nautomatic speech recognition with synthesis achieves greater privacy, and that\na privacy-utility trade-off remains inherent to current anonymisation\nsolutions. Finally, we present our ideas and priorities for future VoicePrivacy\nChallenge editions.",
    "authors": [
      "Michele Panariello",
      "Natalia Tomashenko",
      "Xin Wang",
      "Xiaoxiao Miao",
      "Pierre Champion",
      "Hubert Nourtel",
      "Massimiliano Todisco",
      "Nicholas Evans",
      "Emmanuel Vincent",
      "Junichi Yamagishi"
    ],
    "pdf_link": "http://arxiv.org/pdf/2407.11516v1",
    "category": [
      "Speech Synthesis",
      "Speech Recognition"
    ]
  },
  {
    "title": "Investigating the Effect of Label Topology and Training Criterion on ASR Performance and Alignment Quality",
    "abstract": "The ongoing research scenario for automatic speech recognition (ASR)\nenvisions a clear division between end-to-end approaches and classic modular\nsystems. Even though a high-level comparison between the two approaches in\nterms of their requirements and (dis)advantages is commonly addressed, a closer\ncomparison under similar conditions is not readily available in the literature.\nIn this work, we present a comparison focused on the label topology and\ntraining criterion. We compare two discriminative alignment models with hidden\nMarkov model (HMM) and connectionist temporal classification topology, and two\nfirst-order label context ASR models utilizing factored HMM and strictly\nmonotonic recurrent neural network transducer, respectively. We use different\nmeasurements for the evaluation of the alignment quality, and compare word\nerror rate and real time factor of our best systems. Experiments are conducted\non the LibriSpeech 960h and Switchboard 300h tasks.",
    "authors": [
      "Tina Raissi",
      "Christoph L\u00fcscher",
      "Simon Berger",
      "Ralf Schl\u00fcter",
      "Hermann Ney"
    ],
    "pdf_link": "http://arxiv.org/pdf/2407.11641v1",
    "category": [
      "Speech Recognition",
      "Speech Synthesis"
    ]
  },
  {
    "title": "Vibravox: A Dataset of French Speech Captured with Body-conduction Audio Sensors",
    "abstract": "Vibravox is a dataset compliant with the General Data Protection Regulation\n(GDPR) containing audio recordings using five different body-conduction audio\nsensors : two in-ear microphones, two bone conduction vibration pickups and a\nlaryngophone. The data set also includes audio data from an airborne microphone\nused as a reference. The Vibravox corpus contains 38 hours of speech samples\nand physiological sounds recorded by 188 participants under different acoustic\nconditions imposed by an high order ambisonics 3D spatializer. Annotations\nabout the recording conditions and linguistic transcriptions are also included\nin the corpus. We conducted a series of experiments on various speech-related\ntasks, including speech recognition, speech enhancement and speaker\nverification. These experiments were carried out using state-of-the-art models\nto evaluate and compare their performances on signals captured by the different\naudio sensors offered by the Vibravox dataset, with the aim of gaining a better\ngrasp of their individual characteristics.",
    "authors": [
      "Julien Hauret",
      "Malo Olivier",
      "Thomas Joubaud",
      "Christophe Langrenne",
      "Sarah Poir\u00e9e",
      "V\u00e9ronique Zimpfer",
      "\u00c9ric Bavu"
    ],
    "pdf_link": "http://arxiv.org/pdf/2407.11828v1",
    "category": [
      "Speech Recognition",
      "Speech Synthesis"
    ]
  },
  {
    "title": "DeepGate3: Towards Scalable Circuit Representation Learning",
    "abstract": "Circuit representation learning has shown promising results in advancing the\nfield of Electronic Design Automation (EDA). Existing models, such as DeepGate\nFamily, primarily utilize Graph Neural Networks (GNNs) to encode circuit\nnetlists into gate-level embeddings. However, the scalability of GNN-based\nmodels is fundamentally constrained by architectural limitations, impacting\ntheir ability to generalize across diverse and complex circuit designs. To\naddress these challenges, we introduce DeepGate3, an enhanced architecture that\nintegrates Transformer modules following the initial GNN processing. This novel\narchitecture not only retains the robust gate-level representation capabilities\nof its predecessor, DeepGate2, but also enhances them with the ability to model\nsubcircuits through a novel pooling transformer mechanism. DeepGate3 is further\nrefined with multiple innovative supervision tasks, significantly enhancing its\nlearning process and enabling superior representation of both gate-level and\nsubcircuit structures. Our experiments demonstrate marked improvements in\nscalability and generalizability over traditional GNN-based approaches,\nestablishing a significant step forward in circuit representation learning\ntechnology.",
    "authors": [
      "Zhengyuan Shi",
      "Ziyang Zheng",
      "Sadaf Khan",
      "Jianyuan Zhong",
      "Min Li",
      "Qiang Xu"
    ],
    "pdf_link": "http://arxiv.org/pdf/2407.11095v1",
    "category": [
      "Explainable AI",
      "Multimodal Learning"
    ]
  },
  {
    "title": "Static and multivariate-temporal attentive fusion transformer for readmission risk prediction",
    "abstract": "Background: Accurate short-term readmission prediction of ICU patients is\nsignificant in improving the efficiency of resource assignment by assisting\nphysicians in making discharge decisions. Clinically, both individual static\nstatic and multivariate temporal data collected from ICU monitors play critical\nroles in short-term readmission prediction. Informative static and multivariate\ntemporal feature representation capturing and fusion present challenges for\naccurate readmission prediction. Methods:We propose a novel static and\nmultivariate-temporal attentive fusion transformer (SMTAFormer) to predict\nshort-term readmission of ICU patients by fully leveraging the potential of\ndemographic and dynamic temporal data. In SMTAFormer, we first apply an MLP\nnetwork and a temporal transformer network to learn useful static and temporal\nfeature representations, respectively. Then, the well-designed static and\nmultivariate temporal feature fusion module is applied to fuse static and\ntemporal feature representations by modeling intra-correlation among\nmultivariate temporal features and constructing inter-correlation between\nstatic and multivariate temporal features. Results: We construct a readmission\nrisk assessment (RRA) dataset based on the MIMIC-III dataset. The extensive\nexperiments show that SMTAFormer outperforms advanced methods, in which the\naccuracy of our proposed method is up to 86.6%, and the area under the receiver\noperating characteristic curve (AUC) is up to 0.717. Conclusion: Our proposed\nSMTAFormer can efficiently capture and fuse static and multivariate temporal\nfeature representations. The results show that SMTAFormer significantly\nimproves the short-term readmission prediction performance of ICU patients\nthrough comparisons to strong baselines.",
    "authors": [
      "Zhe Sun",
      "Runzhi Li",
      "Jing Wang",
      "Gang Chen",
      "Siyu Yan",
      "Lihong Ma"
    ],
    "pdf_link": "http://arxiv.org/pdf/2407.11096v1",
    "category": [
      "AI in Healthcare",
      "Multimodal Learning"
    ]
  },
  {
    "title": "CodeV: Empowering LLMs for Verilog Generation through Multi-Level Summarization",
    "abstract": "The increasing complexity and high costs associated with modern processor\ndesign have led to a surge in demand for processor design automation.\nInstruction-tuned large language models (LLMs) have demonstrated remarkable\nperformance in automatically generating code for general-purpose programming\nlanguages like Python. However, these methods fail on hardware description\nlanguages (HDLs) like Verilog due to the scarcity of high-quality instruction\ntuning data, as even advanced LLMs like GPT-3.5 exhibit limited performance on\nVerilog generation. Regarding this issue, we observe that (1) Verilog code\ncollected from the real world has higher quality than those generated by LLMs.\n(2) LLMs like GPT-3.5 excel in summarizing Verilog code rather than generating\nit. Based on these observations, this paper introduces CodeV, a series of\nopen-source instruction-tuned Verilog generation LLMs. Instead of generating\ndescriptions first and then getting the corresponding code from advanced LLMs,\nwe prompt the LLM with Verilog code and let the LLM generate the corresponding\nnatural language description by multi-level summarization. Experimental results\nshow that CodeV relatively surpasses the previous open-source SOTA by 14.4%\n(BetterV in VerilogEval) and 11.3% (RTLCoder in RTLLM) respectively, and also\nrelatively outperforms previous commercial SOTA GPT-4 by 22.1% in VerilogEval.",
    "authors": [
      "Yang Zhao",
      "Di Huang",
      "Chongxiao Li",
      "Pengwei Jin",
      "Ziyuan Nan",
      "Tianyun Ma",
      "Lei Qi",
      "Yansong Pan",
      "Zhenxing Zhang",
      "Rui Zhang",
      "Xishan Zhang",
      "Zidong Du",
      "Qi Guo",
      "Xing Hu",
      "Yunji Chen"
    ],
    "pdf_link": "http://arxiv.org/pdf/2407.10424v2",
    "category": [
      "Speech Synthesis",
      "LLMs"
    ]
  },
  {
    "title": "GraphPrint: Extracting Features from 3D Protein Structure for Drug Target Affinity Prediction",
    "abstract": "Accurate drug target affinity prediction can improve drug candidate\nselection, accelerate the drug discovery process, and reduce drug production\ncosts. Previous work focused on traditional fingerprints or used features\nextracted based on the amino acid sequence in the protein, ignoring its 3D\nstructure which affects its binding affinity. In this work, we propose\nGraphPrint: a framework for incorporating 3D protein structure features for\ndrug target affinity prediction. We generate graph representations for protein\n3D structures using amino acid residue location coordinates and combine them\nwith drug graph representation and traditional features to jointly learn drug\ntarget affinity. Our model achieves a mean square error of 0.1378 and a\nconcordance index of 0.8929 on the KIBA dataset and improves over using\ntraditional protein features alone. Our ablation study shows that the 3D\nprotein structure-based features provide information complementary to\ntraditional features.",
    "authors": [
      "Amritpal Singh"
    ],
    "pdf_link": "http://arxiv.org/pdf/2407.10452v1",
    "category": [
      "AI in Healthcare",
      "Datasets"
    ]
  },
  {
    "title": "BandControlNet: Parallel Transformers-based Steerable Popular Music Generation with Fine-Grained Spatiotemporal Features",
    "abstract": "Controllable music generation promotes the interaction between humans and\ncomposition systems by projecting the users' intent on their desired music. The\nchallenge of introducing controllability is an increasingly important issue in\nthe symbolic music generation field. When building controllable generative\npopular multi-instrument music systems, two main challenges typically present\nthemselves, namely weak controllability and poor music quality. To address\nthese issues, we first propose spatiotemporal features as powerful and\nfine-grained controls to enhance the controllability of the generative model.\nIn addition, an efficient music representation called REMI_Track is designed to\nconvert multitrack music into multiple parallel music sequences and shorten the\nsequence length of each track with Byte Pair Encoding (BPE) techniques.\nSubsequently, we release BandControlNet, a conditional model based on parallel\nTransformers, to tackle the multiple music sequences and generate high-quality\nmusic samples that are conditioned to the given spatiotemporal control\nfeatures. More concretely, the two specially designed modules of\nBandControlNet, namely structure-enhanced self-attention (SE-SA) and\nCross-Track Transformer (CTT), are utilized to strengthen the resulting musical\nstructure and inter-track harmony modeling respectively. Experimental results\ntested on two popular music datasets of different lengths demonstrate that the\nproposed BandControlNet outperforms other conditional music generation models\non most objective metrics in terms of fidelity and inference speed and shows\ngreat robustness in generating long music samples. The subjective evaluations\nshow BandControlNet trained on short datasets can generate music with\ncomparable quality to state-of-the-art models, while outperforming them\nsignificantly using longer datasets.",
    "authors": [
      "Jing Luo",
      "Xinyu Yang",
      "Dorien Herremans"
    ],
    "pdf_link": "http://arxiv.org/pdf/2407.10462v1",
    "category": [
      "Speech Synthesis",
      "Speech Recognition"
    ]
  },
  {
    "title": "GROOT: Generating Robust Watermark for Diffusion-Model-Based Audio Synthesis",
    "abstract": "Amid the burgeoning development of generative models like diffusion models,\nthe task of differentiating synthesized audio from its natural counterpart\ngrows more daunting. Deepfake detection offers a viable solution to combat this\nchallenge. Yet, this defensive measure unintentionally fuels the continued\nrefinement of generative models. Watermarking emerges as a proactive and\nsustainable tactic, preemptively regulating the creation and dissemination of\nsynthesized content. Thus, this paper, as a pioneer, proposes the generative\nrobust audio watermarking method (Groot), presenting a paradigm for proactively\nsupervising the synthesized audio and its source diffusion models. In this\nparadigm, the processes of watermark generation and audio synthesis occur\nsimultaneously, facilitated by parameter-fixed diffusion models equipped with a\ndedicated encoder. The watermark embedded within the audio can subsequently be\nretrieved by a lightweight decoder. The experimental results highlight Groot's\noutstanding performance, particularly in terms of robustness, surpassing that\nof the leading state-of-the-art methods. Beyond its impressive resilience\nagainst individual post-processing attacks, Groot exhibits exceptional\nrobustness when facing compound attacks, maintaining an average watermark\nextraction accuracy of around 95%.",
    "authors": [
      "Weizhi Liu",
      "Yue Li",
      "Dongdong Lin",
      "Hui Tian",
      "Haizhou Li"
    ],
    "pdf_link": "http://arxiv.org/pdf/2407.10471v1",
    "category": [
      "Speech Synthesis",
      "Speech Recognition"
    ]
  },
  {
    "title": "Three Dogmas of Reinforcement Learning",
    "abstract": "Modern reinforcement learning has been conditioned by at least three dogmas.\nThe first is the environment spotlight, which refers to our tendency to focus\non modeling environments rather than agents. The second is our treatment of\nlearning as finding the solution to a task, rather than adaptation. The third\nis the reward hypothesis, which states that all goals and purposes can be well\nthought of as maximization of a reward signal. These three dogmas shape much of\nwhat we think of as the science of reinforcement learning. While each of the\ndogmas have played an important role in developing the field, it is time we\nbring them to the surface and reflect on whether they belong as basic\ningredients of our scientific paradigm. In order to realize the potential of\nreinforcement learning as a canonical frame for researching intelligent agents,\nwe suggest that it is time we shed dogmas one and two entirely, and embrace a\nnuanced approach to the third.",
    "authors": [
      "David Abel",
      "Mark K. Ho",
      "Anna Harutyunyan"
    ],
    "pdf_link": "http://arxiv.org/pdf/2407.10583v1",
    "category": [
      "Reinforcement Learning",
      "Explainable AI"
    ]
  },
  {
    "title": "XEQ Scale for Evaluating XAI Experience Quality Grounded in Psychometric Theory",
    "abstract": "Explainable Artificial Intelligence (XAI) aims to improve the transparency of\nautonomous decision-making through explanations. Recent literature has\nemphasised users' need for holistic \"multi-shot\" explanations and the ability\nto personalise their engagement with XAI systems. We refer to this user-centred\ninteraction as an XAI Experience. Despite advances in creating XAI experiences,\nevaluating them in a user-centred manner has remained challenging. To address\nthis, we introduce the XAI Experience Quality (XEQ) Scale (pronounced \"Seek\"\nScale), for evaluating the user-centred quality of XAI experiences.\nFurthermore, XEQ quantifies the quality of experiences across four evaluation\ndimensions: learning, utility, fulfilment and engagement. These contributions\nextend the state-of-the-art of XAI evaluation, moving beyond the\none-dimensional metrics frequently developed to assess single-shot\nexplanations. In this paper, we present the XEQ scale development and\nvalidation process, including content validation with XAI experts as well as\ndiscriminant and construct validation through a large-scale pilot study. Out\npilot study results offer strong evidence that establishes the XEQ Scale as a\ncomprehensive framework for evaluating user-centred XAI experiences.",
    "authors": [
      "Anjana Wijekoon",
      "Nirmalie Wiratunga",
      "David Corsar",
      "Kyle Martin",
      "Ikechukwu Nkisi-Orji",
      "Belen D\u00edaz-Agudo",
      "Derek Bridge"
    ],
    "pdf_link": "http://arxiv.org/pdf/2407.10662v1",
    "category": [
      "Explainable AI",
      "AI in Healthcare"
    ]
  },
  {
    "title": "Classification of Heart Sounds Using Multi-Branch Deep Convolutional Network and LSTM-CNN",
    "abstract": "This paper presents a fast and cost-effective method for diagnosing cardiac\nabnormalities with high accuracy and reliability using low-cost systems in\nclinics. The primary limitation of automatic diagnosing of cardiac diseases is\nthe rarity of correct and acceptable labeled samples, which can be expensive to\nprepare. To address this issue, two methods are proposed in this work. The\nfirst method is a unique Multi-Branch Deep Convolutional Neural Network (MBDCN)\narchitecture inspired by human auditory processing, specifically designed to\noptimize feature extraction by employing various sizes of convolutional filters\nand audio signal power spectrum as input. In the second method, called as Long\nshort-term memory-Convolutional Neural (LSCN) model, Additionally, the network\narchitecture includes Long Short-Term Memory (LSTM) network blocks to improve\nfeature extraction in the time domain. The innovative approach of combining\nmultiple parallel branches consisting of the one-dimensional convolutional\nlayers along with LSTM blocks helps in achieving superior results in audio\nsignal processing tasks. The experimental results demonstrate superiority of\nthe proposed methods over the state-of-the-art techniques. The overall\nclassification accuracy of heart sounds with the LSCN network is more than 96%.\nThe efficiency of this network is significant compared to common feature\nextraction methods such as Mel Frequency Cepstral Coefficients (MFCC) and\nwavelet transform. Therefore, the proposed method shows promising results in\nthe automatic analysis of heart sounds and has potential applications in the\ndiagnosis and early detection of cardiovascular diseases.",
    "authors": [
      "Seyed Amir Latifi",
      "Hassan Ghassemian",
      "Maryam Imani"
    ],
    "pdf_link": "http://arxiv.org/pdf/2407.10689v1",
    "category": [
      "AI in Healthcare",
      "Speech Recognition"
    ]
  },
  {
    "title": "SEMINAR: Search Enhanced Multi-modal Interest Network and Approximate Retrieval for Lifelong Sequential Recommendation",
    "abstract": "The modeling of users' behaviors is crucial in modern recommendation systems.\nA lot of research focuses on modeling users' lifelong sequences, which can be\nextremely long and sometimes exceed thousands of items. These models use the\ntarget item to search for the most relevant items from the historical sequence.\nHowever, training lifelong sequences in click through rate (CTR) prediction or\npersonalized search ranking (PSR) is extremely difficult due to the\ninsufficient learning problem of ID embedding, especially when the IDs in the\nlifelong sequence features do not exist in the samples of training dataset.\nAdditionally, existing target attention mechanisms struggle to learn the\nmulti-modal representations of items in the sequence well. The distribution of\nmulti-modal embedding (text, image and attributes) output of user's interacted\nitems are not properly aligned and there exist divergence across modalities. We\nalso observe that users' search query sequences and item browsing sequences can\nfully depict users' intents and benefit from each other. To address these\nchallenges, we propose a unified lifelong multi-modal sequence model called\nSEMINAR-Search Enhanced Multi-Modal Interest Network and Approximate Retrieval.\nSpecifically, a network called Pretraining Search Unit (PSU) learns the\nlifelong sequences of multi-modal query-item pairs in a pretraining-finetuning\nmanner with multiple objectives: multi-modal alignment, next query-item pair\nprediction, query-item relevance prediction, etc. After pretraining, the\ndownstream model restores the pretrained embedding as initialization and\nfinetunes the network. To accelerate the online retrieval speed of multi-modal\nembedding, we propose a multi-modal codebook-based product quantization\nstrategy to approximate the exact attention calculati",
    "authors": [
      "Kaiming Shen",
      "Xichen Ding",
      "Zixiang Zheng",
      "Yuqi Gong",
      "Qianqian Li",
      "Zhongyi Liu",
      "Guannan Zhang"
    ],
    "pdf_link": "http://arxiv.org/pdf/2407.10714v1",
    "category": [
      "Multimodal Learning",
      "LLMs"
    ]
  },
  {
    "title": "Exploring the Potentials and Challenges of Deep Generative Models in Product Design Conception",
    "abstract": "The synthesis of product design concepts stands at the crux of early-phase\ndevelopment processes for technical products, traditionally posing an intricate\ninterdisciplinary challenge. The application of deep learning methods,\nparticularly Deep Generative Models (DGMs), holds the promise of automating and\nstreamlining manual iterations and therefore introducing heightened levels of\ninnovation and efficiency. However, DGMs have yet to be widely adopted into the\nsynthesis of product design concepts. This paper aims to explore the reasons\nbehind this limited application and derive the requirements for successful\nintegration of these technologies. We systematically analyze DGM-families (VAE,\nGAN, Diffusion, Transformer, Radiance Field), assessing their strengths,\nweaknesses, and general applicability for product design conception. Our\nobjective is to provide insights that simplify the decision-making process for\nengineers, helping them determine which method might be most effective for\ntheir specific challenges. Recognizing the rapid evolution of this field, we\nhope that our analysis contributes to a fundamental understanding and guides\npractitioners towards the most promising approaches. This work seeks not only\nto illuminate current challenges but also to propose potential solutions,\nthereby offering a clear roadmap for leveraging DGMs in the realm of product\ndesign conception.",
    "authors": [
      "Phillip Mueller",
      "Lars Mikelsons"
    ],
    "pdf_link": "http://arxiv.org/pdf/2407.11104v1",
    "category": [
      "Explainable AI",
      "Multimodal Learning"
    ]
  },
  {
    "title": "Impacts of Data Preprocessing and Hyperparameter Optimization on the Performance of Machine Learning Models Applied to Intrusion Detection Systems",
    "abstract": "In the context of cybersecurity of modern communications networks, Intrusion\nDetection Systems (IDS) have been continuously improved, many of them\nincorporating machine learning (ML) techniques to identify threats. Although\nthere are researches focused on the study of these techniques applied to IDS,\nthe state-of-the-art lacks works concentrated exclusively on the evaluation of\nthe impacts of data pre-processing actions and the optimization of the values\nof the hyperparameters of the ML algorithms in the construction of the models\nof threat identification. This article aims to present a study that fills this\nresearch gap. For that, experiments were carried out with two data sets,\ncomparing attack scenarios with variations of pre-processing techniques and\noptimization of hyperparameters. The results confirm that the proper\napplication of these techniques, in general, makes the generated classification\nmodels more robust and greatly reduces the execution times of these models'\ntraining and testing processes.",
    "authors": [
      "Mateus Guimar\u00e3es Lima",
      "Antony Carvalho",
      "Jo\u00e3o Gabriel \u00c1lvares",
      "Clayton Escouper das Chagas",
      "Ronaldo Ribeiro Goldschmidt"
    ],
    "pdf_link": "http://arxiv.org/pdf/2407.11105v1",
    "category": [
      "Datasets",
      "Explainable AI"
    ]
  },
  {
    "title": "MSegRNN:Enhanced SegRNN Model with Mamba for Long-Term Time Series Forecasting",
    "abstract": "The field of long-term time series forecasting demands handling extensive\nlook-back windows and long-range prediction steps, posing significant\nchallenges for RNN-based methodologies. Among these, SegRNN, a robust\nRNN-driven model, has gained considerable attention in LTSF analysis for\nachieving state-of-the-art results while maintaining a remarkably streamlined\narchitecture. Concurrently, the Mamba structure has demonstrated its advantages\nin small to medium-sized models due to its capability for information\nselection. This study introduces a variant of SegRNN that preprocesses\ninformation using a fine-tuned single-layer Mamba structure. Additionally, it\nincorporates implicit segmentation and residual structures into the model's\nencoding section to further reduce the inherent data iterative cycles of RNN\narchitectures and implicitly integrate inter-channel correlations. This\nvariant, named MSegRNN, utilizes the Mamba structure to select useful\ninformation, resulting in a transformed sequence. The linear-strategy-adapted\nderivative retains the superior memory efficiency of the original SegRNN while\ndemonstrating enhanced performance. Empirical evaluations on real-world LTSF\ndatasets demonstrate the superior performance of our model, thereby\ncontributing to the advancement of LTSF methodologies.",
    "authors": [
      "GaoXiang Zhao",
      "XiaoQiang Wang"
    ],
    "pdf_link": "http://arxiv.org/pdf/2407.10768v1",
    "category": [
      "Speech Synthesis",
      "Explainable AI"
    ]
  },
  {
    "title": "AdapTable: Test-Time Adaptation for Tabular Data via Shift-Aware Uncertainty Calibrator and Label Distribution Handler",
    "abstract": "In real-world applications, tabular data often suffer from distribution\nshifts due to their widespread and abundant nature, leading to erroneous\npredictions of pre-trained machine learning models. However, addressing such\ndistribution shifts in the tabular domain has been relatively underexplored due\nto unique challenges such as varying attributes and dataset sizes, as well as\nthe limited representation learning capabilities of deep learning models for\ntabular data. Particularly, with the recent promising paradigm of test-time\nadaptation (TTA), where we adapt the off-the-shelf model to the unlabeled\ntarget domain during the inference phase without accessing the source domain,\nwe observe that directly adopting commonly used TTA methods from other domains\noften leads to model collapse. We systematically explore challenges in tabular\ndata test-time adaptation, including skewed entropy, complex latent space\ndecision boundaries, confidence calibration issues with both overconfident and\nunder-confident, and model bias towards source label distributions along with\nclass imbalances. Based on these insights, we introduce AdapTable, a novel\ntabular test-time adaptation method that directly modifies output probabilities\nby estimating target label distributions and adjusting initial probabilities\nbased on calibrated uncertainty. Extensive experiments on both natural\ndistribution shifts and synthetic corruptions demonstrate the adaptation\nefficacy of the proposed method.",
    "authors": [
      "Changhun Kim",
      "Taewon Kim",
      "Seungyeon Woo",
      "June Yong Yang",
      "Eunho Yang"
    ],
    "pdf_link": "http://arxiv.org/pdf/2407.10784v1",
    "category": [
      "Datasets",
      "Explainable AI"
    ]
  },
  {
    "title": "GuideLight: \"Industrial Solution\" Guidance for More Practical Traffic Signal Control Agents",
    "abstract": "Currently, traffic signal control (TSC) methods based on reinforcement\nlearning (RL) have proven superior to traditional methods. However, most RL\nmethods face difficulties when applied in the real world due to three factors:\ninput, output, and the cycle-flow relation. The industry's observable input is\nmuch more limited than simulation-based RL methods. For real-world solutions,\nonly flow can be reliably collected, whereas common RL methods need more. For\nthe output action, most RL methods focus on acyclic control, which real-world\nsignal controllers do not support. Most importantly, industry standards require\na consistent cycle-flow relationship: non-decreasing and different response\nstrategies for low, medium, and high-level flows, which is ignored by the RL\nmethods. To narrow the gap between RL methods and industry standards, we\ninnovatively propose to use industry solutions to guide the RL agent.\nSpecifically, we design behavior cloning and curriculum learning to guide the\nagent to mimic and meet industry requirements and, at the same time, leverage\nthe power of exploration and exploitation in RL for better performance. We\ntheoretically prove that such guidance can largely decrease the sample\ncomplexity to polynomials in the horizon when searching for an optimal policy.\nOur rigid experiments show that our method has good cycle-flow relation and\nsuperior performance.",
    "authors": [
      "Haoyuan Jiang",
      "Xuantang Xiong",
      "Ziyue Li",
      "Hangyu Mao",
      "Guanghu Sui",
      "Jingqing Ruan",
      "Yuheng Cheng",
      "Hua Wei",
      "Wolfgang Ketter",
      "Rui Zhao"
    ],
    "pdf_link": "http://arxiv.org/pdf/2407.10811v1",
    "category": [
      "Reinforcement Learning",
      "Explainable AI"
    ]
  },
  {
    "title": "Towards Enhanced Classification of Abnormal Lung sound in Multi-breath: A Light Weight Multi-label and Multi-head Attention Classification Method",
    "abstract": "This study aims to develop an auxiliary diagnostic system for classifying\nabnormal lung respiratory sounds, enhancing the accuracy of automatic abnormal\nbreath sound classification through an innovative multi-label learning approach\nand multi-head attention mechanism. Addressing the issue of class imbalance and\nlack of diversity in existing respiratory sound datasets, our study employs a\nlightweight and highly accurate model, using a two-dimensional label set to\nrepresent multiple respiratory sound characteristics. Our method achieved a\n59.2% ICBHI score in the four-category task on the ICBHI2017 dataset,\ndemonstrating its advantages in terms of lightweight and high accuracy. This\nstudy not only improves the accuracy of automatic diagnosis of lung respiratory\nsound abnormalities but also opens new possibilities for clinical applications.",
    "authors": [
      "Yi-Wei Chua",
      "Yun-Chien Cheng"
    ],
    "pdf_link": "http://arxiv.org/pdf/2407.10828v1",
    "category": [
      "AI in Healthcare",
      "Speech Recognition"
    ]
  },
  {
    "title": "Exploration in Knowledge Transfer Utilizing Reinforcement Learning",
    "abstract": "The contribution focuses on the problem of exploration within the task of\nknowledge transfer. Knowledge transfer refers to the useful application of the\nknowledge gained while learning the source task in the target task. The\nintended benefit of knowledge transfer is to speed up the learning process of\nthe target task. The article aims to compare several exploration methods used\nwithin a deep transfer learning algorithm, particularly Deep Target Transfer\n$Q$-learning. The methods used are $\\epsilon$-greedy, Boltzmann, and upper\nconfidence bound exploration. The aforementioned transfer learning algorithms\nand exploration methods were tested on the virtual drone problem. The results\nhave shown that the upper confidence bound algorithm performs the best out of\nthese options. Its sustainability to other applications is to be checked.",
    "authors": [
      "Adam Jedli\u010dka",
      "Tatiana Valentine Guy"
    ],
    "pdf_link": "http://arxiv.org/pdf/2407.10835v1",
    "category": [
      "Reinforcement Learning",
      "Explainable AI"
    ]
  },
  {
    "title": "Offline Reinforcement Learning with Imputed Rewards",
    "abstract": "Offline Reinforcement Learning (ORL) offers a robust solution to training\nagents in applications where interactions with the environment must be strictly\nlimited due to cost, safety, or lack of accurate simulation environments.\nDespite its potential to facilitate deployment of artificial agents in the real\nworld, Offline Reinforcement Learning typically requires very many\ndemonstrations annotated with ground-truth rewards. Consequently,\nstate-of-the-art ORL algorithms can be difficult or impossible to apply in\ndata-scarce scenarios. In this paper we propose a simple but effective Reward\nModel that can estimate the reward signal from a very limited sample of\nenvironment transitions annotated with rewards. Once the reward signal is\nmodeled, we use the Reward Model to impute rewards for a large sample of\nreward-free transitions, thus enabling the application of ORL techniques. We\ndemonstrate the potential of our approach on several D4RL continuous locomotion\ntasks. Our results show that, using only 1\\% of reward-labeled transitions from\nthe original datasets, our learned reward model is able to impute rewards for\nthe remaining 99\\% of the transitions, from which performant agents can be\nlearned using Offline Reinforcement Learning.",
    "authors": [
      "Carlo Romeo",
      "Andrew D. Bagdanov"
    ],
    "pdf_link": "http://arxiv.org/pdf/2407.10839v1",
    "category": [
      "Reinforcement Learning",
      "Explainable AI"
    ]
  },
  {
    "title": "Deep Causal Learning to Explain and Quantify The Geo-Tension's Impact on Natural Gas Market",
    "abstract": "Natural gas demand is a crucial factor for predicting natural gas prices and\nthus has a direct influence on the power system. However, existing methods face\nchallenges in assessing the impact of shocks, such as the outbreak of the\nRussian-Ukrainian war. In this context, we apply deep neural network-based\nGranger causality to identify important drivers of natural gas demand.\nFurthermore, the resulting dependencies are used to construct a counterfactual\ncase without the outbreak of the war, providing a quantifiable estimate of the\noverall effect of the shock on various German energy sectors. The code and\ndataset are available at https://github.com/bonaldli/CausalEnergy.",
    "authors": [
      "Philipp Kai Peter",
      "Yulin Li",
      "Ziyue Li",
      "Wolfgang Ketter"
    ],
    "pdf_link": "http://arxiv.org/pdf/2407.10878v1",
    "category": [
      "Explainable AI",
      "Datasets"
    ]
  },
  {
    "title": "Hey, That's My Model! Introducing Chain & Hash, An LLM Fingerprinting Technique",
    "abstract": "Amid growing concerns over the ease of theft and misuse of Large Language\nModels (LLMs), the need for fingerprinting models has increased.\nFingerprinting, in this context, means that the model owner can link a given\nmodel to their original version, thereby identifying if their model is being\nmisused or has been completely stolen. In this paper, we first define a set\nfive properties a successful fingerprint should satisfy; namely, the\nfingerprint should be Transparent, Efficient, Persistent, Robust, and\nUnforgeable. Next, we propose Chain & Hash, a new, simple fingerprinting\napproach that implements a fingerprint with a cryptographic flavor, achieving\nall these properties. Chain & Hash involves generating a set of questions (the\nfingerprints) along with a set of potential answers. These elements are hashed\ntogether using a secure hashing technique to select the value for each\nquestion, hence providing an unforgeability property-preventing adversaries\nfrom claiming false ownership. We evaluate the Chain & Hash technique on\nmultiple models and demonstrate its robustness against benign transformations,\nsuch as fine-tuning on different datasets, and adversarial attempts to erase\nthe fingerprint. Finally, our experiments demonstrate the efficiency of\nimplementing Chain & Hash and its utility, where fingerprinted models achieve\nalmost the same performance as non-fingerprinted ones across different\nbenchmarks.",
    "authors": [
      "Mark Russinovich",
      "Ahmed Salem"
    ],
    "pdf_link": "http://arxiv.org/pdf/2407.10887v1",
    "category": [
      "LLMs",
      "Speech Recognition"
    ]
  },
  {
    "title": "A Unified Differentiable Boolean Operator with Fuzzy Logic",
    "abstract": "This paper presents a unified differentiable boolean operator for implicit\nsolid shape modeling using Constructive Solid Geometry (CSG). Traditional CSG\nrelies on min, max operators to perform boolean operations on implicit shapes.\nBut because these boolean operators are discontinuous and discrete in the\nchoice of operations, this makes optimization over the CSG representation\nchallenging. Drawing inspiration from fuzzy logic, we present a unified boolean\noperator that outputs a continuous function and is differentiable with respect\nto operator types. This enables optimization of both the primitives and the\nboolean operations employed in CSG with continuous optimization techniques,\nsuch as gradient descent. We further demonstrate that such a continuous boolean\noperator allows modeling of both sharp mechanical objects and smooth organic\nshapes with the same framework. Our proposed boolean operator opens up new\npossibilities for future research toward fully continuous CSG optimization.",
    "authors": [
      "Hsueh-Ti Derek Liu",
      "Maneesh Agrawala",
      "Cem Yuksel",
      "Tim Omernick",
      "Vinith Misra",
      "Stefano Corazza",
      "Morgan McGuire",
      "Victor Zordan"
    ],
    "pdf_link": "http://arxiv.org/pdf/2407.10954v1",
    "category": [
      "Reinforcement Learning",
      "Multimodal Learning"
    ]
  },
  {
    "title": "BECAUSE: Bilinear Causal Representation for Generalizable Offline Model-based Reinforcement Learning",
    "abstract": "Offline model-based reinforcement learning (MBRL) enhances data efficiency by\nutilizing pre-collected datasets to learn models and policies, especially in\nscenarios where exploration is costly or infeasible. Nevertheless, its\nperformance often suffers from the objective mismatch between model and policy\nlearning, resulting in inferior performance despite accurate model predictions.\nThis paper first identifies the primary source of this mismatch comes from the\nunderlying confounders present in offline data for MBRL. Subsequently, we\nintroduce \\textbf{B}ilin\\textbf{E}ar \\textbf{CAUS}al\nr\\textbf{E}presentation~(BECAUSE), an algorithm to capture causal\nrepresentation for both states and actions to reduce the influence of the\ndistribution shift, thus mitigating the objective mismatch problem.\nComprehensive evaluations on 18 tasks that vary in data quality and environment\ncontext demonstrate the superior performance of BECAUSE over existing offline\nRL algorithms. We show the generalizability and robustness of BECAUSE under\nfewer samples or larger numbers of confounders. Additionally, we offer\ntheoretical analysis of BECAUSE to prove its error bound and sample efficiency\nwhen integrating causal representation into offline MBRL.",
    "authors": [
      "Haohong Lin",
      "Wenhao Ding",
      "Jian Chen",
      "Laixi Shi",
      "Jiacheng Zhu",
      "Bo Li",
      "Ding Zhao"
    ],
    "pdf_link": "http://arxiv.org/pdf/2407.10967v1",
    "category": [
      "Reinforcement Learning",
      "Explainable AI"
    ]
  },
  {
    "title": "Pacer and Runner: Cooperative Learning Framework between Single- and Cross-Domain Sequential Recommendation",
    "abstract": "Cross-Domain Sequential Recommendation (CDSR) improves recommendation\nperformance by utilizing information from multiple domains, which contrasts\nwith Single-Domain Sequential Recommendation (SDSR) that relies on a historical\ninteraction within a specific domain. However, CDSR may underperform compared\nto the SDSR approach in certain domains due to negative transfer, which occurs\nwhen there is a lack of relation between domains or different levels of data\nsparsity. To address the issue of negative transfer, our proposed CDSR model\nestimates the degree of negative transfer of each domain and adaptively assigns\nit as a weight factor to the prediction loss, to control gradient flows through\ndomains with significant negative transfer. To this end, our model compares the\nperformance of a model trained on multiple domains (CDSR) with a model trained\nsolely on the specific domain (SDSR) to evaluate the negative transfer of each\ndomain using our asymmetric cooperative network. In addition, to facilitate the\ntransfer of valuable cues between the SDSR and CDSR tasks, we developed an\nauxiliary loss that maximizes the mutual information between the representation\npairs from both tasks on a per-domain basis. This cooperative learning between\nSDSR and CDSR tasks is similar to the collaborative dynamics between pacers and\nrunners in a marathon. Our model outperformed numerous previous works in\nextensive experiments on two real-world industrial datasets across ten service\ndomains. We also have deployed our model in the recommendation system of our\npersonal assistant app service, resulting in 21.4% increase in click-through\nrate compared to existing models, which is valuable to real-world business.",
    "authors": [
      "Chung Park",
      "Taesan Kim",
      "Hyungjun Yoon",
      "Junui Hong",
      "Yelim Yu",
      "Mincheol Cho",
      "Minsung Choi",
      "Jaegul Choo"
    ],
    "pdf_link": "http://arxiv.org/pdf/2407.11245v1",
    "category": [
      "Reinforcement Learning",
      "Multimodal Learning"
    ]
  },
  {
    "title": "Disentangling Representations in RNNs through Multi-task Learning",
    "abstract": "Abstract, or disentangled, representations are a promising mathematical\nframework for efficient and effective generalization in both biological and\nartificial systems. We investigate abstract representations in the context of\nmulti-task classification over noisy evidence streams -- a canonical\ndecision-making neuroscience paradigm. We derive theoretical bounds that\nguarantee the emergence of disentangled representations in the latent state of\nany optimal multi-task classifier, when the number of tasks exceeds the\ndimensionality of the state space. We experimentally confirm that RNNs trained\non multi-task classification learn disentangled representations in the form of\ncontinuous attractors, leading to zero-shot out-of-distribution (OOD)\ngeneralization. We demonstrate the flexibility of the abstract RNN\nrepresentations across various decision boundary geometries and in tasks\nrequiring classification confidence estimation. Our framework suggests a\ngeneral principle for the formation of cognitive maps that organize knowledge\nto enable flexible generalization in biological and artificial systems alike,\nand closely relates to representations found in humans and animals during\ndecision-making and spatial reasoning tasks.",
    "authors": [
      "Pantelis Vafidis",
      "Aman Bhargava",
      "Antonio Rangel"
    ],
    "pdf_link": "http://arxiv.org/pdf/2407.11249v1",
    "category": [
      "Reinforcement Learning",
      "Explainable AI"
    ]
  },
  {
    "title": "CLAMS: A System for Zero-Shot Model Selection for Clustering",
    "abstract": "We propose an AutoML system that enables model selection on clustering\nproblems by leveraging optimal transport-based dataset similarity. Our\nobjective is to establish a comprehensive AutoML pipeline for clustering\nproblems and provide recommendations for selecting the most suitable\nalgorithms, thus opening up a new area of AutoML beyond the traditional\nsupervised learning settings. We compare our results against multiple\nclustering baselines and find that it outperforms all of them, hence\ndemonstrating the utility of similarity-based automated model selection for\nsolving clustering applications.",
    "authors": [
      "Prabhant Singh",
      "Pieter Gijsbers",
      "Murat Onur Yildirim",
      "Elif Ceren Gok",
      "Joaquin Vanschoren"
    ],
    "pdf_link": "http://arxiv.org/pdf/2407.11286v1",
    "category": [
      "Datasets",
      "Multimodal Learning"
    ]
  },
  {
    "title": "COMET: \"Cone of experience\" enhanced large multimodal model for mathematical problem generation",
    "abstract": "The automatic generation of high-quality mathematical problems is practically\nvaluable in many educational scenarios. Large multimodal model provides a novel\ntechnical approach for the mathematical problem generation because of its wide\nsuccess in cross-modal data scenarios. However, the traditional method of\nseparating problem solving from problem generation and the mainstream\nfine-tuning framework of monotonous data structure with homogeneous training\nobjectives limit the application of large multimodal model in mathematical\nproblem generation. Addressing these challenges, this paper proposes COMET, a\n\"Cone of Experience\" enhanced large multimodal model for mathematical problem\ngeneration. Firstly, from the perspective of mutual ability promotion and\napplication logic, we unify stem generation and problem solving into\nmathematical problem generation. Secondly, a three-stage fine-turning framework\nguided by the \"Cone of Experience\" is proposed. The framework divides the\nfine-tuning data into symbolic experience, iconic experience, and direct\nexperience to draw parallels with experiences in the career growth of teachers.\nSeveral fine-grained data construction and injection methods are designed in\nthis framework. Finally, we construct a Chinese multimodal mathematical problem\ndataset to fill the vacancy of Chinese multimodal data in this field. Combined\nwith objective and subjective indicators, experiments on multiple datasets\nfully verify the effectiveness of the proposed framework and model.",
    "authors": [
      "Sannyuya Liu",
      "Jintian Feng",
      "Zongkai Yang",
      "Yawei Luo",
      "Qian Wan",
      "Xiaoxuan Shen",
      "Jianwen Sun"
    ],
    "pdf_link": "http://arxiv.org/pdf/2407.11315v1",
    "category": [
      "Multimodal Learning",
      "Datasets"
    ]
  },
  {
    "title": "Feature Inference Attack on Shapley Values",
    "abstract": "As a solution concept in cooperative game theory, Shapley value is highly\nrecognized in model interpretability studies and widely adopted by the leading\nMachine Learning as a Service (MLaaS) providers, such as Google, Microsoft, and\nIBM. However, as the Shapley value-based model interpretability methods have\nbeen thoroughly studied, few researchers consider the privacy risks incurred by\nShapley values, despite that interpretability and privacy are two foundations\nof machine learning (ML) models.\n  In this paper, we investigate the privacy risks of Shapley value-based model\ninterpretability methods using feature inference attacks: reconstructing the\nprivate model inputs based on their Shapley value explanations. Specifically,\nwe present two adversaries. The first adversary can reconstruct the private\ninputs by training an attack model based on an auxiliary dataset and black-box\naccess to the model interpretability services. The second adversary, even\nwithout any background knowledge, can successfully reconstruct most of the\nprivate features by exploiting the local linear correlations between the model\ninputs and outputs. We perform the proposed attacks on the leading MLaaS\nplatforms, i.e., Google Cloud, Microsoft Azure, and IBM aix360. The\nexperimental results demonstrate the vulnerability of the state-of-the-art\nShapley value-based model interpretability methods used in the leading MLaaS\nplatforms and highlight the significance and necessity of designing\nprivacy-preserving model interpretability methods in future studies. To our\nbest knowledge, this is also the first work that investigates the privacy risks\nof Shapley values.",
    "authors": [
      "Xinjian Luo",
      "Yangfan Jiang",
      "Xiaokui Xiao"
    ],
    "pdf_link": "http://arxiv.org/pdf/2407.11359v1",
    "category": [
      "Explainable AI",
      "Datasets"
    ]
  },
  {
    "title": "Thorns and Algorithms: Navigating Generative AI Challenges Inspired by Giraffes and Acacias",
    "abstract": "The interplay between humans and Generative AI (Gen AI) draws an insightful\nparallel with the dynamic relationship between giraffes and acacias on the\nAfrican Savannah. Just as giraffes navigate the acacia's thorny defenses to\ngain nourishment, humans engage with Gen AI, maneuvering through ethical and\noperational challenges to harness its benefits. This paper explores how, like\nyoung giraffes that are still mastering their environment, humans are in the\nearly stages of adapting to and shaping Gen AI. It delves into the strategies\nhumans are developing and refining to help mitigate risks such as bias,\nmisinformation, and privacy breaches, that influence and shape Gen AI's\nevolution. While the giraffe-acacia analogy aptly frames human-AI relations, it\ncontrasts nature's evolutionary perfection with the inherent flaws of\nhuman-made technology and the tendency of humans to misuse it, giving rise to\nmany ethical dilemmas. Through the HHH framework we identify pathways to embed\nvalues of helpfulness, honesty, and harmlessness in AI development, fostering\nsafety-aligned agents that resonate with human values. This narrative presents\na cautiously optimistic view of human resilience and adaptability, illustrating\nour capacity to harness technologies and implement safeguards effectively,\nwithout succumbing to their perils. It emphasises a symbiotic relationship\nwhere humans and AI continually shape each other for mutual benefit.",
    "authors": [
      "Waqar Hussain"
    ],
    "pdf_link": "http://arxiv.org/pdf/2407.11360v1",
    "category": [
      "Explainable AI",
      "AI in Healthcare"
    ]
  },
  {
    "title": "Generally-Occurring Model Change for Robust Counterfactual Explanations",
    "abstract": "With the increasing impact of algorithmic decision-making on human lives, the\ninterpretability of models has become a critical issue in machine learning.\nCounterfactual explanation is an important method in the field of interpretable\nmachine learning, which can not only help users understand why machine learning\nmodels make specific decisions, but also help users understand how to change\nthese decisions. Naturally, it is an important task to study the robustness of\ncounterfactual explanation generation algorithms to model changes. Previous\nliterature has proposed the concept of Naturally-Occurring Model Change, which\nhas given us a deeper understanding of robustness to model change. In this\npaper, we first further generalize the concept of Naturally-Occurring Model\nChange, proposing a more general concept of model parameter changes,\nGenerally-Occurring Model Change, which has a wider range of applicability. We\nalso prove the corresponding probabilistic guarantees. In addition, we consider\na more specific problem, data set perturbation, and give relevant theoretical\nresults by combining optimization theory.",
    "authors": [
      "Ao Xu",
      "Tieru Wu"
    ],
    "pdf_link": "http://arxiv.org/pdf/2407.11426v1",
    "category": [
      "Explainable AI",
      "Reinforcement Learning"
    ]
  },
  {
    "title": "Repurformer: Transformers for Repurposing-Aware Molecule Generation",
    "abstract": "Generating as diverse molecules as possible with desired properties is\ncrucial for drug discovery research, which invokes many approaches based on\ndeep generative models today. Despite recent advancements in these models,\nparticularly in variational autoencoders (VAEs), generative adversarial\nnetworks (GANs), Transformers, and diffusion models, a significant challenge\nknown as \\textit{the sample bias problem} remains. This problem occurs when\ngenerated molecules targeting the same protein tend to be structurally similar,\nreducing the diversity of generation. To address this, we propose leveraging\nmulti-hop relationships among proteins and compounds. Our model, Repurformer,\nintegrates bi-directional pretraining with Fast Fourier Transform (FFT) and\nlow-pass filtering (LPF) to capture complex interactions and generate diverse\nmolecules. A series of experiments on BindingDB dataset confirm that\nRepurformer successfully creates substitutes for anchor compounds that resemble\npositive compounds, increasing diversity between the anchor and generated\ncompounds.",
    "authors": [
      "Changhun Lee",
      "Gyumin Lee"
    ],
    "pdf_link": "http://arxiv.org/pdf/2407.11439v1",
    "category": [
      "Datasets",
      "Explainable AI"
    ]
  },
  {
    "title": "Graceful task adaptation with a bi-hemispheric RL agent",
    "abstract": "In humans, responsibility for performing a task gradually shifts from the\nright hemisphere to the left. The Novelty-Routine Hypothesis (NRH) states that\nthe right and left hemispheres are used to perform novel and routine tasks\nrespectively, enabling us to learn a diverse range of novel tasks while\nperforming the task capably. Drawing on the NRH, we develop a reinforcement\nlearning agent with specialised hemispheres that can exploit generalist\nknowledge from the right-hemisphere to avoid poor initial performance on novel\ntasks. In addition, we find that this design has minimal impact on its ability\nto learn novel tasks. We conclude by identifying improvements to our agent and\nexploring potential expansion to the continual learning setting.",
    "authors": [
      "Grant Nicholas",
      "Levin Kuhlmann",
      "Gideon Kowadlo"
    ],
    "pdf_link": "http://arxiv.org/pdf/2407.11456v1",
    "category": [
      "Reinforcement Learning",
      "Multimodal Learning"
    ]
  },
  {
    "title": "Investigating Imperceptibility of Adversarial Attacks on Tabular Data: An Empirical Analysis",
    "abstract": "Adversarial attacks are a potential threat to machine learning models, as\nthey can cause the model to make incorrect predictions by introducing\nimperceptible perturbations to the input data. While extensively studied in\nunstructured data like images, their application to structured data like\ntabular data presents unique challenges due to the heterogeneity and intricate\nfeature interdependencies of tabular data. Imperceptibility in tabular data\ninvolves preserving data integrity while potentially causing misclassification,\nunderscoring the need for tailored imperceptibility criteria for tabular data.\nHowever, there is currently a lack of standardised metrics for assessing\nadversarial attacks specifically targeted at tabular data. To address this gap,\nwe derive a set of properties for evaluating the imperceptibility of\nadversarial attacks on tabular data. These properties are defined to capture\nseven perspectives of perturbed data: proximity to original inputs, sparsity of\nalterations, deviation to datapoints in the original dataset, sensitivity of\naltering sensitive features, immutability of perturbation, feasibility of\nperturbed values and intricate feature interdepencies among tabular features.\nFurthermore, we conduct both quantitative empirical evaluation and case-based\nqualitative examples analysis for seven properties. The evaluation reveals a\ntrade-off between attack success and imperceptibility, particularly concerning\nproximity, sensitivity, and deviation. Although no evaluated attacks can\nachieve optimal effectiveness and imperceptibility simultaneously, unbounded\nattacks prove to be more promised for tabular data in crafting imperceptible\nadversarial examples. The study also highlights the limitation of evaluated\nalgorithms in controlling sparsity effectively. We suggest incorporating a\nsparsity metric in future attack design to regulate the number of perturbed\nfeatures.",
    "authors": [
      "Zhipeng He",
      "Chun Ouyang",
      "Laith Alzubaidi",
      "Alistair Barros",
      "Catarina Moreira"
    ],
    "pdf_link": "http://arxiv.org/pdf/2407.11463v1",
    "category": [
      "Explainable AI",
      "Datasets"
    ]
  },
  {
    "title": "XTraffic: A Dataset Where Traffic Meets Incidents with Explainability and More",
    "abstract": "Long-separated research has been conducted on two highly correlated tracks:\ntraffic and incidents. Traffic track witnesses complicating deep learning\nmodels, e.g., to push the prediction a few percent more accurate, and the\nincident track only studies the incidents alone, e.g., to infer the incident\nrisk. We, for the first time, spatiotemporally aligned the two tracks in a\nlarge-scale region (16,972 traffic nodes) over the whole year of 2023: our\nXTraffic dataset includes traffic, i.e., time-series indexes on traffic flow,\nlane occupancy, and average vehicle speed, and incidents, whose records are\nspatiotemporally-aligned with traffic data, with seven different incident\nclasses. Additionally, each node includes detailed physical and policy-level\nmeta-attributes of lanes. Our data can revolutionalize traditional\ntraffic-related tasks towards higher interpretability and practice: instead of\ntraditional prediction or classification tasks, we conduct: (1) post-incident\ntraffic forecasting to quantify the impact of different incidents on traffic\nindexes; (2) incident classification using traffic indexes to determine the\nincidents types for precautions measures; (3) global causal analysis among the\ntraffic indexes, meta-attributes, and incidents to give high-level guidance of\nthe interrelations of various factors; (4) local causal analysis within road\nnodes to examine how different incidents affect the road segments' relations.\nThe dataset is available at http://xaitraffic.github.io.",
    "authors": [
      "Xiaochuan Gou",
      "Ziyue Li",
      "Tian Lan",
      "Junpeng Lin",
      "Zhishuai Li",
      "Bingyu Zhao",
      "Chen Zhang",
      "Di Wang",
      "Xiangliang Zhang"
    ],
    "pdf_link": "http://arxiv.org/pdf/2407.11477v1",
    "category": [
      "Datasets",
      "Explainable AI"
    ]
  },
  {
    "title": "AIGC for Industrial Time Series: From Deep Generative Models to Large Generative Models",
    "abstract": "With the remarkable success of generative models like ChatGPT, Artificial\nIntelligence Generated Content (AIGC) is undergoing explosive development. Not\nlimited to text and images, generative models can generate industrial time\nseries data, addressing challenges such as the difficulty of data collection\nand data annotation. Due to their outstanding generation ability, they have\nbeen widely used in Internet of Things, metaverse, and cyber-physical-social\nsystems to enhance the efficiency of industrial production. In this paper, we\npresent a comprehensive overview of generative models for industrial time\nseries from deep generative models (DGMs) to large generative models (LGMs).\nFirst, a DGM-based AIGC framework is proposed for industrial time series\ngeneration. Within this framework, we survey advanced industrial DGMs and\npresent a multi-perspective categorization. Furthermore, we systematically\nanalyze the critical technologies required to construct industrial LGMs from\nfour aspects: large-scale industrial dataset, LGMs architecture for complex\nindustrial characteristics, self-supervised training for industrial time\nseries, and fine-tuning of industrial downstream tasks. Finally, we conclude\nthe challenges and future directions to enable the development of generative\nmodels in industry.",
    "authors": [
      "Lei Ren",
      "Haiteng Wang",
      "Yang Tang",
      "Chunhua Yang"
    ],
    "pdf_link": "http://arxiv.org/pdf/2407.11480v1",
    "category": [
      "Datasets",
      "Speech Synthesis"
    ]
  },
  {
    "title": "Multi-Channel Masked Autoencoder and Comprehensive Evaluations for Reconstructing 12-Lead ECG from Arbitrary Single-Lead ECG",
    "abstract": "In the context of cardiovascular diseases (CVD) that exhibit an elevated\nprevalence and mortality, the electrocardiogram (ECG) is a popular and standard\ndiagnostic tool for doctors, commonly utilizing a 12-lead configuration in\nclinical practice. However, the 10 electrodes placed on the surface would cause\na lot of inconvenience and discomfort, while the rapidly advancing wearable\ndevices adopt the reduced-lead or single-lead ECG to reduce discomfort as a\nsolution in long-term monitoring. Since the single-lead ECG is a subset of\n12-lead ECG, it provides insufficient cardiac health information and plays a\nsubstandard role in real-world healthcare applications. Hence, it is necessary\nto utilize signal generation technologies to reduce their clinical importance\ngap by reconstructing 12-lead ECG from the real single-lead ECG. Specifically,\nthis study proposes a multi-channel masked autoencoder (MCMA) for this goal. In\nthe experimental results, the visualized results between the generated and real\nsignals can demonstrate the effectiveness of the proposed framework. At the\nsame time, this study introduces a comprehensive evaluation benchmark named\nECGGenEval, encompassing the signal-level, feature-level, and diagnostic-level\nevaluations, providing a holistic assessment of 12-lead ECG signals and\ngenerative model. Further, the quantitative experimental results are as\nfollows, the mean square errors of 0.0178 and 0.0658, correlation coefficients\nof 0.7698 and 0.7237 in the signal-level evaluation, the average F1-score with\ntwo generated 12-lead ECG is 0.8319 and 0.7824 in the diagnostic-level\nevaluation, achieving the state-of-the-art performance. The open-source code is\npublicly available at \\url{https://github.com/CHENJIAR3/MCMA}.",
    "authors": [
      "Jiarong Chen",
      "Wanqing Wu",
      "Tong Liu",
      "Shenda Hong"
    ],
    "pdf_link": "http://arxiv.org/pdf/2407.11481v1",
    "category": [
      "AI in Healthcare",
      "Datasets"
    ]
  },
  {
    "title": "A Meta-Learning Approach for Multi-Objective Reinforcement Learning in Sustainable Home Environments",
    "abstract": "Effective residential appliance scheduling is crucial for sustainable living.\nWhile multi-objective reinforcement learning (MORL) has proven effective in\nbalancing user preferences in appliance scheduling, traditional MORL struggles\nwith limited data in non-stationary residential settings characterized by\nrenewable generation variations. Significant context shifts that can invalidate\npreviously learned policies. To address these challenges, we extend\nstate-of-the-art MORL algorithms with the meta-learning paradigm, enabling\nrapid, few-shot adaptation to shifting contexts. Additionally, we employ an\nauto-encoder (AE)-based unsupervised method to detect environment context\nchanges. We have also developed a residential energy environment to evaluate\nour method using real-world data from London residential settings. This study\nnot only assesses the application of MORL in residential appliance scheduling\nbut also underscores the effectiveness of meta-learning in energy management.\nOur top-performing method significantly surpasses the best baseline, while the\ntrained model saves 3.28% on electricity bills, a 2.74% increase in user\ncomfort, and a 5.9% improvement in expected utility. Additionally, it reduces\nthe sparsity of solutions by 62.44%. Remarkably, these gains were accomplished\nusing 96.71% less training data and 61.1% fewer training steps.",
    "authors": [
      "Junlin Lu",
      "Patrick Mannion",
      "Karl Mason"
    ],
    "pdf_link": "http://arxiv.org/pdf/2407.11489v1",
    "category": [
      "Reinforcement Learning",
      "Multimodal Learning"
    ]
  },
  {
    "title": "Diff-MTS: Temporal-Augmented Conditional Diffusion-based AIGC for Industrial Time Series Towards the Large Model Era",
    "abstract": "Industrial Multivariate Time Series (MTS) is a critical view of the\nindustrial field for people to understand the state of machines. However, due\nto data collection difficulty and privacy concerns, available data for building\nindustrial intelligence and industrial large models is far from sufficient.\nTherefore, industrial time series data generation is of great importance.\nExisting research usually applies Generative Adversarial Networks (GANs) to\ngenerate MTS. However, GANs suffer from unstable training process due to the\njoint training of the generator and discriminator. This paper proposes a\ntemporal-augmented conditional adaptive diffusion model, termed Diff-MTS, for\nMTS generation. It aims to better handle the complex temporal dependencies and\ndynamics of MTS data. Specifically, a conditional Adaptive Maximum-Mean\nDiscrepancy (Ada-MMD) method has been proposed for the controlled generation of\nMTS, which does not require a classifier to control the generation. It improves\nthe condition consistency of the diffusion model. Moreover, a Temporal\nDecomposition Reconstruction UNet (TDR-UNet) is established to capture complex\ntemporal patterns and further improve the quality of the synthetic time series.\nComprehensive experiments on the C-MAPSS and FEMTO datasets demonstrate that\nthe proposed Diff-MTS performs substantially better in terms of diversity,\nfidelity, and utility compared with GAN-based methods. These results show that\nDiff-MTS facilitates the generation of industrial data, contributing to\nintelligent maintenance and the construction of industrial large models.",
    "authors": [
      "Lei Ren",
      "Haiteng Wang",
      "Yuanjun Laili"
    ],
    "pdf_link": "http://arxiv.org/pdf/2407.11501v1",
    "category": [
      "Datasets",
      "Explainable AI"
    ]
  },
  {
    "title": "LRQ: Optimizing Post-Training Quantization for Large Language Models by Learning Low-Rank Weight-Scaling Matrices",
    "abstract": "With the commercialization of large language models (LLMs), weight-activation\nquantization has emerged to compress and accelerate LLMs, achieving high\nthroughput while reducing inference costs. However, existing post-training\nquantization (PTQ) techniques for quantizing weights and activations of LLMs\nstill suffer from non-negligible accuracy drops, especially on massive\nmultitask language understanding. To address this issue, we propose Low-Rank\nQuantization (LRQ) $-$ a simple yet effective post-training weight quantization\nmethod for LLMs that reconstructs the outputs of an intermediate Transformer\nblock by leveraging low-rank weight-scaling matrices, replacing the\nconventional full weight-scaling matrices that entail as many learnable scales\nas their associated weights. Thanks to parameter sharing via low-rank\nstructure, LRQ only needs to learn significantly fewer parameters while\nenabling the individual scaling of weights, thus boosting the generalization\ncapability of quantized LLMs. We show the superiority of LRQ over prior LLM PTQ\nworks under (i) $8$-bit weight and per-tensor activation quantization, (ii)\n$4$-bit weight and $8$-bit per-token activation quantization, and (iii) low-bit\nweight-only quantization schemes. Our code is available at\n\\url{https://github.com/onliwad101/FlexRound_LRQ} to inspire LLM researchers\nand engineers.",
    "authors": [
      "Jung Hyun Lee",
      "Jeonghoon Kim",
      "June Yong Yang",
      "Se Jung Kwon",
      "Eunho Yang",
      "Kang Min Yoo",
      "Dongsoo Lee"
    ],
    "pdf_link": "http://arxiv.org/pdf/2407.11534v1",
    "category": [
      "LLMs",
      "Speech Recognition"
    ]
  },
  {
    "title": "Learning Global and Local Features of Power Load Series Through Transformer and 2D-CNN: An image-based Multi-step Forecasting Approach Incorporating Phase Space Reconstruction",
    "abstract": "As modern power systems continue to evolve, accurate power load forecasting\nremains a critical issue. The phase space reconstruction method can effectively\nretain the chaotic characteristics of power load from a system dynamics\nperspective and thus is a promising knowledge-based preprocessing method for\npower load forecasting. However, limited by its fundamental theory, there is\nstill a gap in implementing a multi-step forecasting scheme in current studies.\nTo bridge this gap, this study proposes a novel multi-step forecasting approach\nby integrating the PSR with neural networks. Firstly, the useful features in\nthe phase trajectory obtained from the preprocessing of PSR are discussed in\ndetail. Through mathematical derivation, the equivalent characterization of the\nPSR and another time series preprocessing method, patch segmentation, is\ndemonstrated for the first time. Based on this prior knowledge, an image-based\nmodeling perspective with the global and local feature extraction strategy is\nintroduced. Subsequently, a novel deep learning model, namely PSR-GALIEN, is\ndesigned for end-to-end processing, in which the Transformer Encoder and\n2D-convolutional neural networks are employed for the extraction of the global\nand local patterns in the image, and a multi-layer perception based predictor\nis used for the efficient correlation modeling. Then, extensive experiments are\nconducted on five real-world benchmark datasets to verify the effectiveness as\nwell as to have an insight into the detailed properties. The results show that,\ncomparing it with six state-of-the-art deep learning models, the forecasting\nperformance of PSR-GALIEN consistently surpasses these baselines, which\nachieves superior accuracy in both intra-day and day-ahead forecasting\nscenarios. At the same time, a visualization-based method is proposed to\nexplain the attributions of the forecasting results.",
    "authors": [
      "Zihan Tang",
      "Tianyao Ji",
      "Wenhu Tang"
    ],
    "pdf_link": "http://arxiv.org/pdf/2407.11553v1",
    "category": [
      "Datasets",
      "Multimodal Learning"
    ]
  },
  {
    "title": "Improving Engagement and Efficacy of mHealth Micro-Interventions for Stress Coping: an In-The-Wild Study",
    "abstract": "Sustaining long-term user engagement with mobile health (mHealth)\ninterventions while preserving their high efficacy remains an ongoing challenge\nin real-world well-being applications. To address this issue, we introduce a\nnew algorithm, the Personalized, Context-Aware Recommender (PCAR), for\nintervention selection and evaluate its performance in a field experiment. In a\nfour-week, in-the-wild experiment involving 29 parents of young children, we\ndelivered personalized stress-reducing micro-interventions through a mobile\nchatbot. We assessed their impact on stress reduction using momentary stress\nlevel ecological momentary assessments (EMAs) before and after each\nintervention. Our findings demonstrate the superiority of PCAR intervention\nselection in enhancing the engagement and efficacy of mHealth\nmicro-interventions to stress coping compared to random intervention selection\nand a control group that did not receive any intervention. Furthermore, we show\nthat even brief, one-minute interventions can significantly reduce perceived\nstress levels (p=0.001). We observe that individuals are most receptive to\none-minute interventions during transitional periods between activities, such\nas transitioning from afternoon activities to bedtime routines. Our study\ncontributes to the literature by introducing a personalized context-aware\nintervention selection algorithm that improves engagement and efficacy of\nmHealth interventions, identifying key timing for stress interventions, and\noffering insights into mechanisms to improve stress coping.",
    "authors": [
      "Chaya Ben Yehuda",
      "Ran Gilad-Bachrach",
      "Yarin Udi"
    ],
    "pdf_link": "http://arxiv.org/pdf/2407.11612v1",
    "category": [
      "AI in Healthcare",
      "Datasets"
    ]
  },
  {
    "title": "Graph Dimension Attention Networks for Enterprise Credit Assessment",
    "abstract": "Enterprise credit assessment is critical for evaluating financial risk, and\nGraph Neural Networks (GNNs), with their advanced capability to model\ninter-entity relationships, are a natural tool to get a deeper understanding of\nthese financial networks. However, existing GNN-based methodologies\npredominantly emphasize entity-level attention mechanisms for contagion risk\naggregation, often overlooking the heterogeneous importance of different\nfeature dimensions, thus falling short in adequately modeling credit risk\nlevels. To address this issue, we propose a novel architecture named Graph\nDimension Attention Network (GDAN), which incorporates a dimension-level\nattention mechanism to capture fine-grained risk-related characteristics.\nFurthermore, we explore the interpretability of the GNN-based method in\nfinancial scenarios and propose a simple but effective data-centric explainer\nfor GDAN, called GDAN-DistShift. DistShift provides edge-level interpretability\nby quantifying distribution shifts during the message-passing process.\nMoreover, we collected a real-world, multi-source Enterprise Credit Assessment\nDataset (ECAD) and have made it accessible to the research community since\nhigh-quality datasets are lacking in this field. Extensive experiments\nconducted on ECAD demonstrate the effectiveness of our methods. In addition, we\nran GDAN on the well-known datasets SMEsD and DBLP, also with excellent\nresults.",
    "authors": [
      "Shaopeng Wei",
      "Beni Egressy",
      "Xingyan Chen",
      "Yu Zhao",
      "Fuzhen Zhuang",
      "Roger Wattenhofer",
      "Gang Kou"
    ],
    "pdf_link": "http://arxiv.org/pdf/2407.11615v1",
    "category": [
      "Explainable AI",
      "Datasets"
    ]
  },
  {
    "title": "SKADA-Bench: Benchmarking Unsupervised Domain Adaptation Methods with Realistic Validation",
    "abstract": "Unsupervised Domain Adaptation (DA) consists of adapting a model trained on a\nlabeled source domain to perform well on an unlabeled target domain with some\ndata distribution shift. While many methods have been proposed in the\nliterature, fair and realistic evaluation remains an open question,\nparticularly due to methodological difficulties in selecting hyperparameters in\nthe unsupervised setting. With SKADA-Bench, we propose a framework to evaluate\nDA methods and present a fair evaluation of existing shallow algorithms,\nincluding reweighting, mapping, and subspace alignment. Realistic\nhyperparameter selection is performed with nested cross-validation and various\nunsupervised model selection scores, on both simulated datasets with controlled\nshifts and real-world datasets across diverse modalities, such as images, text,\nbiomedical, and tabular data with specific feature extraction. Our benchmark\nhighlights the importance of realistic validation and provides practical\nguidance for real-life applications, with key insights into the choice and\nimpact of model selection approaches. SKADA-Bench is open-source, reproducible,\nand can be easily extended with novel DA methods, datasets, and model selection\ncriteria without requiring re-evaluating competitors. SKADA-Bench is available\non GitHub at https://github.com/scikit-adaptation/skada-bench.",
    "authors": [
      "Yanis Lalou",
      "Th\u00e9o Gnassounou",
      "Antoine Collas",
      "Antoine de Mathelin",
      "Oleksii Kachaiev",
      "Ambroise Odonnat",
      "Alexandre Gramfort",
      "Thomas Moreau",
      "R\u00e9mi Flamary"
    ],
    "pdf_link": "http://arxiv.org/pdf/2407.11676v1",
    "category": [
      "Datasets",
      "Multimodal Learning"
    ]
  },
  {
    "title": "Universal Sound Separation with Self-Supervised Audio Masked Autoencoder",
    "abstract": "Universal sound separation (USS) is a task of separating mixtures of\narbitrary sound sources. Typically, universal separation models are trained\nfrom scratch in a supervised manner, using labeled data. Self-supervised\nlearning (SSL) is an emerging deep learning approach that leverages unlabeled\ndata to obtain task-agnostic representations, which can benefit many downstream\ntasks. In this paper, we propose integrating a self-supervised pre-trained\nmodel, namely the audio masked autoencoder (A-MAE), into a universal sound\nseparation system to enhance its separation performance. We employ two\nstrategies to utilize SSL embeddings: freezing or updating the parameters of\nA-MAE during fine-tuning. The SSL embeddings are concatenated with the\nshort-time Fourier transform (STFT) to serve as input features for the\nseparation model. We evaluate our methods on the AudioSet dataset, and the\nexperimental results indicate that the proposed methods successfully enhance\nthe separation performance of a state-of-the-art ResUNet-based USS model.",
    "authors": [
      "Junqi Zhao",
      "Xubo Liu",
      "Jinzheng Zhao",
      "Yi Yuan",
      "Qiuqiang Kong",
      "Mark D. Plumbley",
      "Wenwu Wang"
    ],
    "pdf_link": "http://arxiv.org/pdf/2407.11745v1",
    "category": [
      "Speech Recognition",
      "Multimodal Learning"
    ]
  },
  {
    "title": "Characterizing and Understanding HGNN Training on GPUs",
    "abstract": "Owing to their remarkable representation capabilities for heterogeneous graph\ndata, Heterogeneous Graph Neural Networks (HGNNs) have been widely adopted in\nmany critical real-world domains such as recommendation systems and medical\nanalysis. Prior to their practical application, identifying the optimal HGNN\nmodel parameters tailored to specific tasks through extensive training is a\ntime-consuming and costly process. To enhance the efficiency of HGNN training,\nit is essential to characterize and analyze the execution semantics and\npatterns within the training process to identify performance bottlenecks. In\nthis study, we conduct an in-depth quantification and analysis of two\nmainstream HGNN training scenarios, including single-GPU and multi-GPU\ndistributed training. Based on the characterization results, we disclose the\nperformance bottlenecks and their underlying causes in different HGNN training\nscenarios and provide optimization guidelines from both software and hardware\nperspectives.",
    "authors": [
      "Dengke Han",
      "Mingyu Yan",
      "Xiaochun Ye",
      "Dongrui Fan",
      "Ninghui Sun"
    ],
    "pdf_link": "http://arxiv.org/pdf/2407.11790v1",
    "category": [
      "LLMs",
      "Explainable AI"
    ]
  },
  {
    "title": "Approximating Probabilistic Inference in Statistical EL with Knowledge Graph Embeddings",
    "abstract": "Statistical information is ubiquitous but drawing valid conclusions from it\nis prohibitively hard. We explain how knowledge graph embeddings can be used to\napproximate probabilistic inference efficiently using the example of\nStatistical EL (SEL), a statistical extension of the lightweight Description\nLogic EL. We provide proofs for runtime and soundness guarantees, and\nempirically evaluate the runtime and approximation quality of our approach.",
    "authors": [
      "Yuqicheng Zhu",
      "Nico Potyka",
      "Bo Xiong",
      "Trung-Kien Tran",
      "Mojtaba Nayyeri",
      "Evgeny Kharlamov",
      "Steffen Staab"
    ],
    "pdf_link": "http://arxiv.org/pdf/2407.11821v1",
    "category": [
      "LLMs",
      "Multimodal Learning"
    ]
  },
  {
    "title": "The Future of Data Science Education",
    "abstract": "The definition of Data Science is a hotly debated topic. For many, the\ndefinition is a simple shortcut to Artificial Intelligence or Machine Learning.\nHowever, there is far more depth and nuance to the field of Data Science than a\nsimple shortcut can provide. The School of Data Science at the University of\nVirginia has developed a novel model for the definition of Data Science. This\nmodel is based on identifying a unified understanding of the data work done\nacross all areas of Data Science. It represents a generational leap forward in\nhow we understand and teach Data Science. In this paper we will present the\ncore features of the model and explain how it unifies various concepts going\nfar beyond the analytics component of AI. From this foundation we will present\nour Undergraduate Major curriculum in Data Science and demonstrate how it\nprepares students to be well-rounded Data Science team members and leaders. The\npaper will conclude with an in-depth overview of the Foundations of Data\nScience course designed to introduce students to the field while also\nimplementing proven STEM oriented pedagogical methods. These include, for\nexample, specifications grading, active learning lectures, guest lectures from\nindustry experts and weekly gamification labs.",
    "authors": [
      "Brian Wright",
      "Peter Alonzi",
      "Ali Riveria"
    ],
    "pdf_link": "http://arxiv.org/pdf/2407.11824v1",
    "category": [
      "Datasets",
      "Explainable AI"
    ]
  },
  {
    "title": "Variational Randomized Smoothing for Sample-Wise Adversarial Robustness",
    "abstract": "Randomized smoothing is a defensive technique to achieve enhanced robustness\nagainst adversarial examples which are small input perturbations that degrade\nthe performance of neural network models. Conventional randomized smoothing\nadds random noise with a fixed noise level for every input sample to smooth out\nadversarial perturbations. This paper proposes a new variational framework that\nuses a per-sample noise level suitable for each input by introducing a noise\nlevel selector. Our experimental results demonstrate enhancement of empirical\nrobustness against adversarial attacks. We also provide and analyze the\ncertified robustness for our sample-wise smoothing method.",
    "authors": [
      "Ryo Hase",
      "Ye Wang",
      "Toshiaki Koike-Akino",
      "Jing Liu",
      "Kieran Parsons"
    ],
    "pdf_link": "http://arxiv.org/pdf/2407.11844v1",
    "category": [
      "Explainable AI",
      "Reinforcement Learning"
    ]
  },
  {
    "title": "Schema Matching with Large Language Models: an Experimental Study",
    "abstract": "Large Language Models (LLMs) have shown useful applications in a variety of\ntasks, including data wrangling. In this paper, we investigate the use of an\noff-the-shelf LLM for schema matching. Our objective is to identify semantic\ncorrespondences between elements of two relational schemas using only names and\ndescriptions. Using a newly created benchmark from the health domain, we\npropose different so-called task scopes. These are methods for prompting the\nLLM to do schema matching, which vary in the amount of context information\ncontained in the prompt. Using these task scopes we compare LLM-based schema\nmatching against a string similarity baseline, investigating matching quality,\nverification effort, decisiveness, and complementarity of the approaches. We\nfind that matching quality suffers from a lack of context information, but also\nfrom providing too much context information. In general, using newer LLM\nversions increases decisiveness. We identify task scopes that have acceptable\nverification effort and succeed in identifying a significant number of true\nsemantic matches. Our study shows that LLMs have potential in bootstrapping the\nschema matching process and are able to assist data engineers in speeding up\nthis task solely based on schema element names and descriptions without the\nneed for data instances.",
    "authors": [
      "Marcel Parciak",
      "Brecht Vandevoort",
      "Frank Neven",
      "Liesbet M. Peeters",
      "Stijn Vansummeren"
    ],
    "pdf_link": "http://arxiv.org/pdf/2407.11852v1",
    "category": [
      "LLMs",
      "Datasets"
    ]
  },
  {
    "title": "Tackling Oversmoothing in GNN via Graph Sparsification: A Truss-based Approach",
    "abstract": "Graph Neural Network (GNN) achieves great success for node-level and\ngraph-level tasks via encoding meaningful topological structures of networks in\nvarious domains, ranging from social to biological networks. However, repeated\naggregation operations lead to excessive mixing of node representations,\nparticularly in dense regions with multiple GNN layers, resulting in nearly\nindistinguishable embeddings. This phenomenon leads to the oversmoothing\nproblem that hampers downstream graph analytics tasks. To overcome this issue,\nwe propose a novel and flexible truss-based graph sparsification model that\nprunes edges from dense regions of the graph. Pruning redundant edges in dense\nregions helps to prevent the aggregation of excessive neighborhood information\nduring hierarchical message passing and pooling in GNN models. We then utilize\nour sparsification model in the state-of-the-art baseline GNNs and pooling\nmodels, such as GIN, SAGPool, GMT, DiffPool, MinCutPool, HGP-SL, DMonPool, and\nAdamGNN. Extensive experiments on different real-world datasets show that our\nmodel significantly improves the performance of the baseline GNN models in the\ngraph classification task.",
    "authors": [
      "Tanvir Hossain",
      "Khaled Mohammed Saifuddin",
      "Muhammad Ifte Khairul Islam",
      "Farhan Tanvir",
      "Esra Akbas"
    ],
    "pdf_link": "http://arxiv.org/pdf/2407.11928v1",
    "category": [
      "LLMs",
      "Datasets"
    ]
  }
]