[
  {
    "title": "The Data Addition Dilemma",
    "abstract": "In many machine learning for healthcare tasks, standard datasets are\nconstructed by amassing data across many, often fundamentally dissimilar,\nsources. But when does adding more data help, and when does it hinder progress\non desired model outcomes in real-world settings? We identify this situation as\nthe \\textit{Data Addition Dilemma}, demonstrating that adding training data in\nthis multi-source scaling context can at times result in reduced overall\naccuracy, uncertain fairness outcomes, and reduced worst-subgroup performance.\nWe find that this possibly arises from an empirically observed trade-off\nbetween model performance improvements due to data scaling and model\ndeterioration from distribution shift. We thus establish baseline strategies\nfor navigating this dilemma, introducing distribution shift heuristics to guide\ndecision-making on which data sources to add in data scaling, in order to yield\nthe expected model performance improvements. We conclude with a discussion of\nthe required considerations for data collection and suggestions for studying\ndata composition and scale in the age of increasingly larger models.",
    "authors": [
      "Judy Hanwen Shen",
      "Inioluwa Deborah Raji",
      "Irene Y. Chen"
    ],
    "pdf_link": "http://arxiv.org/pdf/2408.04154v1",
    "category": [
      "Datasets",
      "AI in Healthcare"
    ]
  },
  {
    "title": "Perceive, Reflect, and Plan: Designing LLM Agent for Goal-Directed City Navigation without Instructions",
    "abstract": "This paper considers a scenario in city navigation: an AI agent is provided\nwith language descriptions of the goal location with respect to some well-known\nlandmarks; By only observing the scene around, including recognizing landmarks\nand road network connections, the agent has to make decisions to navigate to\nthe goal location without instructions. This problem is very challenging,\nbecause it requires agent to establish self-position and acquire spatial\nrepresentation of complex urban environment, where landmarks are often\ninvisible. In the absence of navigation instructions, such abilities are vital\nfor the agent to make high-quality decisions in long-range city navigation.\nWith the emergent reasoning ability of large language models (LLMs), a tempting\nbaseline is to prompt LLMs to \"react\" on each observation and make decisions\naccordingly. However, this baseline has very poor performance that the agent\noften repeatedly visits same locations and make short-sighted, inconsistent\ndecisions. To address these issues, this paper introduces a novel agentic\nworkflow featured by its abilities to perceive, reflect and plan. Specifically,\nwe find LLaVA-7B can be fine-tuned to perceive the direction and distance of\nlandmarks with sufficient accuracy for city navigation. Moreover, reflection is\nachieved through a memory mechanism, where past experiences are stored and can\nbe retrieved with current perception for effective decision argumentation.\nPlanning uses reflection results to produce long-term plans, which can avoid\nshort-sighted decisions in long-range navigation. We show the designed workflow\nsignificantly improves navigation ability of the LLM agent compared with the\nstate-of-the-art baselines.",
    "authors": [
      "Qingbin Zeng",
      "Qinglong Yang",
      "Shunan Dong",
      "Heming Du",
      "Liang Zheng",
      "Fengli Xu",
      "Yong Li"
    ],
    "pdf_link": "http://arxiv.org/pdf/2408.04168v1",
    "category": [
      "Explainable AI",
      "Reinforcement Learning"
    ]
  },
  {
    "title": "Listwise Reward Estimation for Offline Preference-based Reinforcement Learning",
    "abstract": "In Reinforcement Learning (RL), designing precise reward functions remains to\nbe a challenge, particularly when aligning with human intent. Preference-based\nRL (PbRL) was introduced to address this problem by learning reward models from\nhuman feedback. However, existing PbRL methods have limitations as they often\noverlook the second-order preference that indicates the relative strength of\npreference. In this paper, we propose Listwise Reward Estimation (LiRE), a\nnovel approach for offline PbRL that leverages second-order preference\ninformation by constructing a Ranked List of Trajectories (RLT), which can be\nefficiently built by using the same ternary feedback type as traditional\nmethods. To validate the effectiveness of LiRE, we propose a new offline PbRL\ndataset that objectively reflects the effect of the estimated rewards. Our\nextensive experiments on the dataset demonstrate the superiority of LiRE, i.e.,\noutperforming state-of-the-art baselines even with modest feedback budgets and\nenjoying robustness with respect to the number of feedbacks and feedback noise.\nOur code is available at https://github.com/chwoong/LiRE",
    "authors": [
      "Heewoong Choi",
      "Sangwon Jung",
      "Hongjoon Ahn",
      "Taesup Moon"
    ],
    "pdf_link": "http://arxiv.org/pdf/2408.04190v1",
    "category": [
      "Reinforcement Learning",
      "Explainable AI"
    ]
  },
  {
    "title": "Uncertainty-Aware Crime Prediction With Spatial Temporal Multivariate Graph Neural Networks",
    "abstract": "Crime forecasting is a critical component of urban analysis and essential for\nstabilizing society today. Unlike other time series forecasting problems, crime\nincidents are sparse, particularly in small regions and within specific time\nperiods. Traditional spatial-temporal deep learning models often struggle with\nthis sparsity, as they typically cannot effectively handle the non-Gaussian\nnature of crime data, which is characterized by numerous zeros and\nover-dispersed patterns. To address these challenges, we introduce a novel\napproach termed Spatial Temporal Multivariate Zero-Inflated Negative Binomial\nGraph Neural Networks (STMGNN-ZINB). This framework leverages diffusion and\nconvolution networks to analyze spatial, temporal, and multivariate\ncorrelations, enabling the parameterization of probabilistic distributions of\ncrime incidents. By incorporating a Zero-Inflated Negative Binomial model,\nSTMGNN-ZINB effectively manages the sparse nature of crime data, enhancing\nprediction accuracy and the precision of confidence intervals. Our evaluation\non real-world datasets confirms that STMGNN-ZINB outperforms existing models,\nproviding a more reliable tool for predicting and understanding crime dynamics.",
    "authors": [
      "Zepu Wang",
      "Xiaobo Ma",
      "Huajie Yang",
      "Weimin Lvu",
      "Peng Sun",
      "Sharath Chandra Guntuku"
    ],
    "pdf_link": "http://arxiv.org/pdf/2408.04193v1",
    "category": [
      "Datasets",
      "Explainable AI"
    ]
  },
  {
    "title": "Pairwise Judgment Formulation for Semantic Embedding Model in Web Search",
    "abstract": "Semantic Embedding Model (SEM), a neural network-based Siamese architecture,\nis gaining momentum in information retrieval and natural language processing.\nIn order to train SEM in a supervised fashion for Web search, the search engine\nquery log is typically utilized to automatically formulate pairwise judgments\nas training data. Despite the growing application of semantic embeddings in the\nsearch engine industry, little work has been done on formulating effective\npairwise judgments for training SEM. In this paper, we make the first in-depth\ninvestigation of a wide range of strategies for generating pairwise judgments\nfor SEM. An interesting (perhaps surprising) discovery reveals that the\nconventional pairwise judgment formulation strategy wildly used in the field of\npairwise Learning-to-Rank (LTR) is not necessarily effective for training SEM.\nThrough a large-scale empirical study based on query logs and click-through\nactivities from a major commercial search engine, we demonstrate the effective\nstrategies for SEM and highlight the advantages of a hybrid heuristic (i.e.,\nClicked > Non-Clicked) in comparison to the atomic heuristics (e.g., Clicked >\nSkipped) in LTR. We conclude with best practices for training SEM and offer\npromising insights for future research.",
    "authors": [
      "Mengze Hong",
      "Chen Jason Zhang"
    ],
    "pdf_link": "http://arxiv.org/pdf/2408.04197v1",
    "category": [
      "LLMs",
      "Multimodal Learning"
    ]
  },
  {
    "title": "MMRole: A Comprehensive Framework for Developing and Evaluating Multimodal Role-Playing Agents",
    "abstract": "Recently, Role-Playing Agents (RPAs) have garnered increasing attention for\ntheir potential to deliver emotional value and facilitate sociological\nresearch. However, existing studies are primarily confined to the textual\nmodality, unable to simulate humans' multimodal perceptual capabilities. To\nbridge this gap, we introduce the concept of Multimodal Role-Playing Agents\n(MRPAs), and propose a comprehensive framework, MMRole, for their development\nand evaluation, which comprises a personalized multimodal dataset and a robust\nevaluation method. Specifically, we construct a large-scale, high-quality\ndataset, MMRole-Data, consisting of 85 characters, 11K images, and 14K single\nor multi-turn dialogues. Additionally, we present a robust evaluation method,\nMMRole-Eval, encompassing eight metrics across three dimensions, where a reward\nmodel is trained to score MRPAs with the constructed ground-truth data for\ncomparison. Moreover, we develop the first specialized MRPA, MMRole-Agent.\nExtensive evaluation results demonstrate the improved performance of\nMMRole-Agent and highlight the primary challenges in developing MRPAs,\nemphasizing the need for enhanced multimodal understanding and role-playing\nconsistency. The data, code, and models will be available at\nhttps://github.com/YanqiDai/MMRole.",
    "authors": [
      "Yanqi Dai",
      "Huanran Hu",
      "Lei Wang",
      "Shengjie Jin",
      "Xu Chen",
      "Zhiwu Lu"
    ],
    "pdf_link": "http://arxiv.org/pdf/2408.04203v1",
    "category": [
      "Multimodal Learning",
      "Speech Synthesis"
    ]
  },
  {
    "title": "AI-Driven Chatbot for Intrusion Detection in Edge Networks: Enhancing Cybersecurity with Ethical User Consent",
    "abstract": "In today's contemporary digital landscape, chatbots have become indispensable\ntools across various sectors, streamlining customer service, providing personal\nassistance, automating routine tasks, and offering health advice. However,\ntheir potential remains underexplored in the realm of network security,\nparticularly for intrusion detection. To bridge this gap, we propose an\narchitecture chatbot specifically designed to enhance security within edge\nnetworks specifically for intrusion detection. Leveraging advanced machine\nlearning algorithms, this chatbot will monitor network traffic to identify and\nmitigate potential intrusions. By securing the network environment using an\nedge network managed by a Raspberry Pi module and ensuring ethical user consent\npromoting transparency and trust, this innovative solution aims to safeguard\nsensitive data and maintain a secure workplace, thereby addressing the growing\nneed for robust network security measures in the digital age.",
    "authors": [
      "Mugheez Asif",
      "Abdul Manan",
      "Abdul Moiz ur Rehman",
      "Mamoona Naveed Asghar",
      "Muhammad Umair"
    ],
    "pdf_link": "http://arxiv.org/pdf/2408.04281v1",
    "category": [
      "AI in Healthcare",
      "Explainable AI"
    ]
  },
  {
    "title": "Tackling Noisy Clients in Federated Learning with End-to-end Label Correction",
    "abstract": "Recently, federated learning (FL) has achieved wide successes for diverse\nprivacy-sensitive applications without sacrificing the sensitive private\ninformation of clients. However, the data quality of client datasets can not be\nguaranteed since corresponding annotations of different clients often contain\ncomplex label noise of varying degrees, which inevitably causes the performance\ndegradation. Intuitively, the performance degradation is dominated by clients\nwith higher noise rates since their trained models contain more misinformation\nfrom data, thus it is necessary to devise an effective optimization scheme to\nmitigate the negative impacts of these noisy clients. In this work, we propose\na two-stage framework FedELC to tackle this complicated label noise issue. The\nfirst stage aims to guide the detection of noisy clients with higher label\nnoise, while the second stage aims to correct the labels of noisy clients' data\nvia an end-to-end label correction framework which is achieved by learning\npossible ground-truth labels of noisy clients' datasets via back propagation.\nWe implement sixteen related methods and evaluate five datasets with three\ntypes of complicated label noise scenarios for a comprehensive comparison.\nExtensive experimental results demonstrate our proposed framework achieves\nsuperior performance than its counterparts for different scenarios.\nAdditionally, we effectively improve the data quality of detected noisy\nclients' local datasets with our label correction framework. The code is\navailable at https://github.com/Sprinter1999/FedELC.",
    "authors": [
      "Xuefeng Jiang",
      "Sheng Sun",
      "Jia Li",
      "Jingjing Xue",
      "Runhan Li",
      "Zhiyuan Wu",
      "Gang Xu",
      "Yuwei Wang",
      "Min Liu"
    ],
    "pdf_link": "http://arxiv.org/pdf/2408.04301v1",
    "category": [
      "Datasets",
      "Explainable AI"
    ]
  },
  {
    "title": "Learning with Digital Agents: An Analysis based on the Activity Theory",
    "abstract": "Digital agents are considered a general-purpose technology. They spread\nquickly in private and organizational contexts, including education. Yet,\nresearch lacks a conceptual framing to describe interaction with such agents in\na holistic manner. While focusing on the interaction with a pedagogical agent,\ni.e., a digital agent capable of natural-language interaction with a learner,\nwe propose a model of learning activity based on activity theory. We use this\nmodel and a review of prior research on digital agents in education to analyze\nhow various characteristics of the activity, including features of a\npedagogical agent or learner, influence learning outcomes. The analysis leads\nto identification of IS research directions and guidance for developers of\npedagogical agents and digital agents in general. We conclude by extending the\nactivity theory-based model beyond the context of education and show how it\nhelps designers and researchers ask the right questions when creating a digital\nagent.",
    "authors": [
      "Mateusz Dolata",
      "Dzmitry Katsiuba",
      "Natalie Wellnhammer",
      "Gerhard Schwabe"
    ],
    "pdf_link": "http://arxiv.org/pdf/2408.04304v1",
    "category": [
      "Explainable AI",
      "Reinforcement Learning"
    ]
  },
  {
    "title": "KnowPC: Knowledge-Driven Programmatic Reinforcement Learning for Zero-shot Coordination",
    "abstract": "Zero-shot coordination (ZSC) remains a major challenge in the cooperative AI\nfield, which aims to learn an agent to cooperate with an unseen partner in\ntraining environments or even novel environments. In recent years, a popular\nZSC solution paradigm has been deep reinforcement learning (DRL) combined with\nadvanced self-play or population-based methods to enhance the neural policy's\nability to handle unseen partners. Despite some success, these approaches\nusually rely on black-box neural networks as the policy function. However,\nneural networks typically lack interpretability and logic, making the learned\npolicies difficult for partners (e.g., humans) to understand and limiting their\ngeneralization ability. These shortcomings hinder the application of\nreinforcement learning methods in diverse cooperative scenarios.We suggest to\nrepresent the agent's policy with an interpretable program. Unlike neural\nnetworks, programs contain stable logic, but they are non-differentiable and\ndifficult to optimize.To automatically learn such programs, we introduce\nKnowledge-driven Programmatic reinforcement learning for zero-shot Coordination\n(KnowPC). We first define a foundational Domain-Specific Language (DSL),\nincluding program structures, conditional primitives, and action primitives. A\nsignificant challenge is the vast program search space, making it difficult to\nfind high-performing programs efficiently. To address this, KnowPC integrates\nan extractor and an reasoner. The extractor discovers environmental transition\nknowledge from multi-agent interaction trajectories, while the reasoner deduces\nthe preconditions of each action primitive based on the transition knowledge.",
    "authors": [
      "Yin Gu",
      "Qi Liu",
      "Zhi Li",
      "Kai Zhang"
    ],
    "pdf_link": "http://arxiv.org/pdf/2408.04336v1",
    "category": [
      "Reinforcement Learning",
      "Explainable AI"
    ]
  },
  {
    "title": "Optimal Layout-Aware CNOT Circuit Synthesis with Qubit Permutation",
    "abstract": "CNOT optimization plays a significant role in noise reduction for Quantum\nCircuits. Several heuristic and exact approaches exist for CNOT optimization.\nIn this paper, we investigate more complicated variations of optimal synthesis\nby allowing qubit permutations and handling layout restrictions. We encode such\nproblems into Planning, SAT, and QBF. We provide optimization for both CNOT\ngate count and circuit depth. For experimental evaluation, we consider standard\nT-gate optimized benchmarks and optimize CNOT sub-circuits. We show that\nallowing qubit permutations can further reduce up to 56% in CNOT count and 46%\nin circuit depth. In the case of optimally mapped circuits under layout\nrestrictions, we observe a reduction up to 17% CNOT count and 19% CNOT depth.",
    "authors": [
      "Irfansha Shaik",
      "Jaco van de Pol"
    ],
    "pdf_link": "http://arxiv.org/pdf/2408.04349v1",
    "category": [
      "Speech Synthesis",
      "Explainable AI"
    ]
  },
  {
    "title": "Anomaly Prediction: A Novel Approach with Explicit Delay and Horizon",
    "abstract": "Detecting anomalies in time series data is a critical challenge across\nvarious domains. Traditional methods typically focus on identifying anomalies\nin immediate subsequent steps, often underestimating the significance of\ntemporal dynamics such as delay time and horizons of anomalies, which generally\nrequire extensive post-analysis. This paper introduces a novel approach for\ntime series anomaly prediction, incorporating temporal information directly\ninto the prediction results. We propose a new dataset specifically designed to\nevaluate this approach and conduct comprehensive experiments using several\nstate-of-the-art methods. results demonstrate the efficacy of our approach in\nproviding timely and accurate anomaly predictions, setting a new benchmark for\nfuture research in this field.",
    "authors": [
      "Jiang You",
      "Arben Cela",
      "Ren\u00e9 Natowicz",
      "Jacob Ouanounou",
      "Patrick Siarry"
    ],
    "pdf_link": "http://arxiv.org/pdf/2408.04377v1",
    "category": [
      "Datasets",
      "Explainable AI"
    ]
  },
  {
    "title": "Judgment2vec: Apply Graph Analytics to Searching and Recommendation of Similar Judgments",
    "abstract": "In court practice, legal professionals rely on their training to provide\nopinions that resolve cases, one of the most crucial aspects being the ability\nto identify similar judgments from previous courts efficiently. However,\nfinding a similar case is challenging and often depends on experience, legal\ndomain knowledge, and extensive labor hours, making veteran lawyers or judges\nindispensable. This research aims to automate the analysis of judgment text\nsimilarity. We utilized a judgment dataset labeled as the \"golden standard\" by\nexperts, which includes human-verified features that can be converted into an\n\"expert similarity score.\" We then constructed a knowledge graph based on\n\"case-article\" relationships, ranking each case using natural language\nprocessing to derive a \"Node2vec similarity score.\" By evaluating these two\nsimilarity scores, we identified their discrepancies and relationships. The\nresults can significantly reduce the labor hours required for legal searches\nand recommendations, with potential applications extending to various fields of\ninformation retrieval.",
    "authors": [
      "Hsuan-Lei Shao"
    ],
    "pdf_link": "http://arxiv.org/pdf/2408.04382v1",
    "category": [
      "Datasets",
      "AI in Healthcare"
    ]
  },
  {
    "title": "Non-maximizing policies that fulfill multi-criterion aspirations in expectation",
    "abstract": "In dynamic programming and reinforcement learning, the policy for the\nsequential decision making of an agent in a stochastic environment is usually\ndetermined by expressing the goal as a scalar reward function and seeking a\npolicy that maximizes the expected total reward. However, many goals that\nhumans care about naturally concern multiple aspects of the world, and it may\nnot be obvious how to condense those into a single reward function.\nFurthermore, maximization suffers from specification gaming, where the obtained\npolicy achieves a high expected total reward in an unintended way, often taking\nextreme or nonsensical actions.\n  Here we consider finite acyclic Markov Decision Processes with multiple\ndistinct evaluation metrics, which do not necessarily represent quantities that\nthe user wants to be maximized. We assume the task of the agent is to ensure\nthat the vector of expected totals of the evaluation metrics falls into some\ngiven convex set, called the aspiration set. Our algorithm guarantees that this\ntask is fulfilled by using simplices to approximate feasibility sets and\npropagate aspirations forward while ensuring they remain feasible. It has\ncomplexity linear in the number of possible state-action-successor triples and\npolynomial in the number of evaluation metrics. Moreover, the explicitly\nnon-maximizing nature of the chosen policy and goals yields additional degrees\nof freedom, which can be used to apply heuristic safety criteria to the choice\nof actions. We discuss several such safety criteria that aim to steer the agent\ntowards more conservative behavior.",
    "authors": [
      "Simon Dima",
      "Simon Fischer",
      "Jobst Heitzig",
      "Joss Oliver"
    ],
    "pdf_link": "http://arxiv.org/pdf/2408.04385v1",
    "category": [
      "Reinforcement Learning",
      "Explainable AI"
    ]
  },
  {
    "title": "MM-Forecast: A Multimodal Approach to Temporal Event Forecasting with Large Language Models",
    "abstract": "We study an emerging and intriguing problem of multimodal temporal event\nforecasting with large language models. Compared to using text or graph\nmodalities, the investigation of utilizing images for temporal event\nforecasting has not been fully explored, especially in the era of large\nlanguage models (LLMs). To bridge this gap, we are particularly interested in\ntwo key questions of: 1) why images will help in temporal event forecasting,\nand 2) how to integrate images into the LLM-based forecasting framework. To\nanswer these research questions, we propose to identify two essential functions\nthat images play in the scenario of temporal event forecasting, i.e.,\nhighlighting and complementary. Then, we develop a novel framework, named\nMM-Forecast. It employs an Image Function Identification module to recognize\nthese functions as verbal descriptions using multimodal large language models\n(MLLMs), and subsequently incorporates these function descriptions into\nLLM-based forecasting models. To evaluate our approach, we construct a new\nmultimodal dataset, MidEast-TE-mm, by extending an existing event dataset\nMidEast-TE-mini with images. Empirical studies demonstrate that our MM-Forecast\ncan correctly identify the image functions, and further more, incorporating\nthese verbal function descriptions significantly improves the forecasting\nperformance. The dataset, code, and prompts are available at\nhttps://github.com/LuminosityX/MM-Forecast.",
    "authors": [
      "Haoxuan Li",
      "Zhengmao Yang",
      "Yunshan Ma",
      "Yi Bin",
      "Yang Yang",
      "Tat-Seng Chua"
    ],
    "pdf_link": "http://arxiv.org/pdf/2408.04388v1",
    "category": [
      "Multimodal Learning",
      "Speech Recognition"
    ]
  },
  {
    "title": "DIVE: Subgraph Disagreement for Graph Out-of-Distribution Generalization",
    "abstract": "This paper addresses the challenge of out-of-distribution (OOD)\ngeneralization in graph machine learning, a field rapidly advancing yet\ngrappling with the discrepancy between source and target data distributions.\nTraditional graph learning algorithms, based on the assumption of uniform\ndistribution between training and test data, falter in real-world scenarios\nwhere this assumption fails, resulting in suboptimal performance. A principal\nfactor contributing to this suboptimal performance is the inherent simplicity\nbias of neural networks trained through Stochastic Gradient Descent (SGD),\nwhich prefer simpler features over more complex yet equally or more predictive\nones. This bias leads to a reliance on spurious correlations, adversely\naffecting OOD performance in various tasks such as image recognition, natural\nlanguage understanding, and graph classification. Current methodologies,\nincluding subgraph-mixup and information bottleneck approaches, have achieved\npartial success but struggle to overcome simplicity bias, often reinforcing\nspurious correlations. To tackle this, we propose DIVE, training a collection\nof models to focus on all label-predictive subgraphs by encouraging the models\nto foster divergence on the subgraph mask, which circumvents the limitation of\na model solely focusing on the subgraph corresponding to simple structural\npatterns. Specifically, we employs a regularizer to punish overlap in extracted\nsubgraphs across models, thereby encouraging different models to concentrate on\ndistinct structural patterns. Model selection for robust OOD performance is\nachieved through validation accuracy. Tested across four datasets from GOOD\nbenchmark and one dataset from DrugOOD benchmark, our approach demonstrates\nsignificant improvement over existing methods, effectively addressing the\nsimplicity bias and enhancing generalization in graph machine learning.",
    "authors": [
      "Xin Sun",
      "Liang Wang",
      "Qiang Liu",
      "Shu Wu",
      "Zilei Wang",
      "Liang Wang"
    ],
    "pdf_link": "http://arxiv.org/pdf/2408.04400v1",
    "category": [
      "Datasets",
      "Multimodal Learning"
    ]
  },
  {
    "title": "Probabilistic energy forecasting through quantile regression in reproducing kernel Hilbert spaces",
    "abstract": "Accurate energy demand forecasting is crucial for sustainable and resilient\nenergy development. To meet the Net Zero Representative Concentration Pathways\n(RCP) $4.5$ scenario in the DACH countries, increased renewable energy\nproduction, energy storage, and reduced commercial building consumption are\nneeded. This scenario's success depends on hydroelectric capacity and climatic\nfactors. Informed decisions require quantifying uncertainty in forecasts. This\nstudy explores a non-parametric method based on \\emph{reproducing kernel\nHilbert spaces (RKHS)}, known as kernel quantile regression, for energy\nprediction. Our experiments demonstrate its reliability and sharpness, and we\nbenchmark it against state-of-the-art methods in load and price forecasting for\nthe DACH region. We offer our implementation in conjunction with additional\nscripts to ensure the reproducibility of our research.",
    "authors": [
      "Luca Pernigo",
      "Rohan Sen",
      "Davide Baroli"
    ],
    "pdf_link": "http://arxiv.org/pdf/2408.04405v1",
    "category": [
      "Reinforcement Learning",
      "Datasets"
    ]
  },
  {
    "title": "FedAD-Bench: A Unified Benchmark for Federated Unsupervised Anomaly Detection in Tabular Data",
    "abstract": "The emergence of federated learning (FL) presents a promising approach to\nleverage decentralized data while preserving privacy. Furthermore, the\ncombination of FL and anomaly detection is particularly compelling because it\nallows for detecting rare and critical anomalies (usually also rare in locally\ngathered data) in sensitive data from multiple sources, such as cybersecurity\nand healthcare. However, benchmarking the performance of anomaly detection\nmethods in FL environments remains an underexplored area. This paper introduces\nFedAD-Bench, a unified benchmark for evaluating unsupervised anomaly detection\nalgorithms within the context of FL. We systematically analyze and compare the\nperformance of recent deep learning anomaly detection models under federated\nsettings, which were typically assessed solely in centralized settings.\nFedAD-Bench encompasses diverse datasets and metrics to provide a holistic\nevaluation. Through extensive experiments, we identify key challenges such as\nmodel aggregation inefficiencies and metric unreliability. We present insights\ninto FL's regularization effects, revealing scenarios in which it outperforms\ncentralized approaches due to its inherent ability to mitigate overfitting. Our\nwork aims to establish a standardized benchmark to guide future research and\ndevelopment in federated anomaly detection, promoting reproducibility and fair\ncomparison across studies.",
    "authors": [
      "Ahmed Anwar",
      "Brian Moser",
      "Dayananda Herurkar",
      "Federico Raue",
      "Vinit Hegiste",
      "Tatjana Legler",
      "Andreas Dengel"
    ],
    "pdf_link": "http://arxiv.org/pdf/2408.04442v1",
    "category": [
      "Datasets",
      "Explainable AI"
    ]
  },
  {
    "title": "Reasoning about Study Regulations in Answer Set Programming",
    "abstract": "We are interested in automating reasoning with and about study regulations,\ncatering to various stakeholders, ranging from administrators, over faculty, to\nstudents at different stages. Our work builds on an extensive analysis of\nvarious study programs at the University of Potsdam. The conceptualization of\nthe underlying principles provides us with a formal account of study\nregulations. In particular, the formalization reveals the properties of\nadmissible study plans. With these at end, we propose an encoding of study\nregulations in Answer Set Programming that produces corresponding study plans.\nFinally, we show how this approach can be extended to a generic user interface\nfor exploring study plans.",
    "authors": [
      "Susana Hahn",
      "Cedric Martens",
      "Amade Nemes",
      "Henry Otunuya",
      "Javier Romero",
      "Torsten Schaub",
      "Sebastian Schellhorn"
    ],
    "pdf_link": "http://arxiv.org/pdf/2408.04528v1",
    "category": [
      "Explainable AI",
      "Datasets"
    ]
  },
  {
    "title": "Synchronous Multi-modal Semantic CommunicationSystem with Packet-level Coding",
    "abstract": "Although the semantic communication with joint semantic-channel coding design\nhas shown promising performance in transmitting data of different modalities\nover physical layer channels, the synchronization and packet-level forward\nerror correction of multimodal semantics have not been well studied. Due to the\nindependent design of semantic encoders, synchronizing multimodal features in\nboth the semantic and time domains is a challenging problem. In this paper, we\ntake the facial video and speech transmission as an example and propose a\nSynchronous Multimodal Semantic Communication System (SyncSC) with Packet-Level\nCoding. To achieve semantic and time synchronization, 3D Morphable Mode (3DMM)\ncoefficients and text are transmitted as semantics, and we propose a semantic\ncodec that achieves similar quality of reconstruction and synchronization with\nlower bandwidth, compared to traditional methods. To protect semantic packets\nunder the erasure channel, we propose a packet-Level Forward Error Correction\n(FEC) method, called PacSC, that maintains a certain visual quality performance\neven at high packet loss rates. Particularly, for text packets, a text packet\nloss concealment module, called TextPC, based on Bidirectional Encoder\nRepresentations from Transformers (BERT) is proposed, which significantly\nimproves the performance of traditional FEC methods. The simulation results\nshow that our proposed SyncSC reduce transmission overhead and achieve\nhigh-quality synchronous transmission of video and speech over the packet loss\nnetwork.",
    "authors": [
      "Yun Tian",
      "Jingkai Ying",
      "Zhijin Qin",
      "Ye Jin",
      "Xiaoming Tao"
    ],
    "pdf_link": "http://arxiv.org/pdf/2408.04535v1",
    "category": [
      "Multimodal Learning",
      "Speech Synthesis"
    ]
  },
  {
    "title": "Inference with the Upper Confidence Bound Algorithm",
    "abstract": "In this paper, we discuss the asymptotic behavior of the Upper Confidence\nBound (UCB) algorithm in the context of multiarmed bandit problems and discuss\nits implication in downstream inferential tasks. While inferential tasks become\nchallenging when data is collected in a sequential manner, we argue that this\nproblem can be alleviated when the sequential algorithm at hand satisfies\ncertain stability property. This notion of stability is motivated from the\nseminal work of Lai and Wei (1982). Our first main result shows that such a\nstability property is always satisfied for the UCB algorithm, and as a result\nthe sample means for each arm are asymptotically normal. Next, we examine the\nstability properties of the UCB algorithm when the number of arms $K$ is\nallowed to grow with the number of arm pulls $T$. We show that in such a case\nthe arms are stable when $\\frac{\\log K}{\\log T} \\rightarrow 0$, and the number\nof near-optimal arms are large.",
    "authors": [
      "Koulik Khamaru",
      "Cun-Hui Zhang"
    ],
    "pdf_link": "http://arxiv.org/pdf/2408.04595v1",
    "category": [
      "Reinforcement Learning",
      "Explainable AI"
    ]
  }
]