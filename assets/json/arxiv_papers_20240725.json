[
  {
    "title": "Cheems: Wonderful Matrices More Efficient and More Effective Architecture",
    "abstract": "Recent studies have shown that, relative position encoding performs well in\nselective state space model scanning algorithms, and the architecture that\nbalances SSM and Attention enhances the efficiency and effectiveness of the\nalgorithm, while the sparse activation of the mixture of experts reduces the\ntraining cost. I studied the effectiveness of using different position\nencodings in structured state space dual algorithms, and the more effective\nSSD-Attn internal and external function mixing method, and designed a more\nefficient cross domain mixture of experts. I found that the same matrix is very\nwonderful in different algorithms, which allows us to establish a new hybrid\nsparse architecture: Cheems. Compared with other hybrid architectures, it is\nmore efficient and more effective in language modeling tasks.",
    "authors": [
      "Jingze Shi",
      "Lu He",
      "Yuhan Wang",
      "Tianyu He",
      "Bingheng Wu",
      "Mingkun Hou"
    ],
    "pdf_link": "http://arxiv.org/pdf/2407.16958v2",
    "category": [
      "Speech Recognition",
      "Speech Synthesis"
    ]
  },
  {
    "title": "Stochastic Variance-Reduced Iterative Hard Thresholding in Graph Sparsity Optimization",
    "abstract": "Stochastic optimization algorithms are widely used for large-scale data\nanalysis due to their low per-iteration costs, but they often suffer from slow\nasymptotic convergence caused by inherent variance. Variance-reduced techniques\nhave been therefore used to address this issue in structured sparse models\nutilizing sparsity-inducing norms or $\\ell_0$-norms. However, these techniques\nare not directly applicable to complex (non-convex) graph sparsity models,\nwhich are essential in applications like disease outbreak monitoring and social\nnetwork analysis. In this paper, we introduce two stochastic variance-reduced\ngradient-based methods to solve graph sparsity optimization: GraphSVRG-IHT and\nGraphSCSG-IHT. We provide a general framework for theoretical analysis,\ndemonstrating that our methods enjoy a linear convergence speed. Extensive\nexperiments validate",
    "authors": [
      "Derek Fox",
      "Samuel Hernandez",
      "Qianqian Tong"
    ],
    "pdf_link": "http://arxiv.org/pdf/2407.16968v1",
    "category": [
      "Datasets",
      "LLMs"
    ]
  },
  {
    "title": "SepsisLab: Early Sepsis Prediction with Uncertainty Quantification and Active Sensing",
    "abstract": "Sepsis is the leading cause of in-hospital mortality in the USA. Early sepsis\nonset prediction and diagnosis could significantly improve the survival of\nsepsis patients. Existing predictive models are usually trained on high-quality\ndata with few missing information, while missing values widely exist in\nreal-world clinical scenarios (especially in the first hours of admissions to\nthe hospital), which causes a significant decrease in accuracy and an increase\nin uncertainty for the predictive models. The common method to handle missing\nvalues is imputation, which replaces the unavailable variables with estimates\nfrom the observed data. The uncertainty of imputation results can be propagated\nto the sepsis prediction outputs, which have not been studied in existing works\non either sepsis prediction or uncertainty quantification. In this study, we\nfirst define such propagated uncertainty as the variance of prediction output\nand then introduce uncertainty propagation methods to quantify the propagated\nuncertainty. Moreover, for the potential high-risk patients with low confidence\ndue to limited observations, we propose a robust active sensing algorithm to\nincrease confidence by actively recommending clinicians to observe the most\ninformative variables. We validate the proposed models in both publicly\navailable data (i.e., MIMIC-III and AmsterdamUMCdb) and proprietary data in The\nOhio State University Wexner Medical Center (OSUWMC). The experimental results\nshow that the propagated uncertainty is dominant at the beginning of admissions\nto hospitals and the proposed algorithm outperforms state-of-the-art active\nsensing methods. Finally, we implement a SepsisLab system for early sepsis\nprediction and active sensing based on our pre-trained models. Clinicians and\npotential sepsis patients can benefit from the system in early prediction and\ndiagnosis of sepsis.",
    "authors": [
      "Changchang Yin",
      "Pin-Yu Chen",
      "Bingsheng Yao",
      "Dakuo Wang",
      "Jeffrey Caterino",
      "Ping Zhang"
    ],
    "pdf_link": "http://arxiv.org/pdf/2407.16999v1",
    "category": [
      "AI in Healthcare",
      "Datasets"
    ]
  },
  {
    "title": "Time Series Missing Imputation with Multivariate Radial Basis Function Neural Network",
    "abstract": "Researchers have been persistently working to address the issue of missing\nvalues in time series data. Numerous models have been proposed, striving to\nestimate the distribution of the data. The Radial Basis Functions Neural\nNetwork (RBFNN) has recently exhibited exceptional performance in estimating\ndata distribution. In this paper, we propose a time series imputation model\nbased on RBFNN. Our imputation model learns local information from timestamps\nto create a continuous function. Additionally, we incorporate time gaps to\nfacilitate learning information considering the missing terms of missing\nvalues. We name this model the Missing Imputation Multivariate RBFNN\n(MIM-RBFNN). However, MIM-RBFNN relies on a local information-based learning\napproach, which presents difficulties in utilizing temporal information.\nTherefore, we propose an extension called the Missing Value Imputation\nRecurrent Neural Network with Continuous Function (MIRNN-CF) using the\ncontinuous function generated by MIM-RBFNN. We evaluate the performance using\ntwo real-world datasets with non-random missing and random missing patterns,\nand conduct an ablation study comparing MIM-RBFNN and MIRNN-CF.",
    "authors": [
      "Chanyoung Jung",
      "Yun Jang"
    ],
    "pdf_link": "http://arxiv.org/pdf/2407.17040v1",
    "category": [
      "Datasets",
      "AI in Healthcare"
    ]
  },
  {
    "title": "Curriculum Negative Mining For Temporal Networks",
    "abstract": "Temporal networks are effective in capturing the evolving interactions of\nnetworks over time, such as social networks and e-commerce networks. In recent\nyears, researchers have primarily concentrated on developing specific model\narchitectures for Temporal Graph Neural Networks (TGNNs) in order to improve\nthe representation quality of temporal nodes and edges. However, limited\nattention has been given to the quality of negative samples during the training\nof TGNNs. When compared with static networks, temporal networks present two\nspecific challenges for negative sampling: positive sparsity and positive\nshift. Positive sparsity refers to the presence of a single positive sample\namidst numerous negative samples at each timestamp, while positive shift\nrelates to the variations in positive samples across different timestamps. To\nrobustly address these challenges in training TGNNs, we introduce Curriculum\nNegative Mining (CurNM), a model-aware curriculum learning framework that\nadaptively adjusts the difficulty of negative samples. Within this framework,\nwe first establish a dynamically updated negative pool that balances random,\nhistorical, and hard negatives to address the challenges posed by positive\nsparsity. Secondly, we implement a temporal-aware negative selection module\nthat focuses on learning from the disentangled factors of recently active\nedges, thus accurately capturing shifting preferences. Extensive experiments on\n12 datasets and 3 TGNNs demonstrate that our method outperforms baseline\nmethods by a significant margin. Additionally, thorough ablation studies and\nparameter sensitivity experiments verify the usefulness and robustness of our\napproach. Our code is available at https://github.com/zziyue83/CurNM.",
    "authors": [
      "Ziyue Chen",
      "Tongya Zheng",
      "Mingli Song"
    ],
    "pdf_link": "http://arxiv.org/pdf/2407.17070v1",
    "category": [
      "Reinforcement Learning",
      "Datasets"
    ]
  },
  {
    "title": "Towards Robust Knowledge Tracing Models via k-Sparse Attention",
    "abstract": "Knowledge tracing (KT) is the problem of predicting students' future\nperformance based on their historical interaction sequences. With the advanced\ncapability of capturing contextual long-term dependency, attention mechanism\nbecomes one of the essential components in many deep learning based KT (DLKT)\nmodels. In spite of the impressive performance achieved by these attentional\nDLKT models, many of them are often vulnerable to run the risk of overfitting,\nespecially on small-scale educational datasets. Therefore, in this paper, we\npropose \\textsc{sparseKT}, a simple yet effective framework to improve the\nrobustness and generalization of the attention based DLKT approaches.\nSpecifically, we incorporate a k-selection module to only pick items with the\nhighest attention scores. We propose two sparsification heuristics : (1)\nsoft-thresholding sparse attention and (2) top-$K$ sparse attention. We show\nthat our \\textsc{sparseKT} is able to help attentional KT models get rid of\nirrelevant student interactions and have comparable predictive performance when\ncompared to 11 state-of-the-art KT models on three publicly available\nreal-world educational datasets. To encourage reproducible research, we make\nour data and code publicly available at\n\\url{https://github.com/pykt-team/pykt-toolkit}\\footnote{We merged our model to\nthe \\textsc{pyKT} benchmark at \\url{https://pykt.org/}.}.",
    "authors": [
      "Shuyan Huang",
      "Zitao Liu",
      "Xiangyu Zhao",
      "Weiqi Luo",
      "Jian Weng"
    ],
    "pdf_link": "http://arxiv.org/pdf/2407.17097v1",
    "category": [
      "Datasets",
      "LLMs"
    ]
  },
  {
    "title": "Neural Dueling Bandits",
    "abstract": "Contextual dueling bandit is used to model the bandit problems, where a\nlearner's goal is to find the best arm for a given context using observed noisy\npreference feedback over the selected arms for the past contexts. However,\nexisting algorithms assume the reward function is linear, which can be complex\nand non-linear in many real-life applications like online recommendations or\nranking web search results. To overcome this challenge, we use a neural network\nto estimate the reward function using preference feedback for the previously\nselected arms. We propose upper confidence bound- and Thompson sampling-based\nalgorithms with sub-linear regret guarantees that efficiently select arms in\neach round. We then extend our theoretical results to contextual bandit\nproblems with binary feedback, which is in itself a non-trivial contribution.\nExperimental results on the problem instances derived from synthetic datasets\ncorroborate our theoretical results.",
    "authors": [
      "Arun Verma",
      "Zhongxiang Dai",
      "Xiaoqiang Lin",
      "Patrick Jaillet",
      "Bryan Kian Hsiang Low"
    ],
    "pdf_link": "http://arxiv.org/pdf/2407.17112v1",
    "category": [
      "Reinforcement Learning",
      "Explainable AI"
    ]
  },
  {
    "title": "Parameter-Efficient Fine-Tuning for Continual Learning: A Neural Tangent Kernel Perspective",
    "abstract": "Parameter-efficient fine-tuning for continual learning (PEFT-CL) has shown\npromise in adapting pre-trained models to sequential tasks while mitigating\ncatastrophic forgetting problem. However, understanding the mechanisms that\ndictate continual performance in this paradigm remains elusive. To tackle this\ncomplexity, we undertake a rigorous analysis of PEFT-CL dynamics to derive\nrelevant metrics for continual scenarios using Neural Tangent Kernel (NTK)\ntheory. With the aid of NTK as a mathematical analysis tool, we recast the\nchallenge of test-time forgetting into the quantifiable generalization gaps\nduring training, identifying three key factors that influence these gaps and\nthe performance of PEFT-CL: training sample size, task-level feature\northogonality, and regularization. To address these challenges, we introduce\nNTK-CL, a novel framework that eliminates task-specific parameter storage while\nadaptively generating task-relevant features. Aligning with theoretical\nguidance, NTK-CL triples the feature representation of each sample,\ntheoretically and empirically reducing the magnitude of both task-interplay and\ntask-specific generalization gaps. Grounded in NTK analysis, our approach\nimposes an adaptive exponential moving average mechanism and constraints on\ntask-level feature orthogonality, maintaining intra-task NTK forms while\nattenuating inter-task NTK forms. Ultimately, by fine-tuning optimizable\nparameters with appropriate regularization, NTK-CL achieves state-of-the-art\nperformance on established PEFT-CL benchmarks. This work provides a theoretical\nfoundation for understanding and improving PEFT-CL models, offering insights\ninto the interplay between feature representation, task orthogonality, and\ngeneralization, contributing to the development of more efficient continual\nlearning systems.",
    "authors": [
      "Jingren Liu",
      "Zhong Ji",
      "YunLong Yu",
      "Jiale Cao",
      "Yanwei Pang",
      "Jungong Han",
      "Xuelong Li"
    ],
    "pdf_link": "http://arxiv.org/pdf/2407.17120v1",
    "category": [
      "Multimodal Learning",
      "Reinforcement Learning"
    ]
  },
  {
    "title": "Robust Deep Hawkes Process under Label Noise of Both Event and Occurrence",
    "abstract": "Integrating deep neural networks with the Hawkes process has significantly\nimproved predictive capabilities in finance, health informatics, and\ninformation technology. Nevertheless, these models often face challenges in\nreal-world settings, particularly due to substantial label noise. This issue is\nof significant concern in the medical field, where label noise can arise from\ndelayed updates in electronic medical records or misdiagnoses, leading to\nincreased prediction risks. Our research indicates that deep Hawkes process\nmodels exhibit reduced robustness when dealing with label noise, particularly\nwhen it affects both event types and timing. To address these challenges, we\nfirst investigate the influence of label noise in approximated intensity\nfunctions and present a novel framework, the Robust Deep Hawkes Process (RDHP),\nto overcome the impact of label noise on the intensity function of Hawkes\nmodels, considering both the events and their occurrences. We tested RDHP using\nmultiple open-source benchmarks with synthetic noise and conducted a case study\non obstructive sleep apnea-hypopnea syndrome (OSAHS) in a real-world setting\nwith inherent label noise. The results demonstrate that RDHP can effectively\nperform classification and regression tasks, even in the presence of noise\nrelated to events and their timing. To the best of our knowledge, this is the\nfirst study to successfully address both event and time label noise in deep\nHawkes process models, offering a promising solution for medical applications,\nspecifically in diagnosing OSAHS.",
    "authors": [
      "Xiaoyu Tan",
      "Bin Li",
      "Xihe Qiu",
      "Jingjing Huang",
      "Yinghui Xu",
      "Wei Chu"
    ],
    "pdf_link": "http://arxiv.org/pdf/2407.17164v1",
    "category": [
      "AI in Healthcare",
      "Explainable AI"
    ]
  },
  {
    "title": "Take a Step and Reconsider: Sequence Decoding for Self-Improved Neural Combinatorial Optimization",
    "abstract": "The constructive approach within Neural Combinatorial Optimization (NCO)\ntreats a combinatorial optimization problem as a finite Markov decision\nprocess, where solutions are built incrementally through a sequence of\ndecisions guided by a neural policy network. To train the policy, recent\nresearch is shifting toward a 'self-improved' learning methodology that\naddresses the limitations of reinforcement learning and supervised approaches.\nHere, the policy is iteratively trained in a supervised manner, with solutions\nderived from the current policy serving as pseudo-labels. The way these\nsolutions are obtained from the policy determines the quality of the\npseudo-labels. In this paper, we present a simple and problem-independent\nsequence decoding method for self-improved learning based on sampling sequences\nwithout replacement. We incrementally follow the best solution found and repeat\nthe sampling process from intermediate partial solutions. By modifying the\npolicy to ignore previously sampled sequences, we force it to consider only\nunseen alternatives, thereby increasing solution diversity. Experimental\nresults for the Traveling Salesman and Capacitated Vehicle Routing Problem\ndemonstrate its strong performance. Furthermore, our method outperforms\nprevious NCO approaches on the Job Shop Scheduling Problem.",
    "authors": [
      "Jonathan Pirnay",
      "Dominik G. Grimm"
    ],
    "pdf_link": "http://arxiv.org/pdf/2407.17206v1",
    "category": [
      "Reinforcement Learning",
      "Speech Synthesis"
    ]
  },
  {
    "title": "Sublinear Regret for An Actor-Critic Algorithm in Continuous-Time Linear-Quadratic Reinforcement Learning",
    "abstract": "We study reinforcement learning (RL) for a class of continuous-time\nlinear-quadratic (LQ) control problems for diffusions where volatility of the\nstate processes depends on both state and control variables. We apply a\nmodel-free approach that relies neither on knowledge of model parameters nor on\ntheir estimations, and devise an actor-critic algorithm to learn the optimal\npolicy parameter directly. Our main contributions include the introduction of a\nnovel exploration schedule and a regret analysis of the proposed algorithm. We\nprovide the convergence rate of the policy parameter to the optimal one, and\nprove that the algorithm achieves a regret bound of $O(N^{\\frac{3}{4}})$ up to\na logarithmic factor. We conduct a simulation study to validate the theoretical\nresults and demonstrate the effectiveness and reliability of the proposed\nalgorithm. We also perform numerical comparisons between our method and those\nof the recent model-based stochastic LQ RL studies adapted to the state- and\ncontrol-dependent volatility setting, demonstrating a better performance of the\nformer in terms of regret bounds.",
    "authors": [
      "Yilie Huang",
      "Yanwei Jia",
      "Xun Yu Zhou"
    ],
    "pdf_link": "http://arxiv.org/pdf/2407.17226v1",
    "category": [
      "Reinforcement Learning",
      "Explainable AI"
    ]
  },
  {
    "title": "Co-designing an AI Impact Assessment Report Template with AI Practitioners and AI Compliance Experts",
    "abstract": "In the evolving landscape of AI regulation, it is crucial for companies to\nconduct impact assessments and document their compliance through comprehensive\nreports. However, current reports lack grounding in regulations and often focus\non specific aspects like privacy in relation to AI systems, without addressing\nthe real-world uses of these systems. Moreover, there is no systematic effort\nto design and evaluate these reports with both AI practitioners and AI\ncompliance experts. To address this gap, we conducted an iterative co-design\nprocess with 14 AI practitioners and 6 AI compliance experts and proposed a\ntemplate for impact assessment reports grounded in the EU AI Act, NIST's AI\nRisk Management Framework, and ISO 42001 AI Management System. We evaluated the\ntemplate by producing an impact assessment report for an AI-based meeting\ncompanion at a major tech company. A user study with 8 AI practitioners from\nthe same company and 5 AI compliance experts from industry and academia\nrevealed that our template effectively provides necessary information for\nimpact assessments and documents the broad impacts of AI systems. Participants\nenvisioned using the template not only at the pre-deployment stage for\ncompliance but also as a tool to guide the design stage of AI uses.",
    "authors": [
      "Edyta Bogucka",
      "Marios Constantinides",
      "Sanja \u0160\u0107epanovi\u0107",
      "Daniele Quercia"
    ],
    "pdf_link": "http://arxiv.org/pdf/2407.17374v1",
    "category": [
      "AI in Healthcare",
      "Explainable AI"
    ]
  },
  {
    "title": "Systematic Reasoning About Relational Domains With Graph Neural Networks",
    "abstract": "Developing models that can learn to reason is a notoriously challenging\nproblem. We focus on reasoning in relational domains, where the use of Graph\nNeural Networks (GNNs) seems like a natural choice. However, previous work on\nreasoning with GNNs has shown that such models tend to fail when presented with\ntest examples that require longer inference chains than those seen during\ntraining. This suggests that GNNs lack the ability to generalize from training\nexamples in a systematic way, which would fundamentally limit their reasoning\nabilities. A common solution is to instead rely on neuro-symbolic methods,\nwhich are capable of reasoning in a systematic way by design. Unfortunately,\nthe scalability of such methods is often limited and they tend to rely on\noverly strong assumptions, e.g.\\ that queries can be answered by inspecting a\nsingle relational path. In this paper, we revisit the idea of reasoning with\nGNNs, showing that systematic generalization is possible as long as the right\ninductive bias is provided. In particular, we argue that node embeddings should\nbe treated as epistemic states and that GNN should be parameterised\naccordingly. We propose a simple GNN architecture which is based on this view\nand show that it is capable of achieving state-of-the-art results. We\nfurthermore introduce a benchmark which requires models to aggregate evidence\nfrom multiple relational paths. We show that existing neuro-symbolic approaches\nfail on this benchmark, whereas our considered GNN model learns to reason\naccurately.",
    "authors": [
      "Irtaza Khalid",
      "Steven Schockaert"
    ],
    "pdf_link": "http://arxiv.org/pdf/2407.17396v1",
    "category": [
      "Explainable AI",
      "Reinforcement Learning"
    ]
  },
  {
    "title": "Automated Explanation Selection for Scientific Discovery",
    "abstract": "Automated reasoning is a key technology in the young but rapidly growing\nfield of Explainable Artificial Intelligence (XAI). Explanability helps build\ntrust in artificial intelligence systems beyond their mere predictive accuracy\nand robustness. In this paper, we propose a cycle of scientific discovery that\ncombines machine learning with automated reasoning for the generation and the\nselection of explanations. We present a taxonomy of explanation selection\nproblems that draws on insights from sociology and cognitive science. These\nselection criteria subsume existing notions and extend them with new\nproperties.",
    "authors": [
      "Markus Iser"
    ],
    "pdf_link": "http://arxiv.org/pdf/2407.17454v1",
    "category": [
      "Explainable AI",
      "AI in Healthcare"
    ]
  }
]