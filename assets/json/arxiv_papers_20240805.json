[
  {
    "title": "The Artificial Intelligence Disclosure (AID) Framework: An Introduction",
    "abstract": "As the use of Generative Artificial Intelligence tools have grown in higher\neducation and research, there have been increasing calls for transparency and\ngranularity around the use and attribution of the use of these tools. Thus far,\nthis need has been met via the recommended inclusion of a note, with little to\nno guidance on what the note itself should include. This has been identified as\na problem to the use of AI in academic and research contexts. This article\nintroduces The Artificial Intelligence Disclosure (AID) Framework, a standard,\ncomprehensive, and detailed framework meant to inform the development and\nwriting of GenAI disclosure for education and research.",
    "authors": [
      "Kari D. Weaver"
    ],
    "pdf_link": "http://arxiv.org/pdf/2408.01904v1",
    "category": [
      "Explainable AI",
      "AI in Healthcare"
    ]
  },
  {
    "title": "MAO: A Framework for Process Model Generation with Multi-Agent Orchestration",
    "abstract": "Process models are frequently used in software engineering to describe\nbusiness requirements, guide software testing and control system improvement.\nHowever, traditional process modeling methods often require the participation\nof numerous experts, which is expensive and time-consuming. Therefore, the\nexploration of a more efficient and cost-effective automated modeling method\nhas emerged as a focal point in current research. This article explores a\nframework for automatically generating process models with multi-agent\norchestration (MAO), aiming to enhance the efficiency of process modeling and\noffer valuable insights for domain experts. Our framework MAO leverages large\nlanguage models as the cornerstone for multi-agent, employing an innovative\nprompt strategy to ensure efficient collaboration among multi-agent.\nSpecifically, 1) generation. The first phase of MAO is to generate a slightly\nrough process model from the text description; 2) refinement. The agents would\ncontinuously refine the initial process model through multiple rounds of\ndialogue; 3) reviewing. Large language models are prone to hallucination\nphenomena among multi-turn dialogues, so the agents need to review and repair\nsemantic hallucinations in process models; 4) testing. The representation of\nprocess models is diverse. Consequently, the agents utilize external tools to\ntest whether the generated process model contains format errors, namely format\nhallucinations, and then adjust the process model to conform to the output\nparadigm. The experiments demonstrate that the process models generated by our\nframework outperform existing methods and surpass manual modeling by 89%, 61%,\n52%, and 75% on four different datasets, respectively.",
    "authors": [
      "Leilei Lin",
      "Yumeng Jin",
      "Yingming Zhou",
      "Wenlong Chen",
      "Chen Qian"
    ],
    "pdf_link": "http://arxiv.org/pdf/2408.01916v1",
    "category": [
      "Explainable AI",
      "Speech Synthesis"
    ]
  },
  {
    "title": "Top K Enhanced Reinforcement Learning Attacks on Heterogeneous Graph Node Classification",
    "abstract": "Graph Neural Networks (GNNs) have attracted substantial interest due to their\nexceptional performance on graph-based data. However, their robustness,\nespecially on heterogeneous graphs, remains underexplored, particularly against\nadversarial attacks. This paper proposes HeteroKRLAttack, a targeted evasion\nblack-box attack method for heterogeneous graphs. By integrating reinforcement\nlearning with a Top-K algorithm to reduce the action space, our method\nefficiently identifies effective attack strategies to disrupt node\nclassification tasks. We validate the effectiveness of HeteroKRLAttack through\nexperiments on multiple heterogeneous graph datasets, showing significant\nreductions in classification accuracy compared to baseline methods. An ablation\nstudy underscores the critical role of the Top-K algorithm in enhancing attack\nperformance. Our findings highlight potential vulnerabilities in current models\nand provide guidance for future defense strategies against adversarial attacks\non heterogeneous graphs.",
    "authors": [
      "Honglin Gao",
      "Gaoxi Xiao"
    ],
    "pdf_link": "http://arxiv.org/pdf/2408.01964v1",
    "category": [
      "Explainable AI",
      "Reinforcement Learning"
    ]
  },
  {
    "title": "MetaWearS: A Shortcut in Wearable Systems Lifecycle with Only a Few Shots",
    "abstract": "Wearable systems provide continuous health monitoring and can lead to early\ndetection of potential health issues. However, the lifecycle of wearable\nsystems faces several challenges. First, effective model training for new\nwearable devices requires substantial labeled data from various subjects\ncollected directly by the wearable. Second, subsequent model updates require\nfurther extensive labeled data for retraining. Finally, frequent model updating\non the wearable device can decrease the battery life in long-term data\nmonitoring. Addressing these challenges, in this paper, we propose MetaWearS, a\nmeta-learning method to reduce the amount of initial data collection required.\nMoreover, our approach incorporates a prototypical updating mechanism,\nsimplifying the update process by modifying the class prototype rather than\nretraining the entire model. We explore the performance of MetaWearS in two\ncase studies, namely, the detection of epileptic seizures and the detection of\natrial fibrillation. We show that by fine-tuning with just a few samples, we\nachieve 70% and 82% AUC for the detection of epileptic seizures and the\ndetection of atrial fibrillation, respectively. Compared to a conventional\napproach, our proposed method performs better with up to 45% AUC. Furthermore,\nupdating the model with only 16 minutes of additional labeled data increases\nthe AUC by up to 5.3%. Finally, MetaWearS reduces the energy consumption for\nmodel updates by 456x and 418x for epileptic seizure and AF detection,\nrespectively.",
    "authors": [
      "Alireza Amirshahi",
      "Maedeh H. Toosi",
      "Siamak Mohammadi",
      "Stefano Albini",
      "Pasquale Davide Schiavone",
      "Giovanni Ansaloni",
      "Amir Aminifar",
      "David Atienza"
    ],
    "pdf_link": "http://arxiv.org/pdf/2408.01988v1",
    "category": [
      "AI in Healthcare",
      "Datasets"
    ]
  },
  {
    "title": "Reinforcement Learning for an Efficient and Effective Malware Investigation during Cyber Incident Response",
    "abstract": "This research focused on enhancing post-incident malware forensic\ninvestigation using reinforcement learning RL. We proposed an advanced MDP post\nincident malware forensics investigation model and framework to expedite post\nincident forensics. We then implement our RL Malware Investigation Model based\non structured MDP within the proposed framework. To identify malware artefacts,\nthe RL agent acquires and examines forensics evidence files, iteratively\nimproving its capabilities using Q Table and temporal difference learning. The\nQ learning algorithm significantly improved the agent ability to identify\nmalware. An epsilon greedy exploration strategy and Q learning updates enabled\nefficient learning and decision making. Our experimental testing revealed that\noptimal learning rates depend on the MDP environment complexity, with simpler\nenvironments benefiting from higher rates for quicker convergence and complex\nones requiring lower rates for stability. Our model performance in identifying\nand classifying malware reduced malware analysis time compared to human\nexperts, demonstrating robustness and adaptability. The study highlighted the\nsignificance of hyper parameter tuning and suggested adaptive strategies for\ncomplex environments. Our RL based approach produced promising results and is\nvalidated as an alternative to traditional methods notably by offering\ncontinuous learning and adaptation to new and evolving malware threats which\nultimately enhance the post incident forensics investigations.",
    "authors": [
      "Dipo Dunsin",
      "Mohamed Chahine Ghanem",
      "Karim Ouazzane",
      "Vassil Vassilev"
    ],
    "pdf_link": "http://arxiv.org/pdf/2408.01999v1",
    "category": [
      "Reinforcement Learning",
      "Explainable AI"
    ]
  },
  {
    "title": "Joint Learning of Emotions in Music and Generalized Sounds",
    "abstract": "In this study, we aim to determine if generalized sounds and music can share\na common emotional space, improving predictions of emotion in terms of arousal\nand valence. We propose the use of multiple datasets as a multi-domain learning\ntechnique. Our approach involves creating a common space encompassing features\nthat characterize both generalized sounds and music, as they can evoke emotions\nin a similar manner. To achieve this, we utilized two publicly available\ndatasets, namely IADS-E and PMEmo, following a standardized experimental\nprotocol. We employed a wide variety of features that capture diverse aspects\nof the audio structure including key parameters of spectrum, energy, and\nvoicing. Subsequently, we performed joint learning on the common feature space,\nleveraging heterogeneous model architectures. Interestingly, this synergistic\nscheme outperforms the state-of-the-art in both sound and music emotion\nprediction. The code enabling full replication of the presented experimental\npipeline is available at https://github.com/LIMUNIMI/MusicSoundEmotions.",
    "authors": [
      "Simonetta Federico",
      "Certo Francesca",
      "Ntalampiras Stavros"
    ],
    "pdf_link": "http://arxiv.org/pdf/2408.02009v1",
    "category": [
      "Multimodal Learning",
      "Speech Recognition"
    ]
  },
  {
    "title": "Contrastive Learning-based Chaining-Cluster for Multilingual Voice-Face Association",
    "abstract": "The innate correlation between a person's face and voice has recently emerged\nas a compelling area of study, especially within the context of multilingual\nenvironments. This paper introduces our novel solution to the Face-Voice\nAssociation in Multilingual Environments (FAME) 2024 challenge, focusing on a\ncontrastive learning-based chaining-cluster method to enhance face-voice\nassociation. This task involves the challenges of building biometric relations\nbetween auditory and visual modality cues and modelling the prosody\ninterdependence between different languages while addressing both intrinsic and\nextrinsic variability present in the data. To handle these non-trivial\nchallenges, our method employs supervised cross-contrastive (SCC) learning to\nestablish robust associations between voices and faces in multi-language\nscenarios. Following this, we have specifically designed a\nchaining-cluster-based post-processing step to mitigate the impact of outliers\noften found in unconstrained in the wild data. We conducted extensive\nexperiments to investigate the impact of language on face-voice association.\nThe overall results were evaluated on the FAME public evaluation platform,\nwhere we achieved 2nd place. The results demonstrate the superior performance\nof our method, and we validate the robustness and effectiveness of our proposed\napproach. Code is available at https://github.com/colaudiolab/FAME24_solution.",
    "authors": [
      "Wuyang Chen",
      "Yanjie Sun",
      "Kele Xu",
      "Yong Dou"
    ],
    "pdf_link": "http://arxiv.org/pdf/2408.02025v1",
    "category": [
      "Multimodal Learning",
      "Speech Recognition"
    ]
  },
  {
    "title": "Mining Path Association Rules in Large Property Graphs (with Appendix)",
    "abstract": "How can we mine frequent path regularities from a graph with edge labels and\nvertex attributes? The task of association rule mining successfully discovers\nregular patterns in item sets and substructures. Still, to our best knowledge,\nthis concept has not yet been extended to path patterns in large property\ngraphs. In this paper, we introduce the problem of path association rule mining\n(PARM). Applied to any \\emph{reachability path} between two vertices within a\nlarge graph, PARM discovers regular ways in which path patterns, identified by\nvertex attributes and edge labels, co-occur with each other. We develop an\nefficient and scalable algorithm PIONEER that exploits an anti-monotonicity\nproperty to effectively prune the search space. Further, we devise\napproximation techniques and employ parallelization to achieve scalable path\nassociation rule mining. Our experimental study using real-world graph data\nverifies the significance of path association rules and the efficiency of our\nsolutions.",
    "authors": [
      "Yuya Sasaki",
      "Panagiotis Karras"
    ],
    "pdf_link": "http://arxiv.org/pdf/2408.02029v1",
    "category": [
      "AI in Healthcare",
      "Datasets"
    ]
  },
  {
    "title": "Dise\u00f1o de sonido para producciones audiovisuales e historias sonoras en el aula. Hacia una docencia creativa mediante el uso de herramientas inteligentes",
    "abstract": "This study aims to share a teaching experience teaching sound design for\naudiovisual productions and compares different projects tackled by students. It\nis not intended to be a comparative analysis of different types of teaching but\nrather an analysis of different problems observed in different profiles of\nstudents of the subject who study it in different grades. The world of audio\ncan be very interesting for a large part of the students, both those with\ncreative and technical inclinations. Musical creation and production,\nsynchronization with images, dubbing, etc. They are disciplines that are\ngenerally interesting but can have a very high barrier to entry due to their\ngreat technical complexity. Sometimes it can take weeks or even months for the\nuninitiated to begin to use audio editing programs with the necessary ease,\nwhich are not always particularly intuitive for students. Learning through the\nuse of PBL methodologies generates, in our experience, results much superior to\nthose that can be observed through the use of other teaching methods such as\nmaster classes. Students acquire technical skills while developing creative\nprojects in which they get personally involved. Despite everything mentioned\nabove, most interactions between teachers and students focus on aspects of\ntechnical correction. From different parameters in reverbs (such as pre-delay,\ndecay, modulation...) to how to correctly adjust compressors, noise gates,\netc.; The number of tools with which to work with audio is incredibly\nextensive, as well as many of its features that can present serious differences\ndepending on their manufacturers.",
    "authors": [
      "Miguel Civit",
      "Francisco Cuadrado"
    ],
    "pdf_link": "http://arxiv.org/pdf/2408.02113v1",
    "category": [
      "Speech Synthesis",
      "Speech Recognition"
    ]
  },
  {
    "title": "Value-Based Rationales Improve Social Experience: A Multiagent Simulation Study",
    "abstract": "We propose Exanna, a framework to realize agents that incorporate values in\ndecision making. An Exannaagent considers the values of itself and others when\nproviding rationales for its actions and evaluating the rationales provided by\nothers. Via multiagent simulation, we demonstrate that considering values in\ndecision making and producing rationales, especially for norm-deviating\nactions, leads to (1) higher conflict resolution, (2) better social experience,\n(3) higher privacy, and (4) higher flexibility.",
    "authors": [
      "Sz-Ting Tzeng",
      "Nirav Ajmeri",
      "Munindar P. Singh"
    ],
    "pdf_link": "http://arxiv.org/pdf/2408.02117v1",
    "category": [
      "Explainable AI",
      "Reinforcement Learning"
    ]
  },
  {
    "title": "ARVO: Atlas of Reproducible Vulnerabilities for Open Source Software",
    "abstract": "High-quality datasets of real-world vulnerabilities are enormously valuable\nfor downstream research in software security, but existing datasets are\ntypically small, require extensive manual effort to update, and are missing\ncrucial features that such research needs. In this paper, we introduce ARVO: an\nAtlas of Reproducible Vulnerabilities in Open-source software. By sourcing\nvulnerabilities from C/C++ projects that Google's OSS-Fuzz discovered and\nimplementing a reliable re-compilation system, we successfully reproduce more\nthan 5,000 memory vulnerabilities across over 250 projects, each with a\ntriggering input, the canonical developer-written patch for fixing the\nvulnerability, and the ability to automatically rebuild the project from source\nand run it at its vulnerable and patched revisions. Moreover, our dataset can\nbe automatically updated as OSS-Fuzz finds new vulnerabilities, allowing it to\ngrow over time. We provide a thorough characterization of the ARVO dataset,\nshow that it can locate fixes more accurately than Google's own OSV\nreproduction effort, and demonstrate its value for future research through two\ncase studies: firstly evaluating real-world LLM-based vulnerability repair, and\nsecondly identifying over 300 falsely patched (still-active) zero-day\nvulnerabilities from projects improperly labeled by OSS-Fuzz.",
    "authors": [
      "Xiang Mei",
      "Pulkit Singh Singaria",
      "Jordi Del Castillo",
      "Haoran Xi",
      "Abdelouahab",
      "Benchikh",
      "Tiffany Bao",
      "Ruoyu Wang",
      "Yan Shoshitaishvili",
      "Adam Doup\u00e9",
      "Hammond Pearce",
      "Brendan Dolan-Gavitt"
    ],
    "pdf_link": "http://arxiv.org/pdf/2408.02153v1",
    "category": [
      "Benchmarking",
      "Datasets"
    ]
  },
  {
    "title": "Calibration-Disentangled Learning and Relevance-Prioritized Reranking for Calibrated Sequential Recommendation",
    "abstract": "Calibrated recommendation, which aims to maintain personalized proportions of\ncategories within recommendations, is crucial in practical scenarios since it\nenhances user satisfaction by reflecting diverse interests. However, achieving\ncalibration in a sequential setting (i.e., calibrated sequential\nrecommendation) is challenging due to the need to adapt to users' evolving\npreferences. Previous methods typically leverage reranking algorithms to\ncalibrate recommendations after training a model without considering the effect\nof calibration and do not effectively tackle the conflict between relevance and\ncalibration during the reranking process. In this work, we propose LeapRec\n(Calibration-Disentangled Learning and Relevance-Prioritized Reranking), a\nnovel approach for the calibrated sequential recommendation that addresses\nthese challenges. LeapRec consists of two phases, model training phase and\nreranking phase. In the training phase, a backbone model is trained using our\nproposed calibration-disentangled learning-to-rank loss, which optimizes\npersonalized rankings while integrating calibration considerations. In the\nreranking phase, relevant items are prioritized at the top of the list, with\nitems needed for calibration following later to address potential conflicts\nbetween relevance and calibration. Through extensive experiments on four\nreal-world datasets, we show that LeapRec consistently outperforms previous\nmethods in the calibrated sequential recommendation. Our code is available at\nhttps://github.com/jeon185/LeapRec.",
    "authors": [
      "Hyunsik Jeon",
      "Se-eun Yoon",
      "Julian McAuley"
    ],
    "pdf_link": "http://arxiv.org/pdf/2408.02156v1",
    "category": [
      "Reinforcement Learning",
      "Multimodal Learning"
    ]
  },
  {
    "title": "SelfBC: Self Behavior Cloning for Offline Reinforcement Learning",
    "abstract": "Policy constraint methods in offline reinforcement learning employ additional\nregularization techniques to constrain the discrepancy between the learned\npolicy and the offline dataset. However, these methods tend to result in overly\nconservative policies that resemble the behavior policy, thus limiting their\nperformance. We investigate this limitation and attribute it to the static\nnature of traditional constraints. In this paper, we propose a novel dynamic\npolicy constraint that restricts the learned policy on the samples generated by\nthe exponential moving average of previously learned policies. By integrating\nthis self-constraint mechanism into off-policy methods, our method facilitates\nthe learning of non-conservative policies while avoiding policy collapse in the\noffline setting. Theoretical results show that our approach results in a nearly\nmonotonically improved reference policy. Extensive experiments on the D4RL\nMuJoCo domain demonstrate that our proposed method achieves state-of-the-art\nperformance among the policy constraint methods.",
    "authors": [
      "Shirong Liu",
      "Chenjia Bai",
      "Zixian Guo",
      "Hao Zhang",
      "Gaurav Sharma",
      "Yang Liu"
    ],
    "pdf_link": "http://arxiv.org/pdf/2408.02165v1",
    "category": [
      "Reinforcement Learning",
      "Multimodal Learning"
    ]
  },
  {
    "title": "Towards AI-Safety-by-Design: A Taxonomy of Runtime Guardrails in Foundation Model based Systems",
    "abstract": "The rapid advancement and widespread deployment of foundation model (FM)\nbased systems have revolutionized numerous applications across various domains.\nHowever, the fast-growing capabilities and autonomy have also raised\nsignificant concerns about responsible AI and AI safety. Recently, there have\nbeen increasing attention toward implementing guardrails to ensure the runtime\nbehavior of FM-based systems is safe and responsible. Given the early stage of\nFMs and their applications (such as agents), the design of guardrails have not\nyet been systematically studied. It remains underexplored which software\nqualities should be considered when designing guardrails and how these\nqualities can be ensured from a software architecture perspective. Therefore,\nin this paper, we present a taxonomy for guardrails to classify and compare the\ncharacteristics and design options of guardrails. Our taxonomy is organized\ninto three main categories: the motivation behind adopting runtime guardrails,\nthe quality attributes to consider, and the design options available. This\ntaxonomy provides structured and concrete guidance for making architectural\ndesign decisions when designing guardrails and highlights trade-offs arising\nfrom the design decisions.",
    "authors": [
      "Md Shamsujjoha",
      "Qinghua Lu",
      "Dehai Zhao",
      "Liming Zhu"
    ],
    "pdf_link": "http://arxiv.org/pdf/2408.02205v1",
    "category": [
      "Explainable AI",
      "Reinforcement Learning"
    ]
  },
  {
    "title": "Is Large Language Model Good at Database Knob Tuning? A Comprehensive Experimental Evaluation",
    "abstract": "Knob tuning plays a crucial role in optimizing databases by adjusting knobs\nto enhance database performance. However, traditional tuning methods often\nfollow a Try-Collect-Adjust approach, proving inefficient and\ndatabase-specific. Moreover, these methods are often opaque, making it\nchallenging for DBAs to grasp the underlying decision-making process.\n  The emergence of large language models (LLMs) like GPT-4 and Claude-3 has\nexcelled in complex natural language tasks, yet their potential in database\nknob tuning remains largely unexplored. This study harnesses LLMs as\nexperienced DBAs for knob-tuning tasks with carefully designed prompts. We\nidentify three key subtasks in the tuning system: knob pruning, model\ninitialization, and knob recommendation, proposing LLM-driven solutions to\nreplace conventional methods for each subtask.\n  We conduct extensive experiments to compare LLM-driven approaches against\ntraditional methods across the subtasks to evaluate LLMs' efficacy in the knob\ntuning domain. Furthermore, we explore the adaptability of LLM-based solutions\nin diverse evaluation settings, encompassing new benchmarks, database engines,\nand hardware environments. Our findings reveal that LLMs not only match or\nsurpass traditional methods but also exhibit notable interpretability by\ngenerating responses in a coherent ``chain-of-thought'' manner. We further\nobserve that LLMs exhibit remarkable generalizability through simple\nadjustments in prompts, eliminating the necessity for additional training or\nextensive code modifications.\n  Drawing insights from our experimental findings, we identify several\nopportunities for future research aimed at advancing the utilization of LLMs in\nthe realm of database management.",
    "authors": [
      "Yiyan Li",
      "Haoyang Li",
      "Zhao Pu",
      "Jing Zhang",
      "Xinyi Zhang",
      "Tao Ji",
      "Luming Sun",
      "Cuiping Li",
      "Hong Chen"
    ],
    "pdf_link": "http://arxiv.org/pdf/2408.02213v1",
    "category": [
      "Datasets",
      "LLMs"
    ]
  },
  {
    "title": "SpecRover: Code Intent Extraction via LLMs",
    "abstract": "Autonomous program improvement typically involves automatically producing bug\nfixes and feature additions. Such program improvement can be accomplished by a\ncombination of large language model (LLM) and program analysis capabilities, in\nthe form of an LLM agent. Since program repair or program improvement typically\nrequires a specification of intended behavior - specification inference can be\nuseful for producing high quality program patches. In this work, we examine\nefficient and low-cost workflows for iterative specification inference within\nan LLM agent. Given a GitHub issue to be resolved in a software project, our\ngoal is to conduct iterative code search accompanied by specification inference\n- thereby inferring intent from both the project structure and behavior. The\nintent thus captured is examined by a reviewer agent with the goal of vetting\nthe patches as well as providing a measure of confidence in the vetted patches.\nOur approach SpecRover (AutoCodeRover-v2) is built on the open-source LLM agent\nAutoCodeRover. In an evaluation on the full SWE-Bench consisting of 2294 GitHub\nissues, it shows more than 50% improvement in efficacy over AutoCodeRover.\nCompared to the open-source agents available, our work shows modest cost ($0.65\nper issue) in resolving an average GitHub issue in SWE-Bench lite. The\nproduction of explanation by SpecRover allows for a better \"signal\" to be given\nto the developer, on when the suggested patches can be accepted with\nconfidence. SpecRover also seeks to demonstrate the continued importance of\nspecification inference in automated program repair, even as program repair\ntechnologies enter the LLM era.",
    "authors": [
      "Haifeng Ruan",
      "Yuntong Zhang",
      "Abhik Roychoudhury"
    ],
    "pdf_link": "http://arxiv.org/pdf/2408.02232v1",
    "category": [
      "Explainable AI",
      "LLMs"
    ]
  },
  {
    "title": "Contrastive Learning and Abstract Concepts: The Case of Natural Numbers",
    "abstract": "Contrastive Learning (CL) has been successfully applied to classification and\nother downstream tasks related to concrete concepts, such as objects contained\nin the ImageNet dataset. No attempts seem to have been made so far in applying\nthis promising scheme to more abstract entities. A prominent example of these\ncould be the concept of (discrete) Quantity. CL can be frequently interpreted\nas a self-supervised scheme guided by some profound and ubiquitous conservation\nprinciple (e.g. conservation of identity in object classification tasks). In\nthis introductory work we apply a suitable conservation principle to the\nsemi-abstract concept of natural numbers by which discrete quantities can be\nestimated or predicted. We experimentally show, by means of a toy problem, that\ncontrastive learning can be trained to count at a glance with high accuracy\nboth at human as well as at super-human ranges.. We compare this with the\nresults of a trained-to-count at a glance supervised learning (SL) neural\nnetwork scheme of similar architecture. We show that both schemes exhibit\nsimilar good performance on baseline experiments, where the distributions of\nthe training and testing stages are equal. Importantly, we demonstrate that in\nsome generalization scenarios, where training and testing distributions differ,\nCL boasts more robust and much better error performance.",
    "authors": [
      "Daniel N. Nissani"
    ],
    "pdf_link": "http://arxiv.org/pdf/2408.02247v1",
    "category": [
      "Multimodal Learning",
      "Reinforcement Learning"
    ]
  },
  {
    "title": "DRFormer: Multi-Scale Transformer Utilizing Diverse Receptive Fields for Long Time-Series Forecasting",
    "abstract": "Long-term time series forecasting (LTSF) has been widely applied in finance,\ntraffic prediction, and other domains. Recently, patch-based transformers have\nemerged as a promising approach, segmenting data into sub-level patches that\nserve as input tokens. However, existing methods mostly rely on predetermined\npatch lengths, necessitating expert knowledge and posing challenges in\ncapturing diverse characteristics across various scales. Moreover, time series\ndata exhibit diverse variations and fluctuations across different temporal\nscales, which traditional approaches struggle to model effectively. In this\npaper, we propose a dynamic tokenizer with a dynamic sparse learning algorithm\nto capture diverse receptive fields and sparse patterns of time series data. In\norder to build hierarchical receptive fields, we develop a multi-scale\nTransformer model, coupled with multi-scale sequence extraction, capable of\ncapturing multi-resolution features. Additionally, we introduce a group-aware\nrotary position encoding technique to enhance intra- and inter-group position\nawareness among representations across different temporal scales. Our proposed\nmodel, named DRFormer, is evaluated on various real-world datasets, and\nexperimental results demonstrate its superiority compared to existing methods.\nOur code is available at: https://github.com/ruixindingECNU/DRFormer.",
    "authors": [
      "Ruixin Ding",
      "Yuqi Chen",
      "Yu-Ting Lan",
      "Wei Zhang"
    ],
    "pdf_link": "http://arxiv.org/pdf/2408.02279v1",
    "category": [
      "Multimodal Learning",
      "Speech Synthesis"
    ]
  },
  {
    "title": "Hardware Aware Ensemble Selection for Balancing Predictive Accuracy and Cost",
    "abstract": "Automated Machine Learning (AutoML) significantly simplifies the deployment\nof machine learning models by automating tasks from data preprocessing to model\nselection to ensembling. AutoML systems for tabular data often employ post hoc\nensembling, where multiple models are combined to improve predictive accuracy.\nThis typically results in longer inference times, a major limitation in\npractical deployments. Addressing this, we introduce a hardware-aware ensemble\nselection approach that integrates inference time into post hoc ensembling. By\nleveraging an existing framework for ensemble selection with quality diversity\noptimization, our method evaluates ensemble candidates for their predictive\naccuracy and hardware efficiency. This dual focus allows for a balanced\nconsideration of accuracy and operational efficiency. Thus, our approach\nenables practitioners to choose from a Pareto front of accurate and efficient\nensembles. Our evaluation using 83 classification datasets shows that our\napproach sustains competitive accuracy and can significantly improve ensembles'\noperational efficiency. The results of this study provide a foundation for\nextending these principles to additional hardware constraints, setting the\nstage for the development of more resource-efficient AutoML systems.",
    "authors": [
      "Jannis Maier",
      "Felix M\u00f6ller",
      "Lennart Purucker"
    ],
    "pdf_link": "http://arxiv.org/pdf/2408.02280v1",
    "category": [
      "Datasets",
      "Benchmarking"
    ]
  },
  {
    "title": "Generalized Gaussian Temporal Difference Error For Uncertainty-aware Reinforcement Learning",
    "abstract": "Conventional uncertainty-aware temporal difference (TD) learning methods\noften rely on simplistic assumptions, typically including a zero-mean Gaussian\ndistribution for TD errors. Such oversimplification can lead to inaccurate\nerror representations and compromised uncertainty estimation. In this paper, we\nintroduce a novel framework for generalized Gaussian error modeling in deep\nreinforcement learning, applicable to both discrete and continuous control\nsettings. Our framework enhances the flexibility of error distribution modeling\nby incorporating higher-order moments, particularly kurtosis, thereby improving\nthe estimation and mitigation of data-dependent noise, i.e., aleatoric\nuncertainty. We examine the influence of the shape parameter of the generalized\nGaussian distribution (GGD) on aleatoric uncertainty and provide a closed-form\nexpression that demonstrates an inverse relationship between uncertainty and\nthe shape parameter. Additionally, we propose a theoretically grounded\nweighting scheme to fully leverage the GGD. To address epistemic uncertainty,\nwe enhance the batch inverse variance weighting by incorporating bias reduction\nand kurtosis considerations, resulting in improved robustness. Extensive\nexperimental evaluations using policy gradient algorithms demonstrate the\nconsistent efficacy of our method, showcasing significant performance\nimprovements.",
    "authors": [
      "Seyeon Kim",
      "Joonhun Lee",
      "Namhoon Cho",
      "Sungjun Han",
      "Seungeon Baek"
    ],
    "pdf_link": "http://arxiv.org/pdf/2408.02295v1",
    "category": [
      "Reinforcement Learning",
      "Explainable AI"
    ]
  },
  {
    "title": "Active Sensing of Knee Osteoarthritis Progression with Reinforcement Learning",
    "abstract": "Osteoarthritis (OA) is the most common musculoskeletal disease, which has no\ncure. Knee OA (KOA) is one of the highest causes of disability worldwide, and\nit costs billions of United States dollars to the global community. Prediction\nof KOA progression has been of high interest to the community for years, as it\ncan advance treatment development through more efficient clinical trials and\nimprove patient outcomes through more efficient healthcare utilization.\nExisting approaches for predicting KOA, however, are predominantly static, i.e.\nconsider data from a single time point to predict progression many years into\nthe future, and knee level, i.e. consider progression in a single joint only.\nDue to these and related reasons, these methods fail to deliver the level of\npredictive performance, which is sufficient to result in cost savings and\nbetter patient outcomes. Collecting extensive data from all patients on a\nregular basis could address the issue, but it is limited by the high cost at a\npopulation level. In this work, we propose to go beyond static prediction\nmodels in OA, and bring a novel Active Sensing (AS) approach, designed to\ndynamically follow up patients with the objective of maximizing the number of\ninformative data acquisitions, while minimizing their total cost over a period\nof time. Our approach is based on Reinforcement Learning (RL), and it leverages\na novel reward function designed specifically for AS of disease progression in\nmore than one part of a human body. Our method is end-to-end, relies on\nmulti-modal Deep Learning, and requires no human input at inference time.\nThroughout an exhaustive experimental evaluation, we show that using RL can\nprovide a higher monetary benefit when compared to state-of-the-art baselines.",
    "authors": [
      "Khanh Nguyen",
      "Huy Hoang Nguyen",
      "Egor Panfilov",
      "Aleksei Tiulpin"
    ],
    "pdf_link": "http://arxiv.org/pdf/2408.02349v1",
    "category": [
      "AI in Healthcare",
      "Reinforcement Learning"
    ]
  },
  {
    "title": "Operationalizing Contextual Integrity in Privacy-Conscious Assistants",
    "abstract": "Advanced AI assistants combine frontier LLMs and tool access to autonomously\nperform complex tasks on behalf of users. While the helpfulness of such\nassistants can increase dramatically with access to user information including\nemails and documents, this raises privacy concerns about assistants sharing\ninappropriate information with third parties without user supervision. To steer\ninformation-sharing assistants to behave in accordance with privacy\nexpectations, we propose to operationalize $\\textit{contextual integrity}$\n(CI), a framework that equates privacy with the appropriate flow of information\nin a given context. In particular, we design and evaluate a number of\nstrategies to steer assistants' information-sharing actions to be CI compliant.\nOur evaluation is based on a novel form filling benchmark composed of synthetic\ndata and human annotations, and it reveals that prompting frontier LLMs to\nperform CI-based reasoning yields strong results.",
    "authors": [
      "Sahra Ghalebikesabi",
      "Eugene Bagdasaryan",
      "Ren Yi",
      "Itay Yona",
      "Ilia Shumailov",
      "Aneesh Pappu",
      "Chongyang Shi",
      "Laura Weidinger",
      "Robert Stanforth",
      "Leonard Berrada",
      "Pushmeet Kohli",
      "Po-Sen Huang",
      "Borja Balle"
    ],
    "pdf_link": "http://arxiv.org/pdf/2408.02373v1",
    "category": [
      "Explainable AI",
      "Datasets"
    ]
  },
  {
    "title": "Perfect Information Monte Carlo with Postponing Reasoning",
    "abstract": "Imperfect information games, such as Bridge and Skat, present challenges due\nto state-space explosion and hidden information, posing formidable obstacles\nfor search algorithms. Determinization-based algorithms offer a resolution by\nsampling hidden information and solving the game in a perfect information\nsetting, facilitating rapid and effective action estimation. However,\ntransitioning to perfect information introduces challenges, notably one called\nstrategy fusion.This research introduces `Extended Perfect Information Monte\nCarlo' (EPIMC), an online algorithm inspired by the state-of-the-art\ndeterminization-based approach Perfect Information Monte Carlo (PIMC). EPIMC\nenhances the capabilities of PIMC by postponing the perfect information\nresolution, reducing alleviating issues related to strategy fusion. However,\nthe decision to postpone the leaf evaluator introduces novel considerations,\nsuch as the interplay between prior levels of reasoning and the newly deferred\nresolution. In our empirical analysis, we investigate the performance of EPIMC\nacross a range of games, with a particular focus on those characterized by\nvarying degrees of strategy fusion. Our results demonstrate notable performance\nenhancements, particularly in games where strategy fusion significantly impacts\ngameplay. Furthermore, our research contributes to the theoretical foundation\nof determinization-based algorithms addressing challenges associated with\nstrategy fusion.%, thereby enhancing our understanding of these algorithms\nwithin the context of imperfect information game scenarios.",
    "authors": [
      "J\u00e9r\u00f4me Arjonilla",
      "Abdallah Saffidine",
      "Tristan Cazenave"
    ],
    "pdf_link": "http://arxiv.org/pdf/2408.02380v1",
    "category": [
      "Reinforcement Learning",
      "Explainable AI"
    ]
  },
  {
    "title": "Enhancing AI-based Generation of Software Exploits with Contextual Information",
    "abstract": "This practical experience report explores Neural Machine Translation (NMT)\nmodels' capability to generate offensive security code from natural language\n(NL) descriptions, highlighting the significance of contextual understanding\nand its impact on model performance. Our study employs a dataset comprising\nreal shellcodes to evaluate the models across various scenarios, including\nmissing information, necessary context, and unnecessary context. The\nexperiments are designed to assess the models' resilience against incomplete\ndescriptions, their proficiency in leveraging context for enhanced accuracy,\nand their ability to discern irrelevant information. The findings reveal that\nthe introduction of contextual data significantly improves performance.\nHowever, the benefits of additional context diminish beyond a certain point,\nindicating an optimal level of contextual information for model training.\nMoreover, the models demonstrate an ability to filter out unnecessary context,\nmaintaining high levels of accuracy in the generation of offensive security\ncode. This study paves the way for future research on optimizing context use in\nAI-driven code generation, particularly for applications requiring a high\ndegree of technical precision such as the generation of offensive code.",
    "authors": [
      "Pietro Liguori",
      "Cristina Improta",
      "Roberto Natella",
      "Bojan Cukic",
      "Domenico Cotroneo"
    ],
    "pdf_link": "http://arxiv.org/pdf/2408.02402v2",
    "category": [
      "Explainable AI",
      "Speech Synthesis"
    ]
  },
  {
    "title": "Enhancing Heterogeneous Knowledge Graph Completion with a Novel GAT-based Approach",
    "abstract": "Knowledge graphs (KGs) play a vital role in enhancing search results and\nrecommendation systems. With the rapid increase in the size of the KGs, they\nare becoming inaccuracy and incomplete. This problem can be solved by the\nknowledge graph completion methods, of which graph attention network\n(GAT)-based methods stand out since their superior performance. However,\nexisting GAT-based knowledge graph completion methods often suffer from\noverfitting issues when dealing with heterogeneous knowledge graphs, primarily\ndue to the unbalanced number of samples. Additionally, these methods\ndemonstrate poor performance in predicting the tail (head) entity that shares\nthe same relation and head (tail) entity with others. To solve these problems,\nwe propose GATH, a novel GAT-based method designed for Heterogeneous KGs. GATH\nincorporates two separate attention network modules that work synergistically\nto predict the missing entities. We also introduce novel encoding and feature\ntransformation approaches, enabling the robust performance of GATH in scenarios\nwith imbalanced samples. Comprehensive experiments are conducted to evaluate\nthe GATH's performance. Compared with the existing SOTA GAT-based model on\nHits@10 and MRR metrics, our model improves performance by 5.2% and 5.2% on the\nFB15K-237 dataset, and by 4.5% and 14.6% on the WN18RR dataset, respectively.",
    "authors": [
      "Wanxu Wei",
      "Yitong Song",
      "Bin Yao"
    ],
    "pdf_link": "http://arxiv.org/pdf/2408.02456v1",
    "category": [
      "LLMs",
      "Datasets"
    ]
  },
  {
    "title": "A First Look at License Compliance Capability of LLMs in Code Generation",
    "abstract": "Recent advances in Large Language Models (LLMs) have revolutionized code\ngeneration, leading to widespread adoption of AI coding tools by developers.\nHowever, LLMs can generate license-protected code without providing the\nnecessary license information, leading to potential intellectual property\nviolations during software production. This paper addresses the critical, yet\nunderexplored, issue of license compliance in LLM-generated code by\nestablishing a benchmark to evaluate the ability of LLMs to provide accurate\nlicense information for their generated code. To establish this benchmark, we\nconduct an empirical study to identify a reasonable standard for \"striking\nsimilarity\" that excludes the possibility of independent creation, indicating a\ncopy relationship between the LLM output and certain open-source code. Based on\nthis standard, we propose an evaluation benchmark LiCoEval, to evaluate the\nlicense compliance capabilities of LLMs. Using LiCoEval, we evaluate 14 popular\nLLMs, finding that even top-performing LLMs produce a non-negligible proportion\n(0.88% to 2.01%) of code strikingly similar to existing open-source\nimplementations. Notably, most LLMs fail to provide accurate license\ninformation, particularly for code under copyleft licenses. These findings\nunderscore the urgent need to enhance LLM compliance capabilities in code\ngeneration tasks. Our study provides a foundation for future research and\ndevelopment to improve license compliance in AI-assisted software development,\ncontributing to both the protection of open-source software copyrights and the\nmitigation of legal risks for LLM users.",
    "authors": [
      "Weiwei Xu",
      "Kai Gao",
      "Hao He",
      "Minghui Zhou"
    ],
    "pdf_link": "http://arxiv.org/pdf/2408.02487v1",
    "category": [
      "LLMs",
      "Explainable AI"
    ]
  },
  {
    "title": "Single-tap Latency Reduction with Single- or Double- tap Prediction",
    "abstract": "Touch surfaces are widely utilized for smartphones, tablet PCs, and laptops\n(touchpad), and single and double taps are the most basic and common operations\non them. The detection of single or double taps causes the single-tap latency\nproblem, which creates a bottleneck in terms of the sensitivity of touch\ninputs. To reduce the single-tap latency, we propose a novel\nmachine-learning-based tap prediction method called PredicTaps. Our method\npredicts whether a detected tap is a single tap or the first contact of a\ndouble tap without having to wait for the hundreds of milliseconds\nconventionally required. We present three evaluations and one user evaluation\nthat demonstrate its broad applicability and usability for various tap\nsituations on two form factors (touchpad and smartphone). The results showed\nPredicTaps reduces the single-tap latency from 150-500 ms to 12 ms on laptops\nand to 17.6 ms on smartphones without reducing usability.",
    "authors": [
      "Naoto Nishida",
      "Kaori Ikematsu",
      "Junichi Sato",
      "Shota Yamanaka",
      "Kota Tsubouchi"
    ],
    "pdf_link": "http://arxiv.org/pdf/2408.02525v1",
    "category": [
      "Speech Recognition",
      "Multimodal Learning"
    ]
  },
  {
    "title": "Explaining Reinforcement Learning: A Counterfactual Shapley Values Approach",
    "abstract": "This paper introduces a novel approach Counterfactual Shapley Values (CSV),\nwhich enhances explainability in reinforcement learning (RL) by integrating\ncounterfactual analysis with Shapley Values. The approach aims to quantify and\ncompare the contributions of different state dimensions to various action\nchoices. To more accurately analyze these impacts, we introduce new\ncharacteristic value functions, the ``Counterfactual Difference Characteristic\nValue\" and the ``Average Counterfactual Difference Characteristic Value.\" These\nfunctions help calculate the Shapley values to evaluate the differences in\ncontributions between optimal and non-optimal actions. Experiments across\nseveral RL domains, such as GridWorld, FrozenLake, and Taxi, demonstrate the\neffectiveness of the CSV method. The results show that this method not only\nimproves transparency in complex RL systems but also quantifies the differences\nacross various decisions.",
    "authors": [
      "Yiwei Shi",
      "Qi Zhang",
      "Kevin McAreavey",
      "Weiru Liu"
    ],
    "pdf_link": "http://arxiv.org/pdf/2408.02529v2",
    "category": [
      "Explainable AI",
      "Reinforcement Learning"
    ]
  },
  {
    "title": "Clustering and Mining Accented Speech for Inclusive and Fair Speech Recognition",
    "abstract": "Modern automatic speech recognition (ASR) systems are typically trained on\nmore than tens of thousands hours of speech data, which is one of the main\nfactors for their great success. However, the distribution of such data is\ntypically biased towards common accents or typical speech patterns. As a\nresult, those systems often poorly perform on atypical accented speech. In this\npaper, we present accent clustering and mining schemes for fair speech\nrecognition systems which can perform equally well on under-represented\naccented speech. For accent recognition, we applied three schemes to overcome\nlimited size of supervised accent data: supervised or unsupervised\npre-training, distributionally robust optimization (DRO) and unsupervised\nclustering. Three schemes can significantly improve the accent recognition\nmodel especially for unbalanced and small accented speech. Fine-tuning ASR on\nthe mined Indian accent speech using the proposed supervised or unsupervised\nclustering schemes showed 10.0% and 5.3% relative improvements compared to\nfine-tuning on the randomly sampled speech, respectively.",
    "authors": [
      "Jaeyoung Kim",
      "Han Lu",
      "Soheil Khorram",
      "Anshuman Tripathi",
      "Qian Zhang",
      "Hasim Sak"
    ],
    "pdf_link": "http://arxiv.org/pdf/2408.02582v1",
    "category": [
      "Speech Recognition",
      "Speech Synthesis"
    ]
  }
]